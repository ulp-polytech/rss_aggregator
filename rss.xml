<rss version="2.0"><channel><item><title>An LCC Wireless Charger With Embedded Cell Equalization via a Shared Compensation Inductor</title><link>http://ieeexplore.ieee.org/document/11164974</link><description>This article presents an integrated approach for achieving simultaneous battery charging and balancing in wireless power transfer (WPT) systems, unifying both functions within a single, compact circuit topology. The proposed design repurposes the receiver-side compensation inductor as the primary winding of a multiwinding transformer, enabling the balancing function to be realized without introducing additional magnetic components or control circuits. Balancing voltages and accurate intercell energy redistribution are governed by the transformer&#8217;s turns ratio, allowing precise regulation without auxiliary converters or switch matrices. Consequently, the system avoids the multiple receiver coils and complex switching networks typical of conventional WPT equalizers, leading to notable reductions in cost, volume, and control complexity. Furthermore, the topology ensures accurate balancing without stringent coupling consistency and remains stable under coil misalignment, highlighting its robustness to mutual inductance variations. These attributes make the system particularly suitable for dynamic or mobile energy storage applications. Experimental results validate the proposed equalizer, demonstrating a charging efficiency of 81.5% at a 19 W load while maintaining intercell voltage deviations below 0.02 V. These results demonstrate that the proposed method offers a compact, reliable, and scalable approach for integrated battery management in WPT-enabled systems.</description></item><item><title>Data-Based Zero-Phase Angle Frequency Tracking for Series&#8211;Series Compensated WPT Systems</title><link>http://ieeexplore.ieee.org/document/11174129</link><description>The zero-phase angle (ZPA) operation is a widely used strategy in wireless power transfer (WPT) systems to improve the system efficiency. However, the ZPA frequency could vary in application scenarios such as ship-to-shore power systems, where the transfer distance is disturbed by waves, which could force the self- and mutual inductance of the coupled coils to change. Meanwhile, frequency bifurcation often occurs in tightly coupled WPT systems, leading to multiple ZPA frequencies. In this article, a data-based method is proposed to track one of the ZPA frequencies for a magnetic coupling WPT system with series&#8211;series compensation. The proposed method first tracks in real time the waveform of the inverter output current, i.e., amplitude and frequency, from sampled data; then, based on these quantities, aligns the output voltage and current of the inverter to achieve the ZPA operation. Moreover, convergence of the operation frequency is analyzed, and guidelines to suppress frequency hopping are suggested. The implementation of the proposed method in a digital signal processor with the help of a pulsewidth modulation module has also been discussed. The effectiveness of the proposed method is verified by experiments.</description></item><item><title>Hybrid Mechanism- and Data-Driven Joint Parameter Identification for Underwater Wireless Power Transfer Systems</title><link>http://ieeexplore.ieee.org/document/11185120</link><description>Accurate identification of key parameters is crucial for closed-loop control and system stability in underwater wireless power transfer (UWPT) systems. However, the absence of communication and severe harmonic distortion from eddy currents in sea environments present significant challenges to identification results. This article proposes a hybrid mechanism- and data-driven method for accurate joint identification of mutual inductance and load. First, to resolve the linear dependence and parameter coupling inherent in typical LCC&#8211;S compensated UWPT systems, a multifrequency excitation strategy is introduced to extract informative features for joint identification. Second, an artificial neural network is pretrained on mechanism-based data to construct the source domain model (SDM). Moreover, transfer learning fine-tunes the SDM with limited experimental data to obtain a target domain model (TDM), enhancing model generalization under varying conditions. Finally, an experimental platform with 1 kW/85 kHz is constructed to validate the proposed method. Experimental results and three different typical underwater conditions are captured and collected, which demonstrates that the proposed mechanism and data-driven joint parameter identification method can achieve quick and accurate identification results with prediction error below 3% and response time within 2.72 ms.</description></item><item><title>Dynamic Performance Enhancement for Multiexcitation-Units WPT System Using Data-Driven Modeling and Matrix-Inversion-Free Model Predictive Control</title><link>http://ieeexplore.ieee.org/document/11197913</link><description>The multiexcitation-units wireless power transfer (MEU-WPT) system supports multilevel power applications by adjusting the number of excitation units. Its inherent redundancy enhances reliability against inverter failures, making it ideal for wireless electric vehicle and underwater vehicle charging. However, the incorporation of the MEU structure increases the number of control variables (such as the phase-shift angles of the inverters) and introduces cross couplings among different power units, resulting in complex power transfer channels and interconnected feedback loops, where variations in one control variable generate disturbances in other channels. Consequently, achieving high dynamic performance in output regulation becomes challenging without effective coordination of all control variables. This article proposes a constrained model predictive control (MPC) method aimed at achieving high dynamic performance in output regulation for the MEU-WPT system with cross couplings. Initially, a data-driven simplified refined instrumental variable method is employed to model the MEU-WPT system, capturing the dynamics associated with the cross couplings. Subsequently, a Laguerre-network based multivariable MPC control law is derived from the data-driven models. A matrix-inversion-free quadratic programming solver is developed to enable computationally-efficient constrained optimization. Furthermore, an event-triggered mechanism is integrated into the control framework, demonstrating the potential for rapid switching between different input power allocations among excitation units. An MEU-WPT prototype featuring two excitation units is constructed to validate the feasibility of the proposed control approach.</description></item><item><title>3-D Wireless Power Transfer With Orthogonal Transmitters and Adaptive MPC-MPPT</title><link>http://ieeexplore.ieee.org/document/11202560</link><description>This article presents a three-dimensional wireless power transfer system that uses three transmitting coils oriented in orthogonal directions and an adaptive model predictive control (MPC) strategy that incorporates maximum power point tracking (MPPT). The framework combines MPC&#8217;s predictive optimization and MPPT&#8217;s efficiency-seeking behavior, which simultaneously optimizes power tracking accuracy, system efficiency, and current distribution, while maintaining zero-voltage-switching operation. The dynamic weight-adjustment mechanism alters the weights of competing objectives automatically and based on the current operational conditions. The system model indicates that power distribution in 3-D space fits a Lemniscate of Bernoulli surface revolved about its longitudinal axis, so the rotational Lemniscate of Bernoulli surface is important to the control design. The experimental results presented in this article show up to 20% increased efficiency at 40 cm transmission distance, and a peak efficiency of 87% at 60 W and at 40 cm &#215; 40 cm &#215; 40 cm charging volume. The framework provides stable power delivery while the receiver is in motion, making it appealing for applications that require spatial freedom, including mobile robots and bio-inspired aerial vehicles.</description></item><item><title>A M&#246;bius Transformation Impedance Matching Approach for Large Load Region and Multilevel Power Modulation in High Frequency Switched Mode Power Amplifier</title><link>http://ieeexplore.ieee.org/document/11207141</link><description>The switched mode power amplifier (PA) is widely used for high frequency high power applications due to its high efficiency. In the switched mode PAs, impedance matching network (IMN) is usually needed to ensure that the varying load impedances can be matched to the target impedances for high efficiency. The existing IMN design methods usually depend on empirical trial and error, load pull simulation, and numerical optimization, which cannot achieve actual region-to-region impedance matching. Therefore, this article proposed a novel impedance matching design approach for switch mode PAs based on the property of circle preservation in M&#246;bius transformation which guarantee that all the impedance points in a region or trajectory can be precisely transferred to the target region or trajectory. The proposed approach gives the simple and explicit formulas to design the IMN parameters, which helps solve the design challenge of accurate impedance matching for large load region. And the impedance matching design for frequency tuning control is also presented to achieve high efficiency and multilevel power modulation over a large impedance region. For verification, a 500 W 13.56 MHz GaN-based class E PA is built and the experiments show that the PA with proposed matching design can achieve 87.2%&#8211;95% efficiency over a large load region. And the high speed pulsing (200 kHz) and multilevel (25.6 kHz) power modulation can be also achieved by frequency tuning with ultra-fast transitions (369 ns) and 91% average efficiency by using the proposed design.</description></item><item><title>Hybrid Wireless Power Transfer With Self-Resonance Coupler Based on Integrated Coil</title><link>http://ieeexplore.ieee.org/document/11208828</link><description>According to the duality of inductive wireless power transfer (IPT) and capacitive wireless power transfer (CPT) in coupler and tuning method, an integrated coil is designed in this article to constructs a compact hybrid wireless power transfer (HPT). The magnetic field coupling and the electric field coupling constructed by coils and plates share one energy transmission channel, which enhances the transmission power and energy density. The inductance of coils and capacitances of plates compensate for each other. The resonant frequency of integrated coils is adjusted to kHz. Additional tuning inductances and capacitances are eliminated to build a lighter self-resonance coupler. The stacked structure design of coils and plates enables compact integration and miniaturization of integrated coils. A 300 W experimental platform was built, and some comparative experiments were conducted. Compared to the coupler of IPT, the self-resonance coupler has improved performance in transmission power, antioffset, and over-coupling suppression. HPT performs better than CPT in transmission distance, transmission power, and transmission efficiency. It has some advantages in the medium-power application scenarios, such as inspection robots and drones, which expect couplers to have a smaller volume, lighter weight, higher power density and better antioffset.</description></item><item><title>Nonpolar Integration for LCC Compensation Inductor in EV-WPT Systems</title><link>http://ieeexplore.ieee.org/document/11207549</link><description>To reduce the volume of the secondary side of an electric vehicle wireless power transfer system, integrated LCC compensation has become a prevalent approach. However, integrated inductors introduce additional coupling effects among the integrated inductors and the power coils, which may influence the input impedance angle, and increase electrical stresses. To circumvent this problem, this article proposes a nonpolar method for integrated compensation inductor design. The main idea behind the proposed method is to first separate a single compensation inductor into two bipolar inductors, then reconfigure the wirings so that the currents flow in opposite directions, which helps to mitigate their cross interactions. Since this approach decouples the compensation inductors from the power coils, the system becomes more compact and, at the same time, the symmetrical layout results in lower coil current stresses and reduced electromagnetic interference. The universal harmonic-considered time-domain model for vehicle-side magnetic integration is deduced. Furthermore, a systematic comparison of soft-switching behavior between conventional integrated solutions and the proposed topology is carried out under varying misalignment conditions. Experimental results obtained from a 11-kW prototype show that the proposed system achieves zero-voltage switching over the specified misalignment range, with a peak efficiency of 93.4%. A video showing the waveforms of the system during the misalignment process is provided in the Supplementary Material.</description></item><item><title>Pulse Skipping Analysis in Wireless Power Transfer Systems Based on a Reduced-Order Model</title><link>http://ieeexplore.ieee.org/document/11216023</link><description>Wireless power transfer (WPT) systems with battery loads exhibit low damping, which results in significant current overshoots and sustained oscillations when subjected to disturbances. Pulse skipping control is frequently employed in WPT systems and can be considered a significant disturbance. However, the accurate analysis of the resulting system dynamics and current envelope remains a challenge. To allow accurate evaluation of the performance of WPT systems with pulse skipping, this article introduces a new reduced-order model for WPT systems through balanced truncation. The derived second-order model enables real-time computation of the current envelopes on both sides of the system, facilitating a comprehensive analysis of the overall performance. This article presents two case studies that utilize this reduced-order model to optimize pulse skipping control in WPT systems. The first study proposes a pulse skipping soft-start strategy based on this model. The second study investigates the optimal pattern of pulse skipping modulations. Simulations and experimental results from a laboratory prototype validate the effectiveness and feasibility of the proposed reduced-order model and the design and refinement of the pulse skipping patterns.</description></item><item><title>Research on an Efficient Noncontact Power Transfer Method for Elliptical Ultrasonic Tool Holders</title><link>http://ieeexplore.ieee.org/document/11223710</link><description>The elliptical ultrasonic tool holder (EUTH) is a critical core component in elliptical ultrasonic vibration-assisted milling. Traditional EUTH employ conductive slip rings for power transmission, which severely restricts milling speed. This study investigates an efficient noncontact power transfer method for EUTH, utilizing a dual-channel rotary transformer to replace conductive slip rings. Electrical energy is transferred through air coupling between the primary and secondary sides of the rotary transformer, and this frictionless power transmission method eliminates limitations on milling speed. A finite element model of the elliptical ultrasonic transducer was used to analyze its modal shape, impedance, and resonant frequency temperature drift characteristics, thereby determining the transducer's resonant frequency, vibration amplitude, and node positions. The rotary transformer was designed using ferrite core material with high magnetic permeability and low electrical conductivity to reduce eddy current losses. An equivalent circuit model of the EUTH was established, and compensation circuits were designed to improve the efficiency of noncontact power transfer. A dual-channel ultrasonic generator (DCUG) was developed using a Class D amplifier, enabling adjustable voltage amplitude, phase, and frequency. A Fuzzy-PID algorithm was implemented to achieve automatic resonant frequency tracking for the DCUG. Finally, a milling platform was set up to conduct elliptical ultrasonic vibration-assisted milling experiments, where the DCUG drove the EUTH. Experimental results show that below 40 kHz, the maximum driving voltage of the dual-channel ultrasonic generator reaches 300 Vp-p, while the elliptical vibration displacements at the tool tip in the X- and Y-directions are both approximately 20 &#956;mp-p. The output amplitude current remains stable, and the system automatically tracks the resonant frequency of the EUTH during milling. This provides an effective method for achieving high-efficiency noncontact power transfer in EUTH.</description></item><item><title>An Omnidirectional Wireless Power Transfer System via Two Orthogonal Bipolar Coils and Targeting Magnetic Field Control for UAVs</title><link>http://ieeexplore.ieee.org/document/11226851</link><description>Misalignment tolerance represents a critical challenge in uncrewed aerial vehicle wireless power transfer (UAV-WPT) systems. Conventional approaches enhance positional and angular misalignment tolerance by generating wide-range omnidirectional magnetic fields through transmitter design or rotating field techniques. However, these methods exhibit a low magnetic field utilization rate since UAVs typically require only specific field orientations postlanding rather than omnidirectional fields. This article proposes a UAV-WPT system employing two orthogonal bipolar transmitting coils with a targeting magnetic field to achieve omnidirectional powering and enhance the magnetic field utilization rate simultaneously. COMSOL simulations are used to analyze the magnetic field distribution of the transmitter, and the principles for generating a targeting magnetic field through excitation current control are explained. The amplitude and phase of the excitation currents are controlled by adjusting the duty cycle and phase difference of the two half-bridge inverters. The mathematical relationships between maximum output power, maximum input power, and maximum transmission efficiency with respect to duty cycle and phase difference are established. A targeting magnetic field control method combining phase difference and duty cycle scanning is proposed. Experimental results show that the system can establish a targeting magnetic field within 85 ms, with a maximum output power of 216.2 W and a peak dc-to-dc efficiency of 89.5%. The dc-to-dc efficiency exceeds 76.1% across &#177;100 mm positional misalignment and arbitrary angular misalignment. The dc-to-dc efficiency of the targeting magnetic field mode is at least 5% higher than that of the rotating magnetic field mode.</description></item><item><title>A Single-Stage Synchronized Switch Interface Circuit for Power Enhancement and Voltage Regulation in Electromagnetic Energy Harvesting</title><link>http://ieeexplore.ieee.org/document/11240585</link><description>Synchronized switch interface circuits demonstrate good performance for electromagnetic energy harvesting applications, but lack adaptability in terms of harvested power. This article introduces an additional control degree of freedom by proposing two power control methods and implementing them in a synchronous current inversion and energy extraction (SCIEE) circuit. Theoretical analysis indicates that the single-stage system achieves higher efficiency for approximately 41.3% of the supported load range compared to using a commercial dc&#8211;dc regulator. In the load transient experiments, the proposed system maintains the output voltage well-regulated, with undershoot and overshoot below 0.2 V. The output voltage ripple is 0.15 V at an 18 mA load current. The proposed system is compared to three other options: a direct ac&#8211;dc harvesting circuit, the synchronous switch energy extraction (SSEE) circuit, and a two-stage harvesting system using a commercial dc&#8211;dc regulator and an open-loop SCIEE circuit. The proposed system supports a maximum load current of 29.47 mA, the highest among these options. In a field test, the proposed system supports successful integrated circuit long range (LoRa) packet transmissions and exhibits a broader supported load range than the SSEE or direct ac&#8211;dc harvest scheme.</description></item><item><title>Constant Current/Voltage Charging Control for Communication-Free IPT Systems via Network-Based Deep Transfer Learning</title><link>http://ieeexplore.ieee.org/document/11245200</link><description>Parameter identification-based control strategies are considered the preferred solution for achieving constant current (CC) and constant voltage (CV) charging control in communication-free inductive power transfer systems. However, identification errors in mutual inductance, load resistance, and other parameters can affect control accuracy. To improve control accuracy and response speed, a communication-free control strategy based on neural networks and deep transfer learning is proposed. This strategy eliminates the need to identify parameters like mutual inductance and load resistance. Only a few measured datasets are required to train the network model offline, and a trained model can online estimate output voltage/current. By combining with a controller, CV/CC charging control can be achieved under conditions of real-time variations in mutual inductance and load resistance. The experimental results show that the proposed control strategy achieves a static error of only 1.5% and a response time of no more than 24 ms. Compared to the parameter identification-based control strategy, the proposed strategy demonstrates lower static error, shorter response time, and a wider dynamic range.</description></item><item><title>Design of an Anti-Misalignment Coil With Hilbert Structure for WPT System</title><link>http://ieeexplore.ieee.org/document/11249794</link><description>Currently, coil misalignment is recognized as one of the primary factors limiting the transmission efficiency of wireless power transfer (WPT) systems, presenting a substantial barrier to the large-scale adoption of WPT. To enhance transmission efficiency under misalignment, mitigate the impacts of misalignment, and increased transmission distance of WPT systems, research on Hilbert fractal curves in related fields was referenced, mutual inductance expressions for coils with Hilbert-extended structures and conventional coils were derived based on their mathematical formulations, and the potential advantages of Hilbert curves in wireless power transfer applications were analyzed. Supported by extensive simulation outcomes, a fractal coil incorporating a Hilbert structure was designed without altering coil manufacturing costs. The transmission performance advantages of this coil were investigated through simulations. A WPT system verification platform utilizing an LCC-S circuit was constructed, where 300 W power and efficiency tests were conducted under relatively consistent zero voltage switch (ZVS) conditions for both coil types. Experimental results across varying transmission distances and misalignment distances were obtained. The results demonstrate that the proposed coils comprehensively optimize the power transfer capability of conventional coils, delivering more stable output power and improving the transmission efficiency by over 10% (up to 24%).</description></item><item><title>Multifrequency and Multiload WPT System Based on Cascade H-Bridge Multilevel Inverter</title><link>http://ieeexplore.ieee.org/document/11251316</link><description>To address the issues of limited output power and harmonic interference in existing multifrequency and multiload magnetic coupling resonant wireless power transfer (MFML-MCR-WPT) systems, this article proposes a MFML-MCR-WPT system based on a cascaded H-bridge multilevel inverter (CHB-MLI). The system utilizes the phase disposition multifrequency modulation technique, achieving arbitrary frequency and quantity power output and control through the design of modulation wave quantity, frequency, and amplitude. First, the structure of the CHB-MLI-based MFML-MCR-WPT system is proposed, and the working principle of the multifrequency modulation method is analyzed. Subsequently, a five-level dual-frequency and dual-load system is taken as an example to establish the mathematical model. Then, system parameter optimization is conducted to suppress cross-coupling and interfrequency interference. Furthermore, to address the power and loss imbalance among H-bridge units under multifrequency low modulation indices, a carrier reconstruction method is adopted to balance power distribution and switching losses. Finally, an experimental platform is constructed to validate the proposed theory. Simulation and experimental results demonstrate that the system achieves multilevel multifrequency power output with continuous power and frequency control, maintains minimal interchannel interference, and achieves H-bridge unit balancing ratios of 1:1.19, while exhibiting excellent system compatibility and controllability.</description></item><item><title>Analysis and Control of Delta-Connected CHB-Based APQC-ESS for Co-Phase RPS</title><link>http://ieeexplore.ieee.org/document/11215859</link><description>To address the high energy consumption and power quality (PQ) issues in railway power systems (PS), a delta-connected cascaded H-bridge (CHB) based active power quality conditioner integrating energy storage system (APQC-ESS) for co-phase RPS is proposed. First, the operating principles of APQC-ESS for regenerative braking energy (RBE) utilization, reactive power compensation, and negative sequence current (NSC) suppression are analyzed. Then, a multiobjective decoupled control strategy based on sequence component decomposition is developed to achieve independent control of above multiobjectives. On this basis, a collaborative energy management strategy is investigated to enable real-time multiobjective cooperative control for APQC-ESS under fluctuating traction loads. Specifically, the collaborative energy management categorizes RPS operating conditions into two types based on the NSC severity. Subsequently, a three-stage optimization strategy is employed to allocate APQC-ESS capacity to meet various compensation targets, while comprehensively considering capacity limitations and unbalanced power flow within the CHB branches. Finally, the effectiveness and feasibility of the proposed APQC-ESS and its control strategy is validated through experimental results and a filed data case study. The traction energy consumption reduction rate and RBE utilization rate are 26.6% and 27.6% higher than conventional compensation method.</description></item><item><title>Dynamic Optimal Proportional-Integral Control (DOC) Strategy Based on Capacitor Energy Balance in Three-Port Rectifier for Low Frequency Pulse Load</title><link>http://ieeexplore.ieee.org/document/11215829</link><description>The low-frequency pulse load poses a new challenge to the reliability of the power supply system. To adapt to sudden changes in pulse frequency, higher requirements are imposed on the dynamic performance of the converter. The conventional proportional-integral (PI) control cannot simultaneously ensure both excellent dynamic and steady-state performance. The capacitor energy balance control method can achieve high dynamic performance. However, it requires additional output compensation for the converter&#8217;s active current, and its implementation complexity hinders widespread adoption. This article develops an optimized dynamic PI control strategy for three-port rectifiers to address low-frequency pulse load challenges, leveraging capacitor charge balance control (CBC) for enhanced performance. By analyzing the optimal transient trajectories of voltage and current during pulse frequency step changes, the corresponding dynamic controller parameters are prestored based on actual operating conditions. When the pulse frequency changes, rapid active current adjustment within a single pulse cycle is achieved by modifying the outer-loop parameters. This approach maintains the decoupling voltage recovery curve near its optimal trajectory without requiring additional compensation. A three-port rectifier prototype was developed, and experimental results validate both the effectiveness and feasibility of the proposed control method.</description></item><item><title>Magnetic Gear-Based Ferrite PM Vernier Generator for a Direct-Drive Wind Turbine</title><link>http://ieeexplore.ieee.org/document/11220162</link><description>Nowadays, direct-drive wind generators are becoming popular due to the absence of mechanical gearboxes, noiseless operation, high reliability and less maintenance. Usually, permanent magnet synchronous generators (PMSGs) are used for direct-drive wind energy conversion systems due to their high efficiency and voltage regulation. However, the speed of wind turbine blades is generally low, and hence a gear-box is required for grid-connected operation of the generator. Therefore, magnetic geared machines such as flux reversal generators (FRGs) and permanent magnet vernier generators (PMVGs), which have an inherent magnetic gearing effect, low-speed high-torque capability and high torque-to-weight ratio are becoming popular for direct-drive wind generators. In this article, an outer rotor surface-mounted PMVG with ferrite magnets is proposed. A 2-D finite element (FE) analysis is carried-out and the results are presented. In addition, a prototype is fabricated to measure the effectiveness of the proposed generator. Further, experimental validation is carried-out and performance parameters are measured and compared with 2-D FE analysis.</description></item><item><title>Design of Variable Pole Phase Induction Motor Drive With Hybrid Four Quadrant Switch Configuration</title><link>http://ieeexplore.ieee.org/document/11218267</link><description>In electric traction applications, researchers are employing pole phase modulation (PPM) based multiphase induction machines (MIM) to achieve a broader range of speed and torque, allowing for dynamic switching between the various pole phase configurations. The existing literature studies have concentrated more on various inverter topologies for variable pole phase-based induction machines (VPIM). Here, the torque ripple and dc bus voltage utilization (DBVU) issues are tackled with multiple four-quadrant switches along with 3-&#981; SVPWM technology. However, the design of the VPIM drive system w.r.t the converter and machine is crucial, which is not explored in previous studies. This article aims to bridge this gap by describing design considerations of the inverter configuration as well as the motor for VPIM drives. A simple 2-level 9-&#981; inverter with a hybrid four-quadrant switch (HFQS) is proposed for VPIM with phase grouping and isolated neutral techniques. This HFQS is realized with one controllable switch and six power diodes with snubber protection to limit the voltage surges during the transitions from one pole to another pole combination. The design considerations of the dc bus, switch selection for the 9-&#981; inverter, and design of a proposed HFQS are presented in detail. It further presents complete switching loss analysis, conduction loss analysis, and overall inverter as well as motor efficiency. The 3-&#981; carrier-based SVPWM ensures better DBVU, and phase-shifted carriers give the enhanced torque ripple in the high pole mode of a 9-&#981; VPIM drive. The proposed inverter design for a 9-&#981; VPIM has been implemented and validated with Maxwell 2-D, along with Simplorer, and the laboratory prototype of a 5 hp motor.</description></item><item><title>Air-Cooled Coils for Induction Sealing of Large Cylindrical Containers</title><link>http://ieeexplore.ieee.org/document/11217347</link><description>In induction cap sealing, power is transferred to thin Al foil(s) traveling beneath an energized coil-head to create a hermetically sealed bond between the foil and the rim of a plastic/glass container. The distribution of transferred power on foil plays crucial roles for quality of sealing, sealing range, productivity, and energy efficiency. It is particularly difficult to seal moving containers using foils with a large diameter. Achieving desired heat distribution by thermal conduction on a thin foil is difficult. The problem gets aggravated when several large containers reside beneath the coil-head. The effective load resistance could go beyond its limiting value, resulting reduction in coil current. Corresponding reduction in power density in foil could result undersealing. To resolve the problems of sealing continuously fed large-mouth containers (foil diameter &#8805; body diameter), this article proposes a novel coil-head to take care of energy distribution electromagnetically. It achieves sealing of large containers without any feeding constraints and inherently avoids overload condition. The coil enhances the efficiency of energy utilization and productivity. The coil-head is experimentally validated by sealing containers using foils with a diameter range 35&#8211;140 mm. Its superior field distribution is also verified. Even after transferring less power, the foil area sealed/second is drastically increased.</description></item><item><title>Multimicrogrid P2P Energy Trading Benefiting Both Microgrids and the Main Grid Based on a Bi-Level Game</title><link>http://ieeexplore.ieee.org/document/11215689</link><description>This article proposes a multimicrogrid peer-to-peer (P2P) energy trading framework that benefits both microgrids and the main grid. The framework considers the demand satisfaction, trading revenues, and energy generation and storage costs of microgrids with mixed renewable energy sources. Meanwhile, to ensure the main grid&#8217;s utility, mechanisms for trading quantities bargaining and trading fees are designed. The problem is formulated as a bi-level game. A Nash bargaining framework is introduced to model the competitive interactions among multiple microgrids and the main grid. A fully distributed alternating direction method of multipliers (ADMMs), sharing only limited trading information, is applied to the bargaining problem to protect the privacy of individual microgrids. A proportional allocation method is formulated to ensure a rapid and fair allocation of utility among households within each constituent microgrid. Finally, numerical simulations based on a scenario involving Manchester and three surrounding towns validate the feasibility and effectiveness of the proposed framework.</description></item><item><title>Dynamic Models for DC Fault Analysis of Actively Commutated CSC-HVDC Under Different Grid Strengths</title><link>http://ieeexplore.ieee.org/document/11217327</link><description>Actively commutated current source converter based high-voltage direct current transmission (CSC-HVDC) with state-of-the-art high power IGCTs is a promising candidate due to its merits such as fault ride-through capability and small footprint. The existing dc fault models of CSC either focus on 3-level CSC topology or neglect the transient process and commutation of the converter after fault, not suitable for accurate dc fault analysis of CSC-HVDC. Moreover, the elimination of ac-filters at the point of common coupling (PCC) will lead to severe PCC voltage distortion of weak-grid connected CSC-HVDC after fault. The interaction between the valve-groups caused by the voltage distortion and its influence on the fault characteristics is yet to be studied. In this article, two dc fault analysis models for CSC-HVDC connected to ac grid with different strengths are proposed. Based on quasi-steady state assumptions and substitution theorem, a simplified model by decoupling the valve-groups at the PCC and its adaptability under different grid strengths are proposed for analytical studies of dc fault. For weak-grid connected CSC-HVDC, a fault analysis model is further derived based on the quantitative analysis of the interaction between valve-groups. The proposed models are validated through PSCAD simulations and HIL experiments.</description></item><item><title>Study on an Improved Current Ripple Suppression Algorithm for IPOS SAB DC&#8211;DC Converter System</title><link>http://ieeexplore.ieee.org/document/11220830</link><description>The input-parallel output-series (IPOS) single active bridge (SAB) dc&#8211;dc converter system often suffers from current ripple issues caused by enormous branch power differences due to the location of windward surface and wind turbines in the cascaded dc wind farm. Therefore, this article focuses on a dc current ripple suppression algorithm for the IPOS SAB system, and three improvements are as follows. First, the effect of branch power difference on dc current ripple is analyzed, current ripple model is derived by the Fourier decomposition of inductor current within a switching period, and its 2nd ripple component at switching frequency is the main current ripple analytically. Second, system operational regions are divided into Zone I and Zone II according to branch power ratios, and a current ripple suppression algorithm that consists of triangular synthesis phasor method and inverted phasor method is proposed by regulating branch carrier phase-shift angles in the two zones. Third, the proposed current ripple suppression algorithm is verified by simulations and experiments.</description></item><item><title>Fault-Tolerant Model Predictive Control for Three-Level T-Type Converters Based on Fault-Induced State Equation Modeling</title><link>http://ieeexplore.ieee.org/document/11214711</link><description>Three-level T-type converters (3LT${}^{\mathbf{2}}$Cs) provide inherent redundancies that can be used to improve system-level reliability, where fault-tolerant control (FTC) techniques are the enabling algorithms. Existing FTC methods primarily focus on compensating redundant vectors and adjusting dwell times, while neglecting the impact on modeling and control of grid-side currents and neutral-point (NP) voltage under fault conditions. This work formulates a unified fault-induced state space model that facilitates the construction of cost functions in finite-control-set model predictive control (FCS-MPC). The modeling is based on the investigation of the possible cases of single-switch and double-switch open-circuit faults, and the analysis of additional terms introduced by the faults. The proposed FTC method adopts a dual-loop control structure, i.e., the outer loop uses a proportional integral (PI) controller to automatically increase the reference value of the dc bus voltage during vertical faults and converts it into the grid current reference, while the inner loop combines fault-induced grid-side current and NP voltage cost functions in FCS-MPC, adjusting weighting factors based on fault conditions to prioritize grid-side current quality. Experimental results demonstrate the proposed FTC under various open-circuit fault scenarios.</description></item><item><title>Discontinuous Modulation-Based Active Thermal Control for Enhancing the KVA Limit of Grid-Connected Inverter-Based Resources</title><link>http://ieeexplore.ieee.org/document/11217174</link><description>The kVA limit of a power electronic converter (PEC) is often limited to keep the junction temperature ($T_{j}$) within a safe operating area (SOA). Hence, controlling $T_{j}$ with advanced algorithms such as active thermal control (ATC) methods seems to be a promising way to increase the kVA limit of PEC. In this regard, this article presents a novel closed-loop control approach, combining the discontinuous pulse width modulation (DPWM) strategy with a system-level current controller. The proposed method enables grid-connected inverter-based resources (IBR) to increase their kVA limit without violating the $T_{j}$ limit. This method further allows the converters to operate at a higher ambient temperature ($T_{\rm amb}$) without sacrificing their power handling capacity. An analytical relationship between the bus clamp angle ($\alpha$) with respect to the switching loss ($P_{\rm sw}$) for DPWM has been explained, which is then used as a control variable for the ATC. For the thermal model, a simple Foster thermal model-based temperature estimation method is described, and its accuracy has been depicted.</description></item><item><title>Distributed Control for Multibus Voltage Regulation and Adaptive Reactive Power Sharing in Islanded Microgrids</title><link>http://ieeexplore.ieee.org/document/11217313</link><description>In multibus islanded microgrids (IMGs), maintaining all bus voltages within limits while ensuring proper reactive power sharing (RPS) among distributed generators (DGs) presents a significant challenge. To address this challenge, this article presents a distributed control strategy for achieving multibus voltage regulation and adaptive RPS in IMGs. First, we propose a dynamic max/min-consensus algorithm to monitor the real-time voltage range across all buses in a distributed manner. Next, we design a distributed observer to calculate the ideal reactive power reference for each DG. Finally, based on the monitoring of the voltage range, the designed controller ensures that all bus voltages remain within acceptable limits while adjusting each DG&#8217;s output reactive power as close as possible to the reference values. To validate the proposed strategy, we set up IMG systems of different scales using both the hardware-in-the-loop (HIL) experimental platform and the MATLAB/Simulink simulation environment for comprehensive testing. The results show that the proposed strategy effectively regulates all bus voltages within the target range while achieving adaptive RPS, whereas existing methods cause some bus voltages to violate limits.</description></item><item><title>Reinforcement Learning Based Active Model Variation Deadbeat Control for Energy Storage System in DC Microgrids With Constant Power Loads</title><link>http://ieeexplore.ieee.org/document/11216350</link><description>The issues of constant power load (CPL) and model mismatch lead to significant current ripples and voltage fluctuations in dc microgrids, presenting a substantial challenge for the control methods of energy storage systems. To address these issues, this article proposes a reinforcement learning based active model variation deadbeat control (RL-AMVDB), which adjusts a few control model parameters in the current control loop. The model variation factors and the states of closed-loop system are formulated as a Markov decision process, allowing the model variation factors to be optimized through RL. The performance of the proposed method is evaluated through both simulation and hardware experiments. Experimental results demonstrate that the proposed method reduces current ripple by 16.6% under model mismatch conditions. Additionally, under sudden CPL changes, the settling time, voltage fluctuations, and current ripple are reduced by 38.4%, 10.2%, and 12.5%&#8211;20%, respectively.</description></item><item><title>A Simple and Efficient Direct Predictive Control Framework for Multiparallel Power Converters</title><link>http://ieeexplore.ieee.org/document/11218625</link><description>Parallel connection of power converters is a widely adopted approach to increase power capacity and enhance fault tolerance. This article presents a simple and efficient direct predictive control framework for multiparallel two-level and three-level neutral-point-clamped converters. By using the number of available switching states as control variables, rather than the switching states themselves, the candidate set is reduced to no more than four, significantly lowering the computational burden and enhancing scalability. Additionally, a novel current sorting method is introduced to suppress circulating currents independently, allowing more flexibility for output current and voltage balancing optimization. Both simulation and experimental results validate its effectiveness.</description></item><item><title>Adaptive Virtual Bus Strategy for Electrolytic Capacitorless DAB Microinverters</title><link>http://ieeexplore.ieee.org/document/11220219</link><description>In residential photovoltaic (PV) systems, microinverters link the PV panels to the ac bus. Conventionally, these microinverters incorporate a stable dc bus that relies on bulky and unreliable electrolytic capacitors. To improve, we propose an adaptive virtual bus strategy for DAB microinverter, which removes the electrolytic capacitors. The microinverter features a quasi-single-stage design interconnected by a virtual bus, which exhibits a notable double-line-frequency voltage ripple. The front-end employs a boost converter to elevate the low PV voltage and regulate the voltage of the virtual bus. The back-end utilizes a dual-active-bridge (DAB) inverter to transform the oscillating virtual bus voltage into the desired ac output. This architecture facilitates active power decoupling (APD) for enhanced power density by buffering mismatched power on the minimized bus capacitors and dynamically adjusting the operational state of the DAB inverter. Furthermore, by decoupling the control algorithms of the two parts, we reduce the number of required voltage and current sensors, thereby simplifying the overall control system. To validate the concept, a GaN-based prototype rated at 200 W and 600 kHz maximum is designed and tested. This prototype achieved a peak efficiency of 92.67%.</description></item><item><title>Energy-Aware Adaptive Force-Admittance Control for Robotic Manipulators: Application in High-Precision Aircraft Assembly</title><link>http://ieeexplore.ieee.org/document/11217341</link><description>An energy-aware adaptive force-admittance control strategy is proposed, which integrates accurate force regulation through a direct force controller with compliant motion enabled by adaptive admittance control. This combined mechanism addresses environmental uncertainties while simultaneously regulating wrench and position. However, the admittance adaptation and direct force controller introduce nonpassive behaviors, undermining the system&#8217;s passivity. To resolve this issue, a virtual energy tank is introduced to monitor the energy associated with nonpassive actions, ensuring energy boundedness and restoring system passivity for stable interaction with passive environments. To further enhance safety and performance, the proposed scheme incorporates online energy injection and freezing mechanisms. When the tank&#8217;s energy level falls below a preset threshold, additional energy is injected to improve control performance. Conversely, when the exerted wrench exceeds specified limits, the control system reverts to a constant admittance model to maintain compliance, effectively freezing any additional energy extraction. Two activation functions are also developed to ensure precise positioning in the direction of position control. The effectiveness of the proposed approach is validated through real industrial robot applications in aircraft assembly tasks. Experimental results demonstrate its superiority in improving both task performance and operational safety.</description></item><item><title>Minimum-Spacing Optimized Winding Switching Control for Winding-Segmented PMLSM With Multiple Movers</title><link>http://ieeexplore.ieee.org/document/11220838</link><description>The winding-segmented permanent magnet linear synchronous motor (WS-PMLSM) system adopts a modular mover-stator topology, offering advantages such as high load capacity and high-precision positioning. Traditional strategy typically employs a synchronous current drive method for dual-stator units, which mandates the minimum spacing of multiple movers exceeding the length of two stator units. To minimize the spacing constraints between the movers, this article proposes an optimized stator winding switching control strategy based on single/dual-stator winding drive modes. First, an analytical electromagnetic thrust model of WS-PMLSM is established based on the magnetic energy principle. Second, for the single-stator winding drive mode, a current feedforward control strategy is proposed to compensate for the electromagnetic force disturbance between adjacent segments. Furthermore, based on the coupling length between the mover and stator windings, an optimized winding switching strategy with linear transition switching method is proposed to reduce the thrust ripple. Finally, a WS-PMLSM experimental platform is built to validate the effectiveness of the proposed control strategy.</description></item><item><title>Model-Free Energy Flow Regulation Passivity-Based Control for Robotic Rotary Joints With Data-Driven Surrogate Model</title><link>http://ieeexplore.ieee.org/document/11215801</link><description>Passivity-based control (PBC) is a powerful control strategy, excelling in stability through its energy-based framework. It is regarded as an effective method for enhancing the dependability of robotic rotary joints (RRJs). However, as a fundamentally model-based control method, PBC&#8217;s effectiveness heavily relies on accurate system modeling and parameter estimation. Consequently, its control performance is significantly degraded in RRJs, which exhibit complex nonlinear dynamics complicate parameter identification and frequently lead to parameter mismatches between theoretical models and physical systems. To address this limitation, this article presents a novel energy flow regulation-PBC (EFR-PBC) methodology. Leveraging the system&#8217;s polynomial characteristics, EFR-PBC incorporates a data-driven recursive polynomial response surface (RPRS) surrogate model to predict energy flow tensor (EFT) variations from input-output measurements, facilitating adaptive control law synthesis. By reducing dependence on precise mathematical models and system parameters, EFR-PBC maintains robust performance under uncertain conditions. Extensive comparative studies through both numerical simulations and experimental validations against conventional interconnection and damping assignment (IDA)-PBC and PID-PBC implementations demonstrate the effectiveness and superior performance of the proposed method.</description></item><item><title>Variable Symmetry Constraints-Based Stability Analysis of Large Delayed Cyber-Physical Power System</title><link>http://ieeexplore.ieee.org/document/11216358</link><description>Linear matrix inequality (LMI)-based delay-dependent stability analysis methods have been effectively utilized in the delayed cyber-physical power system (DCPPS). However, the significant computational burden associated with solving large-scale LMIs presents a substantial challenge when these methods are applied to real-world power systems. This article investigates an efficient evaluation method for the delay-dependent stability of the large DCPPS by presenting a variable symmetry constraints-based approach. First, by exploring the highly symmetric characteristics of control loops and renewable energy sources (RES), this article gives new structure restrictions for the weighting matrices required in the LMI-based stability criterion to reduce the number of decision variables (NDVs). In contrast, the existing methods focus only on the symmetric characteristics of traditional generators and are not applicable to large DCPPS integrated with the RES. Then, by introducing an adjustable parameter into the proposed structure restrictions, the approach based on variable symmetry constraints is established to bridge the gap where the existing constant methods fail to address the variable stability conditions. Moreover, the proposed variable symmetry constraints-based approach is more relaxed than the existing method since it keeps the NDVs in the LMIs unchanged despite massive generators equipped in the same control area of the DCPPS. Case studies are based on the large DCPPS with illustration of the load frequency control (LFC) schemes and the 39-Bus New England System to demonstrate the superiority of the proposed method. The proposed method is verified to be available to analyze the delay-dependent stability of the large-scale DCPPS efficiently while guaranteeing the computation accuracy.</description></item><item><title>High-Precision Nonlinear Spatial Gradient Disturbance Suppression Method for Magnetic Shielding Cylinder</title><link>http://ieeexplore.ieee.org/document/11220881</link><description>High-power devices used in hospitals generate harmonic magnetic field disturbances inside magnetic shielding cylinders (MSCs). These disturbances exhibit axial-gradient spatial distributions, which substantially degrade the imaging quality of magnetocardiography (MCG). To address this issue, a high-precision nonlinear spatial gradient disturbance suppression method is proposed for single-open MSCs. First, a nonlinear gradient coil design is developed to generate variable magnetic field gradients, precisely matching the nonlinear gradient distribution induced by external magnetic disturbances in the MSC. Subsequently, the entire system is modeled, and a composite controller based on proportional-integral repetitive control-linear extended state observer (PIRC-LESO) is designed to enhance the suppression of magnetic field disturbances with harmonic characteristics. Finally, an active magnetic field disturbance suppression system was implemented to evaluate the effectiveness of the nonlinear spatial gradient disturbance suppression method. Experimental results demonstrate that the proposed method reduces the peak-to-peak magnetic field disturbance from 42.0 to 6.9 pT and significantly enhances the signal-to-noise ratio of the MCG signals.</description></item><item><title>Revisit Windup Phenomenon in Grid-Forming Inverters With Priority Current Limiter: A Physical Perspective</title><link>http://ieeexplore.ieee.org/document/11220825</link><description>This article investigates the windup phenomenon of grid-forming (GFM) inverters with priority current limiters (PCL). It is found that a crucial transitional stage exists in both the PCL triggering and exit processes, which significantly impacts the windup issue. By analyzing the phasor diagrams and power-angle curves of the GFM inverter, it is revealed that the fault clearance angle and switching angle between the transitional stage and stable stage in current-limiting mode jointly determine the existence of windup after fault clearance. A criterion is developed based on these findings. Further, four distinct scenarios are examined in light of this criterion and transitional stage. A practical antiwindup control method based on the criterion is proposed. Finally, the theoretical findings are demonstrated through experiments.</description></item><item><title>DC Link Capacitance Minimizing Set of Type-II Voltage Controller Coefficients for PFC Rectifiers</title><link>http://ieeexplore.ieee.org/document/11217337</link><description>The brief presents a method for deriving a type-II voltage controller coefficients set allowing to minimize the dc link capacitance in single-phase active power factor correction rectifiers (PFCR) operating without hold-up time requirements. The proposed methodology considers grid current quality and dc link voltage loop stability constraints as well as system response to a step-like zero-to-rated load power variation. Design guidelines for deriving the optimal coefficients set and corresponding minimum capacitance value are provided by means of combined time and frequency domain analysis. The findings are accurately supported by simulations and experiments.</description></item><item><title>Active Ripple Suppression Technique Based on Digital Dead-Beat Average Current Control and Load Current Feed-Forward for IGBT and GaN Hybrid Half-Bridge Circuit in Fractional Power Processing Mode</title><link>http://ieeexplore.ieee.org/document/11217338</link><description>The insulated gate bipolar transistor (IGBT) and gallium nitride (GaN) hybrid half-bridge (HHB) circuit operating in fractional power processing (FPP) mode combines the advantages of silicon devices and wide bandgap devices to achieve the optimal tradeoff among efficiency, power quality, and cost. However, due to the fact that the load transient response of HHB circuit depends on the IGBT branch with lower switching frequency, the system load transient response is poor. To overcome this issue, an active ripple suppression technique based on digital dead-beat average current (DBAC) control and load current feed-forward for both IGBT branch and GaN branch in the HHB circuit is proposed in this letter. The operating principle and control law of proposed control for the HHB circuit in FPP mode are analyzed in detail. The load transient performance of the HHB circuit is further investigated. Finally, experimental results of the active ripple suppression technique for the IGBT and GaN HHB circuit are provided to verify the correctness of the theoretical analysis.</description></item><item><title>Interpretable Wind Power Forecasting With Feature and Loss Function Construction Guided by Domain Knowledge</title><link>http://ieeexplore.ieee.org/document/11122909</link><description>Current wind power forecasting (WPF) methods predominantly rely on data-driven deep learning models, inherently lacking integration of domain knowledge, which limits forecasting accuracy and model interpretability. To address this issue, an interpretable data-knowledge fusion ultra-short-term WPF model is proposed, in which domain knowledge guides the feature construction process and is directly embedded into the design of the loss function. In the feature construction module, a wind speed-power curve is established to generate theoretical power outputs by using historical wind speed as inputs. These theoretical outputs, combined with historical measured data, serve as inputs for the model. In the loss function construction module, a boundary constraint loss is designed by extracting the upper and lower boundaries of wind power output using the alpha shape algorithm and Local Weighted Linear Regression based on wind speed and power data. Notably, the parameters of boundaries are dynamically updated to capture the volatility of wind power. Additionally, an error distribution shape loss is introduced to penalize the deviation of the training error distribution from the normal distribution, using Jensen-Shannon divergence as an indicator. Case studies across 30 wind farms demonstrate that the proposed method guided by interpretable knowledge achieves the best average performance across all time horizons compared to baseline models. The method also shows strong robustness in noise and missing data experiments.</description></item><item><title>Novel Unified Control Framework for Networked RES-BES Microgrids With Enhanced Performance</title><link>http://ieeexplore.ieee.org/document/11120450</link><description>The increasing deployment of renewable energy sources (RESs) facilitates the interconnection of distributed energy networks, thereby maximizing the utilization of the unevenly distributed RESs. Networked hybrid ac/dc microgrids enable regional multi-terminal networks at end-user sites, offering plug-and-play integration for RESs and battery energy storage systems (BESs) through synergistic ac/dc complementarity. However, this interconnected configuration introduces increased complexity in control strategies and poses significant power management challenges for RES-BES microgrids, as sudden RES fluctuations demand system-wide BES compensation to prevent local overloads. This paper proposes a unified droop control-based framework for networked hybrid microgrids comprising RESs, BESs and loads. The proposed approach enables seamless transitions between operational modes, proportional power sharing, and enhanced operation without circulating currents or overstressing components. Furthermore, it inherently addresses abrupt source failures and asymmetric line faults without requiring adjustments in the primary control methods, ensuring uninterrupted maximum power harvest of RESs. The effectiveness of the proposed approach is validated through case studies using real-time simulation platform Typhoon-HIL.</description></item><item><title>Time-Varying Inertia Characterization of DFIG-Based Wind Turbines for Power System Frequency Dynamic Analysis</title><link>http://ieeexplore.ieee.org/document/11113495</link><description>Accurately assessing the inertial response of renewable energy generation (REG) is critical for frequency stability. However, REG represented by doubly-fed induction generator (DFIG)-based wind turbine (WT) exhibits inherent time-varying inertia behavior, fundamentally distinct from synchronous generators (SGs). Prevailing inertia assessment methods predominantly rely on SG-derived time-domain inertia constants, which cannot capture this intrinsic variability. Consequently, the rationality of directly applying these conventional methods to DFIG-based WT lacks theoretical justification. To address this gap, this paper derives an expression for calculating time-varying inertia using the angular momentum theorem. Results demonstrate that inertia in the time domain dynamically varies with disturbances, highlighting the significant limitations of conventional inertia descriptions. Alternatively, a frequency-domain inertia characterization method is investigated to provide a disturbance-independent description of inertia, effectively capturing its intrinsic time-varying nature. Due to the duality between time and frequency domains, this paper mathematically describes the relationship between frequency-domain inertia and time-domain inertia, explicitly clarifying the physical meaning of inertia in the frequency domain. Simulations on an IEEE 39-bus system verify that the frequency-domain inertia method accurately captures inertia dynamics and is suitable for frequency stability analysis. These findings emphasize frequency-domain inertia characterization as an essential method for representing inertia in renewable-rich power systems.</description></item><item><title>Wind Turbulence-Induced Power Fluctuations Mitigation in PMSG-Based Wind Turbines by a Coordinated Control Scheme</title><link>http://ieeexplore.ieee.org/document/11106269</link><description>Power fluctuations in large-scale wind turbines (WTs), induced by persistent wind turbulences, can degrade the reliability of power modules and increase mechanical stress on light-strength structural components. These issues entail intricate challenges for system operators in terms of operation and maintenance. This paper investigates specifications of power fluctuations in PMSG-based WTs and presents a control scheme advantageous both below and above the rated wind speed, without requiring additional energy storage devices. This work strives to bridge the gap between the complicated art of WT modeling and wind turbulence-induced power fluctuations aiming to reveal the origin of power fluctuations in terms of operating regions and control strategies. In the proposed control scheme, the power fluctuations are mitigated without any auxiliary control terms below the nominal wind speed. Above the nominal wind speed, the power smoothing action is performed via three items, in which the machine side converter (MSC) virtually regulates the rotor inertia, the grid side converter (GSC) exerts the damping component, and the pitch control system helps enhance the damping mechanism. The feedback gains of the auxiliary terms are optimized while considering their interactions. Simulation results illustrate that the proposed control scheme effectively mitigates both the electrical and mechanical oscillations.</description></item><item><title>Incorporating Frequency Security Constraints in Two-Stage Robust Unit Commitment of Integrated Transmission and Distribution System</title><link>http://ieeexplore.ieee.org/document/11098731</link><description>With the integration of high-proportion renewable energies, the independent operation of the transmission and distribution systems (T&amp;amp;DSs) makes it difficult to achieve optimal scheduling and ensure frequency security. Therefore, this paper proposes a two-stage robust frequency-constrained unit commitment (TRO-FCUC) model of T&amp;amp;DS. Firstly, the impacts of distributed energy resources (DERs) frequency regulation capabilities on inertial response and primary frequency response (PFR) are considered, and dynamic frequency constraints considering the cooperation of thermal units, wind farms, and DERs with their inertia-based frequency reserve are constructed. Then, the TRO-FCUC model is formulated to address uncertainties of wind farms (WFs) and distributed photovoltaics (DPVs) based on uncertainty sets. Further, the column and constraint generation (C&amp;amp;CG) algorithm and strong duality theory are utilized to transform the TRO-FCUC model into a mixed-integer second-order cone programming (MISOCP) model and then solve it iteratively. Finally, case analyses proposed demonstrate that the coordinated operation of T&amp;amp;DS can fully mobilize the frequency regulation potential of DERs and improve the operation&#8217;s economy while ensuring the frequency security of the system.</description></item><item><title>Novel Series-Isolated-Parallel Wind Farm DC Collection System With New Control Strategies</title><link>http://ieeexplore.ieee.org/document/11105057</link><description>Offshore wind farm (WF) DC collection systems offer significant reductions in weight and size compared to conventional AC systems. Among DC architectures, the series-parallel wind farm (SP-WF) configuration achieves higher efficiency by reducing the number of power conversion stages. However, because SP-WF places the DC-DC converter upstream of the series connection of wind turbines (WTs), it suffers from reduced reliability due to its vulnerability to DC short-circuit faults within the series string. This paper proposes a novel series-isolated-parallel wind farm (SIP-WF) architecture that enhances reliability by integrating a DC-DC converter to isolate each group of series-connected WTs. This isolation provides intrinsic DC fault blocking capability without the need for external DC circuit breakers. Furthermore, as only passive rectifiers are used at each individual WT, the proposed SIP-WF architecture maintains high efficiency. To manage maximum power point tracking (MPPT) across turbines experiencing different wind conditions, two new centralized control strategies are proposed to coordinate multiple WTs using a single DC-DC converter per group. The proposed SIP-WF architecture and control strategies are validated through simulations in MATLAB/Simulink. A comprehensive performance comparison is conducted against existing DC collection topologies. The results demonstrate that SIP-WF achieves a higher net energy yield while reducing cost, system weight, and volume, and offering superior fault tolerance compared to conventional architectures.</description></item><item><title>Fault Ride-Through Strategy for Grid-Forming Converters Satisfying Multi-Objective Constraints</title><link>http://ieeexplore.ieee.org/document/11091548</link><description>Transient synchronization stability (TSS), current limitation and reactive power support (RPS) are the key objectives for fault ride-through (FRT) that grid-forming converters (GFMCs) must satisfy. However, the complex coupling restraints among these objectives, along with the fact that GFMC cannot directly control current due to its voltage-source nature, present significant challenges for FRT. To address these issues, this paper first analyzes the coupling relationships among the three objectives, and reveals the formations and control mechanisms of phase current, reactive current, and fault inrush current in GFMC. Inspired these insights, an adaptive FRT strategy is designed by cooperatively adjusting the active power and voltage references, as well as the adaptive virtual resistance, which satisfies FRT multi-objective constraints even if the voltage sags to 0. And it is straightforward to implement. Furthermore, the proposed FRT strategy is shown to exhibit superior TSS and RPS performance, as demonstrated through region of attraction and voltage phase portraits. Finally, simulation and experiment results validate the effectiveness and superiority of the proposed FRT strategy.</description></item><item><title>Transient Stability Analysis of MMC-HVDC Connected DFIG-Based Wind Farms in the Electromechanical Timescale</title><link>http://ieeexplore.ieee.org/document/11106276</link><description>This paper investigates the transient stability of doubly-fed induction generator (DFIG)-based wind farms connected via a modular multilevel converter (MMC)-based high-voltage direct-current (HVDC) transmission system in the electromechanical timescale. During faults, the MMC tends to be switched to the current-limiting mode, which further interacts with the control systems of DFIG-based wind farms, thereby complicating the transient stability problem. In this paper, a large-signal model is constructed for transient stability analysis under this condition. The transient stability mechanism is revealed, and a transient stability index that considers the impact of a phase-locked loop in the electromechanical timescale is derived. The proposed index quantitatively assesses the instability risk arising from the coupled interaction between the DFIG-based wind farms and the MMC. In addition, the impacts of the current- limiting mode and other parameters (i.e., speed control loop gains, rotor shaft damping, inertia coefficient and fault location and severity) are analyzed. Based on the results of the parametric analysis, a suite of targeted countermeasures is proposed to enhance the transient stability of the power system. Finally, a theoretical analysis is demonstrated and verified through hardware-in-the-loop simulations using the Modeling Tech microgrid real-time simulation platform.</description></item><item><title>A Quantitative Accommodation Guaranteed Robust Scheduling Method for Renewable Power System With Dynamic Uncertainty Set</title><link>http://ieeexplore.ieee.org/document/11090046</link><description>Wind power generation (WPG) has been increasingly integrated into power systems to reduce carbon emissions. However, its inherent volatility and stochasticity have significantly challenged the reliable system operation and effective accommodation. In this paper, a robust scheduling method with a quantitative accommodation guarantee for power systems with WPG integration is proposed. First, a dynamic uncertainty set (DUS) of WPG is introduced, and a stochastic accommodation rate (SAR) indicator is accordingly proposed and derived to quantify the attainable accommodation level. Based on the DUS, a robust scheduling method is proposed, in which the implicit affine strategy (IAS) is adapted to guarantee the nonanticipativity of scheduling strategies. Moreover, a SAR constraint is carefully built according to the assessment result of the power system&#8217;s maximal and minimal SAR and embedded into the scheduling model to provide a quantitative accommodation guarantee. An illustrative case is presented to validate the effectiveness of the SAR indicator. Numerical simulations in the modified 6-bus, 14-bus, and 118-bus power systems validate the superiority of the proposed scheduling method.</description></item><item><title>Current Control and DC Capacitor Dynamic Interaction in a Cross-Timescale Manner in DFIG-WT Dominated Power Systems</title><link>http://ieeexplore.ieee.org/document/11088231</link><description>The Doubly-Fed Induction Generator (DFIG) based wind turbine (WT) contains control loops and energy storage components operating across multiple timescales, leading to potential cross-timescale influence dynamics in DFIG-WT-dominated power systems. Previous analyses have primarily focused on single timescale dynamics or the interactions between control loops at different timescales, with limited attention given to the cross-timescale influences between control loops and energy storage components. This paper aims to reveal the cross-timescale influence mechanism of current control at the AC-current-control timescale on the dynamics of the DC capacitor at the DC-voltage-control timescale. Modal analysis is a mature method used to uncover the cross-timescale influence phenomena and laws of current control on the dynamics of the DC capacitor. Subsequently, an equivalent circuit model is established to analyze the mechanism by which current control affects the dynamics of the DC capacitor. Finally, the conclusions are validated through simulations based on a four-machine two-area power system and the power grid of Northwest China.</description></item><item><title>Rapid Active Power Regulation of Distributed Photovoltaics Based on Optimal Dynamic Droop Coefficients</title><link>http://ieeexplore.ieee.org/document/11095309</link><description>To realize the active response for rapid active power regulation of massive distributed photovoltaics (DPVs), a bi-level architecture integrating clustering and optimization is proposed for the coordinated design of dynamic droop coefficients of DPVs in this paper. At the lower level, the adjustable capacity and response time are selected as clustering features according to the rapid active power regulation requirements, and the U-k-means algorithm is applied to implement the clustering of DPVs. At the upper level, a frequency deviation-optimal droop coefficient model incorporating the regulation performance and network losses is developed in a perspective that considers power flow impacts. The droop coefficient regulation strategy under various frequency fluctuations is pre-calculated by a graph attention network (GAT). Simulations are performed on a modified IEEE 33-bus test system, and the results verify the outperformance of the proposed GAT model over the existing neural network models, as well as the effectiveness and superiority of the proposed optimal droop coefficient regulation strategy.</description></item><item><title>Real-Time Energy Management of Hybrid Energy Storage System With Application to Wave Energy Converters: A Learning-Augmented MPC Strategy</title><link>http://ieeexplore.ieee.org/document/11090041</link><description>Integrating hybrid energy storage systems (HESSs) into wave energy converters (WECs) can mitigate power fluctuations of WECs across multiple timescales, provided that an effective energy management strategy (EMS) is implemented. Model predictive control (MPC) is the mainstream EMS for HESSs, as it typically yields a control solution close to the global optimum while satisfying constraints. However, MPC faces a high computational burden when the optimal control problem is nonlinear. More importantly, considering multiple competing objectives, tuning weighting factors (WFs) in the MPC cost function is also challenging. To tackle these challenges, this article proposes a learning-augmented MPC strategy to optimize energy management for the HESS in WECs. The strategy first utilizes a fuzzy logic-based asymmetric action trimming technique to reduce MPC computational time. Further, a warm-start Q-learning (QL) framework with high learning efficiency is applied to obtain the WF online tuning method. To bridge the simulation-to-reality gap in the QL framework, the article designs a neural network-based current predictor, aiming to sense the nonlinear power loss during power conversion. Finally, simulations and experiments demonstrate the superior performance of the proposed strategy in reducing energy loss, battery degradation, and MPC computational burden.</description></item><item><title>Spatio-Temporal Probabilistic Forecasting of Wind Speed Using Transformer-Based Diffusion Models</title><link>http://ieeexplore.ieee.org/document/11091547</link><description>Spatio-temporal wind speed forecasting plays a crucial role in enhancing energy conversion efficiency and optimizing resource allocation, forming a cornerstone of sustainable development. However, existing methods for spatio-temporal wind speed forecasting face challenges in capturing intricate spatio-temporal dependencies and adapting to dynamic variations in wind speed data. To address these limitations, we propose the Probabilistic Spatio-Temporal Diffusion Transformer (PSTDT), a novel model that combines the generative power of denoising diffusion probabilistic models with the robust spatio-temporal modeling capabilities of Transformers. This approach introduces a dual-spatial attention module to model static positional relationships and dynamic dependencies from historical data, thereby capturing evolving spatial correlations. Additionally, PSTDT integrates a dual-phase temporal module for modeling cross-period temporal dependencies alongside auto-regressive temporal features, enhancing its capacity to address the complexities of time-series forecasting. Furthermore, a temporal-adaptive layer normalization is incorporated to dynamically adjust normalization parameters, improving the model&#8217;s forecast accuracy and stability. Extensive experiments demonstrate that PSTDT outperforms state-of-the-art methods across multiple datasets, reducing continuous ranked probability score by 8% &#8211;20% and mean absolute error by 7% &#8211;19% .</description></item><item><title>End-to-End Collaborative Optimization for Active Distribution Network Power Dispatch Based on Sparse Model-Ensemble Learning Policy</title><link>http://ieeexplore.ieee.org/document/11119768</link><description>With the higher penetration of distributed renewable power sources, novel active distribution networks are increasingly implementing flexible adjustment strategies. Currently, the dual uncertainties from both sources and demand significantly affect power dispatch in distribution networks. Typically, power dispatch is performed using a predict-then-optimize approach, making it challenging to quantify the gap between the real-time and theoretically optimal dispatch performances due to inaccuracies in power predictions. Hence, this study introduces a novel end-to-end policy to solve a collaborative optimization between prediction and dispatch. The policy directly utilizes all available information, such as gridded numerical weather forecasts, for dispatch decision-making, which eliminates the need for power predictions as intermediate variables for dispatch. To address the challenges of high-dimensional and open-scenario model training in end-to-end policies, sparse model-ensemble learning is proposed to formulate the dispatch policy model. The model is solved using constrained policy optimization. Comparative studies show that the proposed end-to-end policy outperforms the predict-then-optimize policy in real-time dispatch cases involving photovoltaic reactive power ancillary service and demand response within distribution networks.</description></item><item><title>LPV Model Predictive Control for Offshore Wind Farms Considering Wake Delay Characteristics</title><link>http://ieeexplore.ieee.org/document/11082107</link><description>The pronounced wake effect in large-scale offshore wind farm necessitates careful consideration of its delay characteristics, which are crucial yet often overlooked in control. Addressing the coupling between the dynamic evolution of wake effects and the parameter changes of the WT control model, this paper introduces a Linear Parameter-Varying (LPV) model predictive control method that considers wake delay characteristics. Through the development of a quasi-steady state wake model, the wake delay characteristic is incorporated within an LPV model for the wind farm. A two-stage dimensionality reduction method is proposed to simplify the calculation, and a model predictive control (MPC) method is combined to optimize the fatigue damage balance and power generation enhancement in the wind farm coordinately. Simulation results from a wind farm consisting of 16 wind turbines validate the efficacy of the quasi-steady state wake model in depicting the spatial distribution of wake delays. Furthermore, in dynamically varying wind speed and directions scenarios, the proposed control method can effectively capture the wind speed delay and fluctuation characteristics between different wind turbines, leading to heightening power output and diminishing fatigue stresses. Notably, in comparison to the static model control, the adaptive parameter tuning mechanism inherent in the proposed method effectively curtails control overshoot, enhancing overall system performance.</description></item><item><title>Fast Frequency Response in Low Inertia Grids via Integrated Supercapacitor Energy Storage Systems and Wind Turbine Generators</title><link>http://ieeexplore.ieee.org/document/11082652</link><description>The increasing penetration of inverter-based resources in modern power systems has led to a significant reduction in system inertia, creating challenges for maintaining grid frequency stability. To address these issues, a new ancillary service market, termed &#8220;Fast Frequency Response (FFR)&#8221;, has emerged. FFR mandates rapid power delivery from renewable energy sources,including wind power systems, immediately following contingency events to alleviate frequency drops in a few seconds. This paper presents a control method combining supercapacitor energy storage systems and wind turbine generators to enhance the FFR capabilities of wind power systems and mitigate the frequency drop. This approach ensures the readiness of supercapacitor energy storage systems to provide FFR services under diverse wind conditions. Additionally, a control scheme for the wind turbine generator is developed to optimize its participation in FFR across a range of wind speeds while maintaining a stable operation of the wind power system. The results demonstrate that, while preserving an equivalent investment cost to that of supercapacitor banks, wind power systems can significantly increase their FFR contributions. This improvement effectively addresses critical frequency stability challenges in low-inertia grids. Eventually, the proposed method is validated through real-time experiments on a hardware-in-the-loop (HIL) setup.</description></item><item><title>Dynamic Evolution and Stability Analysis of GFM-Based Renewable Energy Resources Considering Repeated &amp; Continuous Current Saturation</title><link>http://ieeexplore.ieee.org/document/11079878</link><description>The current saturation (CS) strategy of grid-forming renewable energy sources (GFM-RESs) is designed to protect the device from overcurrent damages. However, the potential switching processes of control strategies trigger new stability issues. It is revealed that two emerging stability issues, i.e., repeated current saturation (R-CS) and continuous current saturation (C-CS) governed by the inherent inconsistency of switching conditions, will occur when the system operates into the corresponding virtual power angle (VPA) region. This paper adopts the hybrid system theory to analyze such stability issues by deriving the necessary and sufficient switching conditions of current saturation and desaturation. During R-CS, the GFM-RES externally behaves as an abnormal current source, triggering adverse high-frequency oscillations. When subject to C-CS, the system will suffer from persistent overvoltage issues and cannot return to its initial operating point. To identify the stability risks of these two issues and offer guidance for GFM-RES&#8217;s controller design, a novel R&amp;amp;C-CS criterion, along with a generic desaturation region-based (DRB) principle, is proposed. Meanwhile, a switching condition and dynamic characteristic decoupling control (S&amp;amp;D-DC) is developed based on the DRB principle to prevent the R&amp;amp;C-CS issues. High-fidelity electromagnetic transient simulations conducted on both single-machine and multi-machine systems validate the theoretical derivations and proposed control strategy.</description></item><item><title>Interpretable Augmented Ambiguity Set for Quantifying Regional Wind Power Uncertainty in Distributionally Robust Optimal Dispatch</title><link>http://ieeexplore.ieee.org/document/11082100</link><description>A large-scale grid penetration of wind power has posed severe uncertainty challenges for power system operation. This paper comes up with an interpretable augmented ambiguity set assisted by deep learning for two-stage economic dispatch formulated in a distributionally robust optimization, aiming at precisely representing regional wind power uncertainty. The specifically designed augmented ambiguity set is driven by both the fine-grained uncertainty model of each wind farm and interactive dependencies among different sites. In particular, a multi-teacher knowledge distillation-time generative adversarial network (MKD-time GAN) is presented for the first time to form a spherical ambiguity set gathering all possible distributions for power prediction error of single wind farm. This model leverages a cascaded learning framework by typical teacher-time GANs to jointly educate one general student-time GAN so as to induce a family of comprehensive reference distributions as an ambiguity set. Further, multiple ambiguity sets are mapped into augmented ambiguity set, an interdependent joint probability distribution space for regional prediction error by Nataf transformation. Based on that, a tractable solution algorithm of two-stage optimal dispatch is explicitly derived and saves computation scale. The benefits of both novel MKD-time GAN and decision-making dispatch schemes are demonstrated in IEEE 118-bus systems.</description></item><item><title>Tri-layer Distributed Scheduling for Coastal Integrated Transmission-Distribution-Gas System With Uncertain Typhoons-Affected Offshore Wind Power</title><link>http://ieeexplore.ieee.org/document/11075623</link><description>This paper addresses the scheduling challenges associated with offshore wind power within coastal power systems during uncertain typhoons. The proposed tri-layer chance-constrained coordinated scheduling model differs from existing formulations through two major innovations. First, unlike the deterministic scheduling under forecasted typhoons, it implements a scenario-based stochastic programming to address the wind power deviations resulting from the typhoon uncertainties, while additionally factoring in the potential damage to wind turbines. Second, moving beyond the isolated scheduling of thermal units in the transmission network, the proposed model enables a distributed coordination of diverse flexible resources across the distribution and gas networks to mitigate typhoon damage, resulting in a more complex tri-layer scheduling framework. These advancements introduce marked challenges for model solution. To handle this, a mix-sample average approximation method is introduced to reformulate the original random variables involved model into a tractable linear form. Moreover, a novel efficient distributed solution methodology is proposed to tackle the specific nested interactions within the tri-layer scheduling framework. Case studies verify the economic and reliability advantages of the proposed model, with 20.2% average cost saving and over 90% decrease in imbalanced power, as well as the computational superiority of the proposed distributed solution for significantly reduced solution time.</description></item><item><title>A Two-Stage Ultra-Short-Term Wind Power Forecasting Method Based on Transitional Weather Identification and Meteorological Prediction Error Propagation</title><link>http://ieeexplore.ieee.org/document/11078806</link><description>Accurate and reliable wind power forecasting is crucial for the safe and economical operation of power systems. However, under transitional weather conditions, the forecasting errors of meteorological variables such as wind speed tend to increase, introducing significant input noise into wind power prediction models and reducing their reliability. To address this, this paper focuses on analyzing the error propagation mechanism of meteorological input variables and proposes a strategy to improve short-term wind power forecasting accuracy under transitional weather conditions. First, transitional weather periods are identified by analyzing the fluctuation characteristics of multi-dimensional meteorological variables. Then, a two-stage model combining Sparse Variational Gaussian Process (SVGP) and Noisy Input Gaussian Process (NIGP) is proposed. In this model, noisy input data (wind speed predictions) are decomposed into true data (actual wind speed) and noise data (forecast errors), which are modeled independently. By considering the propagation process of input noise in wind power forecasting and making necessary corrections, the SVGP-NIGP model provides more accurate deterministic forecasts and higher-quality interval predictions. Experimental results show that the proposed method significantly enhances wind power forecasting accuracy under transitional weather conditions, offering an effective solution to address the uncertainties arising from meteorological forecasting.</description></item><item><title>Self-Optimizing Local Voltage Control of SOP in Active Distribution Networks Based on Lift-Dimension Mapping Linearization</title><link>http://ieeexplore.ieee.org/document/11072306</link><description>The high penetration of distributed generators (DGs) deteriorates the voltage violations in active distribution networks (ADNs). Owing to the flexible adjustment capacity, the local power regulation provided by soft open point (SOP) presents a promising solution for eliminating voltage violations in ADNs. A data-driven local control method can fully excavate the potential logic from operational data without requiring precious network parameters. However, the training data may be insufficient in practical applications. In this paper, a self-optimizing local voltage control method for SOP is proposed to achieve adaptive control in label-poor conditions. First, a SOP local control model is constructed based on lift-dimension mapping linearization (LDML), which portrays the complex relationship between ADN states and SOP control strategies. Subsequently, a self-optimizing guidance mechanism is established to obtain the label data of SOP control strategy, which provides a large number of training samples for the local control model. Finally, the effectiveness of the proposed method is validated using a practical distribution network with a four-terminal SOP. Results demonstrate that efficient control strategies can be determined based on local state measurements. A rapid response to DG fluctuations can be achieved while enhancing the adaptability to variations in practical operations.</description></item><item><title>A Novel Optimized Parameter Tuning Algorithm for Wind Turbine Grid-Forming Control to Mitigate Power Oscillations</title><link>http://ieeexplore.ieee.org/document/11068198</link><description>As the transition from synchronous generators (SGs) to renewable energy sources (RESs) accelerates, grid forming wind turbines (GFM-WTs) are increasingly expected to play a critical role in maintaining power system stability. However, the integration of GFM without thoroughly considering the interaction between the outer and inner control loops can induce power oscillations. Therefore, this paper offers a systematic sensitivity analysis to explicitly reveal how the control parameters contribute to power oscillations in the GFM-WT system. This analysis is based on a linearized state-space model for the GFM-WT system, incorporating comprehensive system dynamics and control strategies. Furthermore, an optimized control algorithm is developed based on a comprehensive small-signal model, incorporating essential constraints such as the eigenvalue damping ratio and the control loop bandwidth. The algorithm autonomously tunes the control parameters of both the inner and outer loop systems, resulting in optimal parameter values. A comprehensive stability analysis was conducted to validate the effectiveness of the proposed algorithm in ensuring system stability. The proposed method is verified through various scenario in modified WSCC 9-bus and New England 39-bus systems. Simulation results indicate that the proposed algorithm effectively mitigates power oscillations in the WT output, subsequently reducing power oscillations in the SG.</description></item><item><title>Deterministic and Probabilistic Forecasting of Wind Power Generation and Ramp Rate With Expectation-Implemented Deep Learning</title><link>http://ieeexplore.ieee.org/document/11068153</link><description>Accurate day-ahead forecasting of wind power generation, both deterministically and probabilistically, is crucial for reliable and efficient power system operations, and its significance will increase in renewable energy-dominant power systems. Furthermore, inherent variability of wind farms necessitates day-ahead ramp rate forecasting to ensure stable energy balancing. To address these needs, we propose an hourly day-ahead forecasting framework that concurrently predicts the wind power generation and ramp rate. This framework leverages expectation-implemented deep learning models trained by the custom loss functions tailored to the different signal attributes and our distinct expectations. Additional strategies, such as feature generation and a feedforward error learning model, are implemented to enhance forecasting performance while maintaining a balance between tasks. Finally, our framework integrates heterogeneous generation and ramp rate forecasting results, incorporating probabilistic ramp rate forecasting derived from the synthesized output. We validate our approach using real wind power data and assess the impact of each proposed method individually. The results demonstrate that the proposed framework can significantly contribute to identifying the intrinsic volatility of wind power, thereby fully exploiting its potential benefits.</description></item><item><title>Optimal BESS Management for Peak Load Shaving and Battery Health Under Prediction Uncertainty</title><link>http://ieeexplore.ieee.org/document/11071638</link><description>In modern power grids, integrating renewable energy sources (RESs), deploying battery energy storage systems (BESSs) is increasingly vital for mitigating power fluctuations. However, optimizing BESS operation remains challenging amidst uncertainties in both RES and load forecasting. This paper proposes a novel stochastic model predictive control (SMPC) framework for BESS operation, focusing on peak load shaving and battery health while addressing prediction uncertainties. The proposed framework employs a long short-term memory (LSTM) neural network for forecasting and integrates a constraint-tightening technique into a stochastic optimization (SO) problem with a receding horizon. Based on the load profile of a company in Germany, the proposed framework achieves an additional reduction of 99 kW (5.8%) in peak grid take-out power compared with the traditional model predictive control (MPC) approach, demonstrating its advantage in addressing uncertainties.</description></item><item><title>PMU-Based Power Oscillation Damping Control for Renewable Energy System With Communication Disruption and Multi-Time Delays</title><link>http://ieeexplore.ieee.org/document/11071336</link><description>This paper presents a novel model-free power oscillation damping strategy for renewable energy (RE) system considering communication disruption and multiple time delays in control loops. First, a multivariate Ornstein-Uhlenbeck (OU) process-enabled online estimation method is developed for state-space modeling estimation only using measurement data. This estimation method is applicable to systems with different delays in each wide-area control loop. Subsequently, a novel wide-area power oscillation damper (POD) is designed for the renewable energy sources (RESs) and that is further reconstructed in a decomposition manner to achieve independently sub-control, which allows to retain better damping performance under communication disruption. After that, the POD parameter settings are carefully tuned, where the time delay and estimation error are considered, formulated as stability constraints using Razumikhin theorem, and solved via linear matrix inequality (LMI), yielding multi-dimensional robustness of the system, including operating conditions, time delay and communication disruption. Case studies in the improved 4-machine 2-area system and IEEE 39-bus system show that the proposed method can accurately estimate the state-space modeling of closed-loop system and effectively dampen power oscillations in time delay and communication disruption scenarios.</description></item><item><title>A Unified Method for Assessing Frequency Support Capability of Diverse Renewable Power Generation Units</title><link>http://ieeexplore.ieee.org/document/11061796</link><description>The proliferation of renewable power generation units (RGUs) deteriorates the physical inertia of the system, making the evaluation of unit-level frequency support capability (FSC) and system-level frequency stability increasingly important. However, the prior-art approaches lack a standardized framework for FSC assessment, and the non-disclosure of RGU information by manufacturers exacerbates this challenge. To address these issues, this paper proposes a unified transfer function structure (UTFS) model and its parameter solving method based on impedance measurement, enabling a unified assessment of both the unit-level FSC and system-level frequency stability. The unit-level UTFS can be obtained through frequency-domain approaches, e.g., xy-impedance measurements. Moreover, the system-level UTFS can be acquired through the simple aggregation of unit-level UTFS. Without detailed models or post-event data, the proposed framework uniformly represents the FSC of various RGUs through three key indicators: effective inertia, damping, and primary frequency regulation (PFR). Furthermore, the proposed method analytically derives system frequency indicators: frequency nadir, rate of change of frequency (RoCoF), and steady-state frequency deviation. Numerical simulations and analysis of the operational data of a provincial power grid are provided to validate the proposed method.</description></item><item><title>Multi-Timescale Operational Optimization for Mobile Charging Solutions Considering Voltage Regulation Support for ADN: A Two-Stage Coordination Approach</title><link>http://ieeexplore.ieee.org/document/11051060</link><description>To alleviate the pressure of traditional fixed charging methods, mobile charging solutions have emerged in recent years. This article presents a two-stage coordination approach for mobile charging robots (MCRs) and active distribution networks (ADN). In the first stage, we maximize the total revenue for the MCRs from providing charging services for electric vehicles (EVs) and interacting with the ADN within a frame-based time scale, where the duration of each frame is determined by the charging decisions of MCRs. Furthermore, we consider the long-term objectives of meeting the battery energy deficit constraint for each MCR, thereby improving their battery life. Lyapunov optimization is utilized to transform frame-based scheduling into an optimization problem within a specified time slot, simplifying the process of solving the optimization problem. To avoid affecting charging efficiency when MCRs interact with the power grid, we use the reactive power of free MCRs to provide voltage regulation support for the ADN, improving power quality and minimizing total network loss simultaneously. Decoupling active and reactive power in two stages ensures both the profitability of the MCRs cluster and the voltage security of the ADN, resulting in a win-win situation. The simulation results, based on the 18-bus and 51-bus distribution networks, confirm the effectiveness and superiority of the proposed approach.</description></item><item><title>Assessing Grid Penalized Reinforcement Learning for Renewable Energy Management of Power-to-X Integrated With Intermediate Storage</title><link>http://ieeexplore.ieee.org/document/11051013</link><description>This research explores the deep reinforcement learning (DRL) based planning strategies of power-to-X (PtX) systems under uncertainties of renewable and price through a detailed case study and comparative analysis of system planning. A DRL-based hourly planning model is proposed to minimize operational costs for a PtX system, incorporating a hybrid energy storage system. The model employs a grid-penalized reward function to manage grid power usage while accounting for temporal uncertainties in renewable and grid prices. To analyze the DRL model&#8217;s planning strategies, it is compared to a general rule-based model across varying spatial and temporal uncertainties using real-world data from national (France) areas. The results show that the DRL-based planning approach consistently outperforms the rule-based model, achieving 1,360.12% higher monthly profits in the national area, though with a relatively lower renewable energy penetration (REP). However, sensitivity analysis reveals that increasing the grid penalty level effectively reduces the gap in REP while sustaining higher profitability. This comparative analysis is the first to quantitatively reveal the planning strategies of a DRL-based PtX system, highlighting its effectiveness in reducing grid power overuse while maintaining higher profitability in system planning.</description></item><item><title>Distributed Proximal Policy Optimization With Embedded Dual Rules for Power Systems Considering Wind and Photovoltaic Forecasting</title><link>http://ieeexplore.ieee.org/document/11059762</link><description>Most renewable energy power systems are created to provide more resilient, reliable, economical, sustainable and secure power support services for loads. However, owing to the inherent forecasting errors of wind and photovoltaic (PV) power, existing optimal dispatch decisions based on forecasting errors have biases. To address this issue, this paper proposes the distributed proximal policy optimization (DPPO) model with embedded dual rules for optimal power dispatch that considers wind and PV power forecasting error correction. The proposed model embeds forecasting and error correction information into the DPPO state space. Moreover, considering the physical characteristics and operational security constraints of the power grid, power balance and flow constraints are embedded in the DPPO network in a regular form. Finally, by integrating the established rules, wind and PV forecasting, and error correction information, the proposed model achieves optimal dispatch decisions through the calculation of state and execution of prescribed actions. The proposed method is applied and tested on a modified IEEE-30 bus system using actual data from a provincial power grid. The numerical results demonstrate that the proposed method effectively addresses optimal dispatch decisions caused by wind and PV forecasting errors. Compared with three other advanced methods, the proposed approach has significant advantages in promoting wind power accommodation, reducing operating costs, and enhancing the adaptability of optimal dispatch to uncertainty.</description></item><item><title>An End-to-End Ensemble Learning Approach for Enhancing Wind Power Forecasting</title><link>http://ieeexplore.ieee.org/document/11048619</link><description>Accurate wind power forecasts are crucial for grid stability, thereby ensuring a reliable and efficient power supply. To characterize the complicated fluctuation of wind power, numerous ensemble models with multiple base forecasters have been developed. However, most existing ensemble forecasting models contain several modeling stages, which increases the risk of error accumulation and inefficiency in model training. Moreover, the limited number of base forecasters results in forecasts with reduced diversity, thereby diminishing the performance of ensemble models. To address these challenges, MG-DS, a simple but efficient end-to-end ensemble learning model based on the Dempster-Shafer (DS) evidence theory, is proposed to unify base model learning and ensemble learning into a single process. It comprises an all-MLP-based nonlinear feature extraction module, a GRU and cross attention-based base forecast generation module, and a DS-based self-ensemble forecasting module with a DS-based magnifying glass to enhance the diversity of base forecasts. Further, a DS-based self-ensemble (DSSE) plugin is proposed to integrate the trained RNN-type and non-RNN-type base forecasters. Experiments on five wind power datasets show that MG-DS outperforms popular wind power forecasting models and ensemble techniques, and the effectiveness of the DSSE plugin is also validated in enhancing the performance of ensemble wind power forecasting.</description></item><item><title>A Fully Distributed Incentive Mechanism for Integrated Electricity and Heat Systems</title><link>http://ieeexplore.ieee.org/document/11045415</link><description>Coordination between electric power systems (EPS) and district heating systems (DHS) integrates more renewable energy and improves economic benefits. However, the dispatch of integrated electricity and heat systems (IEHS) raises privacy and incentive concerns. To address these issues, we propose a fully distributed incentive mechanism for IEHS. Specifically, the combined heat and power dispatch (CHPD) model is transformed into a monotone variational inequality (MVI) and solved by a fully distributed predictor-corrector algorithm (FDPCA). With FDPCA, the EPS and DHS operators can dispatch independently. Additionally, we use a novel two-stage benefit allocation approach based on Nash bargaining to distribute profits while simplifying computational complexity. Case studies demonstrate that the fully distributed incentive mechanism effectively protects privacy, enhances efficiency, and promotes cooperation.</description></item><item><title>Adaptable Parameters Estimation for Microgrid Distributed Energy Resources Using Modified Physics-Informed Neural Network</title><link>http://ieeexplore.ieee.org/document/11045087</link><description>Parameters estimation in microgrids remains challenging due to ambiguous system dynamics brought by distributed energy resources (DERs) and scarcity of data. This study presents a modified physics-informed neural network (PINN) paradigmdesigned for parameters estimation under such constraints. This paper introduces two main innovations: First, by combining small-signal analysis with the PINN framework for ordinary differential equations, we introduce an adaptable parameter estimation paradigm applicable to different types of DERs in microgrid. Second, we introduce a modified data transformation that reduces training time by up to 82.87% compared to traditional PINN approaches at best. To validate our approach, we conducted simulation on two typical system setups based on open-source real-world microgrid using real-time digital simulation to generate data. We evaluate the proposed method by using an error margin below 5% as a key metric to confirm its robustness and accuracy for different types of DERs. The experimental results demonstrate the effectiveness and adaptability of the proposed method across varying ordinary differential equations to diverse mathematical models. Additionally, suboptimal and failed cases are analyzed and discussed to provide a comprehensive evaluation of the method&#8217;s limitations.</description></item><item><title>A Novel Fractional Programming-Based Planning Model for 100% Renewable Poly-Generation of Electricity and Methanol</title><link>http://ieeexplore.ieee.org/document/11045219</link><description>Engaging in long-term power purchase agreements (PPAs) with renewable energy producers (REPs) is a promising strategy for decarbonizing hard-to-abate sectors, such as internet data centers. However, due to the inherent volatility and intermittency of renewable energy sources (RES), REPs typically require substantial over-installation of capacity to meet fixed PPA delivery commitments, resulting in significant energy curtailment and increased supply costs. Power-to-methanol (P2M) offers a viable pathway for large-scale integration of RES by providing flexible chemical storage and demand. This study proposes a unified planning framework for the 100% renewable poly-generation of electricity and methanol, considering both flexible and inflexible loads. The objective is to maximize the internal rate of return (IRR), a key metric for investment decision-making. To this end, a mixed-integer linear fractional programming (MILFP) model is developed and solved in a computationally tractable manner. The model is validated using real-world data. Results show that the proposed approach significantly improves IRR, reduces RES curtailment, and lowers the levelized costs of both electricity and methanol. Furthermore, the model effectively coordinates electricity delivery under PPA constraints with methanol synthesis, offering an economically robust solution for renewable energy utilization and sector coupling.</description></item><item><title>Human-in-the-Loop Reinforcement Learning Method for Volt/Var Control in Active Distribution Network With Safe Operation Mechanism</title><link>http://ieeexplore.ieee.org/document/11045109</link><description>In recent years, distributed energy resources (DERs) in power systems have been increasingly integrated into the distribution network. DERs will improve the flexibility and economy of active distribution networks (ADNs) while introducing increased complexity and challenges in maintaining stable and efficient system operations. The traditional voltage regulation methods struggle to cope with these complexities, highlighting the need for more advanced and adaptive control strategies for fast-response PVs and battery energy storage systems (BESS). This paper proposes a novel Human-in-the-loop deep reinforcement learning (HITL-DRL) framework for Volt/Var control in ADNs, addressing the limitations of the existing approaches by integrating human experience and knowledge into the learning process. Additionally, a Security-Clipped Proximal Policy Optimization (SC-PPO) algorithm is introduced to ensure safe operation during reinforcement learning. The paper explores three human-intervention strategies: human demonstration, human feedback, and setting adversary, which enhance the learning process by leveraging expert knowledge and experience. The proposed HITL-DRL framework demonstrates improved convergence speed, robustness, reduced exploration risk, and increased interpretability and trust, paving the way for more effective voltage regulation in complex power systems. The proposed HITL-DRL method is verified in the IEEE 33-bus system, demonstrating superior performance over standard DRL algorithms in terms of training speed and robustness, achieving the highest average reward and the second-fastest computational time. Compared to traditional PPO, our method significantly excels in managing unforeseen contingencies, resulting in a lower voltage violation rate of 73.4%. Compared with the model-based method, the strategy of HITL-DRL is very close to that of optimization results in terms of energy loss and voltage violation rates. However, HITL-DRL shows advantages in decision-making time, responding within 1 millisecond, which is capable of rapidly adapting to time-vary changes in ADNs.</description></item><item><title>Hierarchical Flexibility Aggregation of Heterogeneous Demand-Side Energy Storages for Secondary Frequency Regulation</title><link>http://ieeexplore.ieee.org/document/11044873</link><description>Demand-side energy storages (DESs), such as household batteries and electric vehicles (EVs), have shown great potential in providing fast frequency regulation services. This paper proposes a three-layer hierarchical flexibility aggregation framework to fully evaluate and reliably realize the aggregate flexibility of heterogeneous DESs for secondary frequency regulation (SFR). At the device layer, the regulation capacity of an individual DES is modeled as a two-dimensional feasible region, with the real-time state-of-charge (SoC) constraint and the statistical features of regulation signals well considered. On this basis, heterogeneous DESs are divided into several clusters according to the geometry of their feasible region. At the cluster layer, regulation capacity, dynamic response model as well as regulation costs are efficiently aggregated within each DES cluster by prototype-based maximum inner approximation (MIA). At the aggregator layer, an analytical expression of the multi-cluster coordinated SFR flexibility can be formulated by convex optimizations at each feasible operating point, which provides a comprehensive model for DES aggregators to economically participate in SFR. Comparative simulations validate that the proposed method can accurately capture the aggregate SFR flexibility of heterogeneous DESs with lower flexibility loss and affordable computational burden, while the disaggregation feasibility of aggregate flexibility is further demonstrated using real-world regulation signals.</description></item><item><title>Distributed Autonomous Control for Global Economic Operation of AC/DC Microgrid Clusters Interconnected by Flexible DC Distribution Network</title><link>http://ieeexplore.ieee.org/document/11045308</link><description>This paper presents a distributed autonomous control strategy for AC/DC microgrid clusters interconnected by the flexible DC distribution network to simultaneously achieve the global economic operation and frequency/voltage control of the system while complying with the power limits of DGs and interlinking converters. First, the optimal control problem for the system is formulated and the Karush-Kuhn-Tucker (KKT) condition of the system global economic dispatch is obtained. Then, the three-layer control framework including the distributed generator layer (DG-layer), microgrid layer (MG-layer), and microgrid cluster layer (MGC-layer) is established. In the MG-layer, the distributed frequency/voltage and economic dispatch controllers are designed for each ACMG and DCMG. In the MGC-layer, a distributed peer-to-peer control method is provided to realize the coordinated control among interlinking converters while controlling the voltage of DC distribution network. The coordination method between MG-layer and MGC-layer is also designed. Finally, time-domain simulation and experiments are carried out to validate the effectiveness of the proposed methods.</description></item><item><title>Deep Reinforcement Learning-Based Allocation of Mobile Wind Turbines for Enhancing Resilience in Power Distribution Systems</title><link>http://ieeexplore.ieee.org/document/11045830</link><description>The growing adoption of wind energy resources has demonstrated notable benefits in combating climate change. Mobile wind turbines (MWTs) are uniquely positioned to navigate transportation systems, being towed by trucks, and supply energy to power distribution systems (PDSs). This flexibility enables MWTs to serve as emergency power sources, thereby contributing to enhancing the system resilience by facilitating service restoration following extreme events. This paper presents a novel framework based on Multi-agent Deep Reinforcement Learning (MADRL) to dispatch MWTs for service restoration. Deep Q-learning (DQL) and Double Deep Q-learning (DDQL) approaches are implemented within the agent for training and comparison purposes. Additionally, an action limitation is incorporated into the proposed framework in order to mitigate the influence of wind power fluctuations. Case studies conducted on an integrated power-transport system, comprising a Sioux Falls transportation system and four IEEE 33-bus test systems, illustrate the effectiveness of the proposed restoration scheduling policy in enhancing PDSs&#8217; resilience against disasters.</description></item><item><title>Robust Unit Commitment With Multi-State Uncertainty: A Novel Formulation and Scalable Solution Method</title><link>http://ieeexplore.ieee.org/document/11045107</link><description>To mitigate the conservatism of scheduling schemes derived from the two-stage robust unit commitment model (TS-RUCM), this paper proposes a novel multi-state uncertainty set (MSUS) considering the uncertain wind power output (WPO). The MSUS formulates WPO uncertainties with higher resolution by introducing multiple discrete state values within the uncertain interval. Additionally, the MSUS limits extreme fluctuations of WPO uncertainties among state values through transition indicators embedded in multiple transition constraints. The state values and transition indicators are calculated using the conditional quantile regression technique and Markov chain analysis. This systematic and scientific approach allows the MSUS to effectively exclude low-probability WPO scenarios, thereby significantly mitigating the conservatism of the scheduling schemes. Moreover, to accelerate the computation of the TS-RUCM based on the MSUS, this paper proposes an improved inexact column and constraint generation (II-C&amp;amp;CG) method. The II-C&amp;amp;CG method employs an adaptive tolerance strategy and refined backtracking to solve master and subproblems inexactly while ensuring finite convergence, significantly reducing computational time. Case studies demonstrate the effectiveness and advantages of both the MSUS and the II-C&amp;amp;CG method.</description></item><item><title>Integrated Artificial Intelligence and Physics-Based Modeling for Long-Term Cascaded Hydropower Scheduling Under Extreme Heat Events</title><link>http://ieeexplore.ieee.org/document/11059276</link><description>The operation of hydropower plants are significantly challenged by extreme heatwave events. This paper integrates artificial intelligence and a physics-based model to introduce an efficient long-term scheduling framework aimed at maximizing hydropower generation during extreme heat events. The water values derived from the proposed long-term scheduling model can be used in developing effective strategies for short-term hydropower scheduling. A physics-based evaporation model (PEM), which captures key land-atmosphere interactions, is developed to account for significant variations in reservoir evaporation rates during extreme heat events. A multivariate long short-term memory (M-LSTM) forecasting model is also utilized to predict the key input parameters required for both the PEM and the long-term scheduling problem. A regression-based machine learning algorithm is also utilized to estimate the hydropower production function, which enables linear integration of the nonlinear and nonconvex behavior of hydropower plant in the mixed-integer linear formulation of the scheduling problem. The proposed model is applied to a case study of eleven cascaded hydropower units located on the Columbia river. The numerical results demonstrate that the proposed long-term scheduling model effectively manages reservoir operations, mitigating the adverse impacts of extreme heat events on hydropower generation and operator profitability.</description></item><item><title>Chance-Constrained Optimization for VPPs With Base Stations Considering Diverse Communication Rate Requirements</title><link>http://ieeexplore.ieee.org/document/11082584</link><description>5G Base Stations (BSs) consume a large amount of electricity, requiring predominantly green power, which brings huge pressure on their electricity costs. To reduce energy costs and carbon emissions, aggregating 5G BSs (Macro BS and Micro BS), and distributed renewable energy into virtual power plants (VPPs) to participate in market transactions has become a trend. However, the operation of VPPs faces challenges: the uncertainty of renewable energy output and the unclear regulation mechanism of BSs. Consequently, this paper focuses on developing an optimal scheduling strategy for VPPs, considering the schedulability of BSs and the uncertainty of internal renewable energy. Firstly, the flexibility of BSs with 4G and 5G modules is investigated, particularly in terms of transceivers and backup energy storage. The communication rates of BSs are modeled to evaluate the impact of active transceiver numbers on user experience. A dynamic time-domain model of backup energy storage capacity considering communication load is proposed. The impact of user mobility and overlapping coverage areas of BSs on communication rates is considered to be more in line with real-world scenarios. Subsequently, an optimization model is developed for VPPs to maximize the profit of engaging BSs in the day-ahead market transaction, considering diverse communication rate requirements. The optimization model determines the schedule of transceivers, backup energy storage, and other resources. Then, to control the operational risks associated with the uncertainty of internal distributed renewable energy outputs, the chance constraint is introduced. Furthermore, the Taylor expansion-based algorithm is applied to coordinately solve the VPP dispatching problem. Numerical simulations are carried out to validate the effectiveness of the proposed models, which achieve a 5.4% increase in the proportion of internal renewable energy consumption and a 18.72% increase in economic benefits.</description></item><item><title>Synthetic Inertia Control for a Wind Turbine Generator Based on Event Size and Rotor Speed</title><link>http://ieeexplore.ieee.org/document/11045832</link><description>To enhance the frequency nadir without causing the excessive deceleration of the rotor speed (${{{{\omega }}}_{{r}}}$), synthetic inertia control (SIC) schemes of a wind turbine generator (WTG) need to provide incremental power in response to event magnitude and ${{{{\omega }}}_{{r}}}$. Conventional stepwise SIC approaches face limitations during large events due to the increase of predefined incremental power, which does not match the actual event size. This paper presents an SIC strategy for WTGs that adjusts incremental power in relation to event size and ${{{{\omega }}}_{{r}}}$. During the frequency-support phase, the incremental power is modulated based on the frequency deviation, along with a control gain proportional to ${{{{\omega }}}_{{r}}}$, rather than the rate of change of frequency. While this approach accounts for the power imbalance, it remains vulnerable to noise and delays in practical applications. After the frequency-support phase, the proposed method decreases the active power reference in accordance with ${{{{\omega }}}_{{r}}}$, ensuring it stabilizes within a secure operating range. Following stabilization, the WTG transitions smoothly back to maximum power point tracking operation. Simulation results indicate that the proposed approach significantly enhances the frequency nadir during large events, even under low wind conditions, while avoiding excessive deceleration of the rotor speed.</description></item><item><title>Prototype Federated Reinforcement Learning for Voltage Regulation in Distribution Systems With Physics-Aware Spatial-Temporal Graph Perception</title><link>http://ieeexplore.ieee.org/document/11045127</link><description>Online voltage regulation in active distribution systems faces challenges stemming from privacy protection concerns and uncertainties introduced by renewable energy sources. To address these issues, a novel spatial-temporal transformer-based prototype federated reinforcement learning (STT-PFRL) model is proposed to mitigate voltage deviations while ensuring data privacy. Specifically, STT-PFRL operating within a decentralized framework trains the model by transmitting local prototype information between a central data server and local agents, avoiding raw data privacy leakage. Besides, a novel physics-aware spatial-temporal transformer network is proposed to improve the voltage regulation policy learning stability against uncertainties by embedding the spatial-temporal graphical physics information into the data aggregation process. Furthermore, the prototype learning-based federated soft actor-critic (ProtoFedSAC) algorithm incorporates a prototype layer to utilize diverse feature representations, thereby enhancing the model&#8217;s ability to handle heterogeneity in environmental data. Simulation results on 33- and 118-node distribution systems demonstrate the superior effectiveness and efficiency of STT-PFRL in voltage regulation.</description></item><item><title>County-Level Distributed PV Day-Ahead Power Prediction Based on Grey Correlation Analysis and Transformer-GCAN Model</title><link>http://ieeexplore.ieee.org/document/11061797</link><description>The distributed photovoltaic (PV) power stations within the entire county exist spatiotemporal correlation. Merely considering temporal correlation makes it challenging to meet the day-ahead scheduling demands. This paper proposes a distributed PV county-level day-ahead power prediction method based on grey relational analysis and the Transformer-Graph Convolutional Attention Network (Transformer-GCAN) model. Firstly, the grey relational degree is used to measure the relevance between each distributed PV stations, and the connection relationship of the station graph is determined based on the analysis results. Secondly, the Transformer network is utilized to extract the temporal features of each PV sequence in the graph. Based on the Graph Convolutional Network (GCN) model, a Graph Attention Mechanism (GAT) is introduced to dynamically extract spatial features between each photovoltaic station in the graph. Finally, the integration of spatiotemporal features is achieved through a fully connected neural network, enabling day-ahead power prediction at the county level. Case analysis results demonstrate that compared with the Transformer-GCN model, the Root Mean Square Error (RMSE) of the power prediction model proposed in this paper is reduced by 11.90%, 15.72% and 19.61% respectively in sunny days, cloudy days and rainy days.</description></item><item><title>Power Capacity Allocation Among Multiple Renewable Power Plants: A Perspective From System Strength</title><link>http://ieeexplore.ieee.org/document/11122291</link><description>Large-scale renewable energy projects consisting of renewable power plants (RPPs) managed by different stakeholders may suffer weak system strength. Consequently, only a limited amount of renewable power capacity can be delivered, or the insufficient system strength could incur stability issues. The allocation of system strength constrained power capacity among different RPPs deserves investigation, which is critical to their respective benefits. To this end, the system strength demand of each RPP is quantified based on its allowable power capacity. A power capacity allocation approach is proposed, ensuring that the RPPs efficiently and fairly utilize system strength. Case studies show that RPPs with longer electrical distances deliver less renewable capacity due to their greater impact on system strength.</description></item><item><title>Nonsmooth Decentralized Voltage Controller for Constrained Regulation of DC Microgrids With Constant Power Loads</title><link>http://ieeexplore.ieee.org/document/11168949</link><description>This paper presents a novel decentralized voltage controller that enforces state constrains at all times and significantly enhances the transient response of DC Microgrid networks with constant power loads. The structure of the proposed controller ensures the existence of a positive invariant set under the solution of the dynamics, enforcing boundedness of each nodal voltage around a rated value. A rigorous analysis is presented to formulate sufficient conditions on the controller tuning parameters such that the boundedness property is guaranteed despite the time-varying nature of the nonlinear load demand. Closed-loop stability of the entire DC Microgrid with respect to desired reference points is analytically proven by employing a suitable Lyapunov function. This allows us to estimate the region of attraction of the desired equilibrium and obtain conditions under which system stability is ensured at all times. Furthermore, the structure of the proposed controller significantly improves the convergence rate of the closed loop system when compared with similar approaches in the literature. The theoretic results are verified in both experimental and power hardware-in-the-loop testing scenarios, while demonstrating fast voltage restoration in cases of load demand fluctuations and constrained regulation to the desired voltage References.</description></item><item><title>A Control Strategy of Multi-Terminal Grid-Forming Soft Open Point for Uninterrupted Power Supply Under Feeder Power Outages</title><link>http://ieeexplore.ieee.org/document/11173992</link><description>This paper proposes a control strategy of the multi-terminal grid-forming soft open point (MGSOP), aimed to ensure uninterrupted power supply during distribution feeder outages. Unlike existing approaches, the proposed control does not rely on an ideal DC voltage assumption, master-slave structure, or control mode switching. In the MGSOP, the AC-DC and DC-DC converters are used for multi-feeder interconnections and energy storage integration. The MGSOP control system comprises local and coordinating controllers, used to implement the proposed control strategy, which is made up of three sections: 1) Grid-forming AC voltage control implemented by local controllers, which ensures the independent construction of AC voltage and prevents control switching between grid-connected and standalone modes. 2) Hierarchical DC voltage control collaborated by both local and coordinating controllers. Based on the multi dynamic of DC voltage ( $\Delta U_{dc}$  and dUdc/dt), the control ensures dynamic DC power balance and DC voltage stability, avoiding system instability and restoration failures caused by the shutdown of the master converter under traditional master-slave control. 3) Coordinated control for the power regulation among multiple feeders, which reduces the consumption of energy storage during supply restorations. Finally, the effectiveness of the proposed control strategy is validated by simulations.</description></item><item><title>CommonPower: A Framework for Safe Data-Driven Smart Grid Control</title><link>http://ieeexplore.ieee.org/document/11186797</link><description>The growing complexity of power system management has led to an increased interest in reinforcement learning (RL). To validate their effectiveness, RL algorithms have to be evaluated across multiple case studies. Case study design is an arduous task requiring the consideration of many aspects, among them the influence of available forecasts and the level of decentralization in the control structure. Furthermore, vanilla RL controllers cannot themselves ensure the satisfaction of system constraints, which makes devising a safeguarding mechanism a necessary task for every case study before deploying the system. To address these shortcomings, we introduce the Python tool CommonPower, the first general framework for the modeling and simulation of power system management tailored towards machine learning. Its modular architecture enables users to focus on specific elements without having to implement a simulation environment. Another unique contribution of CommonPower is the automatic synthesis of model predictive controllers and safeguards. Beyond offering a unified interface for single-agent RL, multi-agent RL, and optimal control, CommonPower includes a training pipeline for machine-learning-based forecasters as well as a flexible mechanism for incorporating feedback of safeguards into the learning updates of RL controllers.</description></item><item><title>Chattering-Free Robust Terminal Sliding Mode Control for DC Nanogrids</title><link>http://ieeexplore.ieee.org/document/11197018</link><description>DC nanogrid is an emerging solution for providing affordable electricity to rural areas and homes equipped with solar panels, power converters, and on-site batteries. However, its poor transient response limits its practical application, presenting a significant drawback. This paper proposes a chattering-free robust terminal sliding mode control with finite time stability for the DC nanogrid. The proposed control strategy effectively addresses issues such as poor transient response and chattering, thereby ensuring optimal operation of the DC nanogrid. To achieve robust closed-loop power system operation, advanced nonlinear sliding surfaces and control laws are designed. This work focuses on achieving robustness against dynamic changes and system uncertainties caused by the intermittent nature of the renewable generation unit, instantaneous load variation, and saturation of the control laws. The finite-time stability of the closed-loop system is proved using Lyapunov theory to ensure finite-time convergence for both the reaching and sliding phases. The effectiveness of the proposed nonlinear controller is demonstrated by comparing it with higher-order SMC and conventional asymptotic SMC. System behavior is analyzed through MATLAB/Simulink simulations, and practical applicability is validated experimentally using an IMPERIX hardware setup.</description></item><item><title>Large-Signal Stability Analysis of Multi-Stack Fuel Cell Hybrid Power Systems With Virtual Inertia-Based Control</title><link>http://ieeexplore.ieee.org/document/11197052</link><description>Multi-stack fuel cell (FC) hybrid power systems (MSFCHPSs) are high-order nonlinear systems with inherently complex nonlinear characteristics due to their integration of multiple FC stacks, power electronic converters, and nonlinear loads. Thus, MSFCHPSs are very vulnerable to destabilization by transient disturbances, which exceeds the capabilities of traditional small signal stability analysis. To explore the destabilization mechanism of MSFCHPSs, this article proposes a comprehensive large-signal stability (LSS) analysis framework integrating a full-order nonlinear model, including all main circuits, complete control loops, and FC aging effects, with virtual inertia-based control. The nonlinear system is transformed into a Takagi&#8211;Sugeno (T-S) fuzzy representation, enabling domain of attraction (DOA) estimation via Lyapunov theory and linear matrix inequalities (LMIs) with low computational burden and reduced conservatism. The method quantitatively assesses the influence of power distribution, virtual inertia parameters, circuit elements, control gains, and FC aging on LSS, identifying dominant stability factors. A hardware-in-the-loop (HIL) platform is developed to experimentally validate the proposed approach. Results show strong agreement between estimated and actual stability boundaries, confirming the method&#8217;s accuracy and practical applicability for MSFCHPS design and operation.</description></item><item><title>Artificial Intelligence Data Driven Control for DC Solid State Transformer in DC Microgrid</title><link>http://ieeexplore.ieee.org/document/11215658</link><description>The DC solid-state transformer (DCSST) serves as a key component for connecting power supplies, loads, and other elements in a DC microgrid system. With the integration of new energy sources and random loads, the system has become increasingly complex, making accurate modeling challenging due to high modeling costs. The randomness of the loads introduces various disturbances, compromising system stability. To address these challenges, this paper proposes a data-driven model-free control (DMFC) approach based on deep reinforcement learning (DRL) and an improved Kalman filter (IKF) for the DCSST. First, a data-driven model of the DCSST is established. Next, the IKF is designed, which is tailored for DMFC to correct measurement errors, filter noise, and estimate uncertain disturbances. Subsequently, the DMFC is introduced, which ensures stability under large signal disturbances without relying on an accurate system model. Finally, a DRL sub-controller is integrated into the DMFC to intelligently adjust the control signal and enhance the system&#8217;s operational adaptability. Experimental results demonstrate that the proposed control method can adaptively ensure the stability of the system under large signal disturbances without requiring an accurate model, while also exhibiting good dynamic and steady-state performance.</description></item><item><title>Visual-Based Reinforcement Learning for Voltage Regulation and Attack Mitigation in Distribution Networks</title><link>http://ieeexplore.ieee.org/document/11173844</link><description>The growing integration of distributed generators introduces increased vulnerability to cyber threats in modern power distribution systems, especially false data injection attacks (FDIAs) targeting communication network. This paper presents a novel real-time voltage regulation framework that enhances both system security and operational efficiency under FDIA scenarios. A time-frequency visual (TFV) model is first developed to identify FDIA types and accurately detect their duration in real-time. Based on the detection outcomes, a redirected control mechanism is employed to correct compromised control signals. These components are embedded into a Markov decision process (MDP) that guides voltage regulation strategies. To solve the MDP, an attention-based multi-agent soft actor-critic (AMS) algorithm is introduced, leveraging attention mechanisms to enhance decision-making under complex and uncertain environments. Integrating the TFV and AMS modules, a visual-based reinforcement learning (VRL) approach is formulated for robust and adaptive voltage control. Extensive simulations conducted on a modified IEEE 33-bus system using real-world synchrophasor data demonstrate that the proposed method effectively contains voltage deviations within 0.02085 p.u., significantly improving the resilience of the distribution network against cyberattacks.</description></item><item><title>A Safe Combined Reinforcement Learning and Model Predictive Control Scheme for Utility-Level Battery Control in Distribution Grids</title><link>http://ieeexplore.ieee.org/document/11193800</link><description>Optimally controlling energy storage systems is essential for the integration of renewables and electromobility in future power grids. Such control schemes may need to satisfy lookahead requirements for the batteries state-of-charge so as to ensure a smooth grid operation. Model predictive control (MPC) is traditionally used to solve these type of problems suffering however from long runtimes and the need of fine-tuned forecasts. Reinforcement Learning (RL) approaches are considered as alternatives but usually cannot guarantee constraints satisfaction. To overcome the limitations of both MPC and RL, in this work, a novel method that integrates RL into MPC is proposed leading to a fast real-time control scheme that aims to enforce near-future constraints satisfaction and accounts for lookahead constraints in the current decisions. Due to the inclusion of the RL-based learned value function in the MPC cost, traditional optimization solutions do not apply and the application of the cross-entropy-method (CEM) is suggested. Its runtime is reduced to the time scale of seconds by employing appropriate initialization based on RL decisions as well as an exponentially decaying amount of samples. Numerical comparisons show that the proposed method outperforms MPC and other safe RL schemes in terms of cost performance and constraints violations.</description></item><item><title>Optimal Placement of Smart Hybrid Transformers in Distribution Networks</title><link>http://ieeexplore.ieee.org/document/11224498</link><description>Hybrid transformers are a relatively new technology that combine conventional power transformers with power electronics to provide voltage and reactive power control capabilities in distribution networks. This paper proposes a novel method of determining the optimal location and utilisation of hybrid transformers in 3-phase distribution networks to maximise the net present value of hybrid transformers based on their ability to increase the export of power produced by distributed generators over their operational lifespan. This has been accomplished through sequential linear programming, a key feature of which is the consideration of nonlinear characteristics and constraints relating to hybrid transformer power electronics and control capabilities. Test cases were carried out in a modified version of the Cigre European Low Voltage Distribution Network Benchmark, which has been extended by connecting it with two additional low voltage distribution test networks. All test case results demonstrate that the installation and utilisation of hybrid transformers can improve the income earned from exporting excess active power, justifying their installation cost (with the highest net present value being (6.56 million, resulting from a 45.53% increase in estimated annual profits due to coordinated HT compensation).</description></item><item><title>Real-Time Operational Strategy for Ice Thermal Storage District Cooling Systems via Model-Free Safe Deep Reinforcement Learning</title><link>http://ieeexplore.ieee.org/document/11184258</link><description>District cooling system (DCS) offers centralized cooling services for building groups that significantly reduce energy consumption and carbon emissions. However, existing model-based methods struggle with the large-scale, stochastic, and nonlinear characteristics of the DCS optimization problem under strict time limits. To fill this research gap, this paper proposes a model-free safe deep reinforcement learning (MFS-DRL) algorithm for the DCS to deliver real-time scheduling strategies of multiple chillers and ice thermal storage units under varying operating conditions. The problem is modeled as a constrained Markov decision process (CMDP) to systematically decouple the objective from the constraint, therefore overcoming the confusion between reward and penalty caused by manual penalty coefficients in traditional DRL methods. Moreover, prior expert knowledge is acquired through the interior point optimizer (IPOPT) solver, and the agent is pre-trained using imitation learning (IL) to mitigate exploration disorder and local convergence in the early training stage. Ultimately, the Lagrangian relaxation approach is applied to modify the optimality criteria and gradient update rules of the classic deep deterministic policy gradient (DDPG) algorithm, thereby achieving a trade-off between feasibility and optimality. Numerical experiments on 12-node and 619-node DCSs demonstrate that the proposed method outperforms representative model-based and data-driven baselines, delivering high-quality solutions within only milliseconds and maintaining robustness across hyperparameter variations.</description></item><item><title>Load Prediction of Hydrogen Powered Ship: A Deep Prediction Framework Considering Operating Environment and Error Correction</title><link>http://ieeexplore.ieee.org/document/11187418</link><description>The load prediction for the future period can serve as an important reference for ship navigation planning. However, the small displacement of hydrogen powered ships and the complex operating environment and conditions pose a serious challenge to load prediction. This study develops an advanced load forecasting framework for hydrogen energy ships by integrating navigation data with hydro-meteorological conditions, proposing a novel strategy that combines classified load prediction with unified error correction. The methodology begins with Spearman correlation analysis to identify critical features for both propulsion and maintenance loads. LightGBM models then generate rapid preliminary predictions for these load categories, employing continuous training to enhance computational efficiency while producing initial forecast sequences. The framework&#8217;s key innovation is the Int-ConvGRU network, which implements error correction through a parallel architecture that simultaneously processes historical data and preliminary predictions while preserving precise temporal relationships. This unique design significantly improves prediction accuracy by effectively capturing complex temporal dependencies. Comprehensive validation using data from hydrogen-powered vessels demonstrates the framework&#8217;s superior performance against multiple benchmark models, particularly in handling the distinct load characteristics of modern ships.</description></item><item><title>Multi-Time-Domain Hierarchical Scheduling of Integrated Energy Systems With Frequency Decomposition Considering Large-Scale Grid Connection of Electric Vehicles</title><link>http://ieeexplore.ieee.org/document/11192655</link><description>Amid global decarbonization efforts, Integrated Energy Systems (IES) face critical challenges from the inherent uncertainties of high-penetration renewable energy sources and the large-scale, potentially disorderly integration of Electric Vehicles (EVs), leading to significant supply-demand imbalances and system volatility. Existing approaches struggle to effectively coordinate diverse device response times and capture complex EV user behavior. To address these, this paper proposes a multi-time domain control model-driven bi-level optimization framework for Integrated Energy Systems. The upper level employs a multi-objective intelligent algorithm to generate Pareto-optimal solutions balancing economic costs and environmental impacts. The lower level implements a singular perturbation theory-based multi-time domain control model, dynamically partitioning devices into fast/slow subsystems for differentiated scheduling, significantly enhancing resilience against uncertainties. Additionally, a prospect theory-driven EV dynamic charging response model accurately incorporates user psychology (e.g., loss aversion) to guide orderly charging via price incentives. Furthermore, a Fourier-based power decoupling strategy for hybrid storage (LIB-SC) reduces battery degradation by 28.7%. Case studies demonstrate superior performance: a 12.2% reduction in economic costs, an 11.5% reduction in emissions, and robustly maintained system volatility below 5% under extreme uncertainties, showcasing significant advancements in balancing economic-environmental objectives while accommodating high renewable and EV penetration.</description></item><item><title>Interpretable and Accurate Multi-Energy Loads Forecasting via Continuous-Time Modeling</title><link>http://ieeexplore.ieee.org/document/11195784</link><description>High-precision interpretable forecasting of multi-energy loads is crucial for planning and optimizing Integrated Energy Systems (IES). Current methods have three key limitations: 1) reliance on closed-box models obscures feature interactions; 2) traditional modal decomposition methods ignore cross-modal correlations and fail to efficiently extract global cycle-trend characteristics; 3) limitations in sampling frequency prevent capturing fast dynamic characteristics of energy loads. To address these, we propose a dual resolution channel multi-period cross reconstruction parallel closed-form continuous-time network (DMP-PCFC) for multi-energy load forecasting. This method includes a multi-period cross-reconstruction network which equivalent to the signal sifter for decoupling original sequences and nonlinear mapping across periods, and models hidden states of energy loads using neuron state iterative differential equations. A parallel Closed-form continuous-time neural network (PCFC) based on chunked parallelization reduces inference time from  $O(T)$  (change with input sequence length) to  $O(P)$  (fixed cycle length). To overcome inherent sampling resolution limitations, a dual-resolution channel model with weight-sharing PCFC is used for simultaneous inference. Extensive experiments and continuous wavelet transform (CWT) on the IES dataset at Arizona State University&#8217;s Tempe campus show that DMP-PCFC offers higher prediction accuracy and greater interpretability than existing methods, providing a new paradigm for downstream tasks based on other research methods, making it valuable for IES engineering applications. The code is publicly available at https://github.com/nuist-xf/DMP-PCFC</description></item><item><title>Uncertainty-Aware Flexibility of HVAC Systems in Buildings: From Quantification to Provision</title><link>http://ieeexplore.ieee.org/document/11193807</link><description>Buildings represent a promising flexibility source to support the integration of renewable energy sources, as they may shift their heating energy consumption over time without impacting users&#8217; comfort. However, the predicted flexibility potential of a building&#8217;s Heating, Ventilation, and Air Conditioning (HVAC) system is based on uncertain ambient weather forecasts and a typically inaccurate building thermal model. This paper presents an uncertainty-aware flexibility quantifier using a chance-constrained formulation. Because such a quantifier may be conservative, we additionally model real-time feedback in the quantification, in the form of affine feedback policies. Such adaptation can take the form of intra-day trades or rebound around the flexibility provision period. To assess the flexibility quantification formulations, we further assume that flexible buildings participate in secondary frequency control markets. The results show some increase in flexibility and revenues when introducing affine feedback policies. Additionally, we demonstrate that accounting for uncertainties in the flexibility quantification is necessary, especially when intra-day trades are not available. Even though an uncertainty-ignorant potential may seem financially profitable in secondary frequency control markets, it comes at the cost of significant thermal discomfort for inhabitants. Hence, we suggest a comfort-preserving approach, aiming to truly reflect thermal discomfort on the economic flexibility revenue, to obtain a fairer comparison.</description></item><item><title>Game-Based Optimization Method for Geo-Distributed Data Centers Under Customer Directrix Load Demand Response Mechanism</title><link>http://ieeexplore.ieee.org/document/11173940</link><description>This study considers geo-distributed data centers (DCs) with diverse load profiles, electricity prices, and renewable energy availability, aggregated within their respective local virtual power plants (VPPs). To optimize demand response (DR) within such a system, a two-stage decision-making framework is proposed. First, a potential game-based method is developed to decompose the total customer directrix load (CDL) into regional sub-CDLs, aligning with grid requirements while minimizing VPP adjustment costs. Second, an evolutionary game model optimizes workload allocation strategies for DCs across spatial and temporal dimensions, considering constraints of bounded rationality and incomplete information. The proposed models are rigorously analyzed for equilibrium existence, convergence, and stability. A case study based on Google&#8217;s geo-distributed DCs and local grid data demonstrates that the framework effectively enhances VPP revenues and reduces DC operational costs, especially during peak demand periods.</description></item><item><title>Multi-Objective Low-Carbon Scheduling Method for Data Centers Based on Ensemble Reinforcement Learning</title><link>http://ieeexplore.ieee.org/document/11201935</link><description>The explosive growth of GPU data centers is driven by the surging demand for machine learning, artificial intelligence, and high-performance computing applications, with the pressure on the power grid intensifying. Meanwhile, as renewable energy becomes more integrated into the grid, the carbon intensity of grid electricity varies at different times. This variability presents an opportunity for data centers to align their workloads with periods of high renewable energy generation and low carbon intensity, thereby reducing their operational carbon emissions. This paper proposes a multi-objective scheduling strategy to minimize carbon emissions and maximize quality of service (QoS) by identifying the Pareto front. The proposed strategy employs an integrated reinforcement learning model to dynamically integrate action strategies for multiple objectives. Results from a case study based on a real-world, large-scale data center illustrate the method&#8217;s effectiveness. This effectiveness arises from its dual-objective job scheduling strategy, which simultaneously reduces carbon emissions from electricity consumption and maintains a high quality of service in data centers. The method aims to promote the low-carbon operation of data centers, provide decision support, and facilitate coordination between data centers and power systems in real-world applications.</description></item><item><title>Stability Constrained Voltage Control in Distribution Grids With Arbitrary Communication Infrastructure</title><link>http://ieeexplore.ieee.org/document/11164977</link><description>We consider the problem of designing learning-based reactive power controllers that perform voltage regulation in distribution grids while ensuring closed-loop system stability. In contrast to existing methods, where the provably stable controllers are restricted to be decentralized, we propose a unified design framework that enables the controllers to take advantage of an arbitrary communication infrastructure on top of the physical power network. This allows the controllers to incorporate information beyond their local bus, covering existing methods as a special case and leading to less conservative constraints on the controller design. We then provide a design procedure to construct input convex neural network (ICNN) based controllers that satisfy the identified stability constraints by design under arbitrary communication scenarios, and train these controllers using supervised learning. Simulation results on the University of California, San Diego (UCSD) microgrid testbed illustrate the effectiveness of the framework and highlight the role of communication in improving control performance.</description></item><item><title>Virtual Power Plants for Frequency Regulation: A Learning-Based Method With Safety Guarantee</title><link>http://ieeexplore.ieee.org/document/11195783</link><description>Frequency safety is becoming increasingly critical in modern power systems due to the reduction of rotational inertia and governor damping. With advances in power electronics, the inverter-based resources (IBRs) installed in distribution networks can provide inertia and frequency support if their controllers are properly designed. In this paper, the virtual power plants (VPPs) framework is leveraged to aggregate and coordinate IBRs to provide inertial and primary-frequency responses. In particular, sufficient conditions are derived for the VPP central controller design to guarantee the transient frequency safety, including stability, the rate of change of frequency and Nadir requirements. On this basis, a nonlinear controller parameterization that satisfies these conditions automatically is proposed. The optimal VPPs control policies are trained by recurrent neural network (RNN)-based reinforcement learning and then fairly disaggregated to individual IBRs, ensuring that IBRs share the power injections for frequency response in proportion to their reserve capacities. Moreover, the controllers are equipped with a safety layer with trivial computation burden to satisfy critical constraint during implementation. Case studies demonstrate that the proposed control strategy outperforms linear controller and other cutting-edge learning-based control strategies.</description></item><item><title>Iterative Linear Programming-Based Angle-Relaxed Branch Flow Model and Its Application to Volt-Var Control</title><link>http://ieeexplore.ieee.org/document/11195819</link><description>This paper addresses the challenge of optimizing distribution networks under the increasing integration of distributed energy resources and the inherent nonconvexity of AC power flow equations. Traditional methods relying on conic-relaxed formulations often fail to accurately capture critical voltage and power flow dynamics, particularly when the optimization objective does not directly minimize current magnitudes. To overcome these limitations, we propose an iterative linear formulation for the angle-relaxed branch flow model (BFM-ar), termed BFM-it. This approach iteratively linearizes the branch flow equations and updates key parameters&#8212;such as losses and voltage estimates&#8212;so that each iteration solves a linear program that progressively converges to the true nonlinear AC power flow solution. Both mathematical analysis and numerical experiments confirm that the BFM-it achieves convergence with errors on the order of machine precision, while demonstrating superior performance in volt-var control compared to conventional methods. The proposed method not only enhances modeling accuracy but also offers a computationally efficient framework for real-time distribution network optimization.</description></item><item><title>Power Swing Trajectory Influenced by Virtual Impedance-Based Current-Limiting Strategy</title><link>http://ieeexplore.ieee.org/document/11203273</link><description>Grid-forming (GFM) inverter-based resources (IBRs) can emulate the external characteristics of synchronous generators (SGs) through appropriate control loop design. However, in systems with GFM IBRs, the apparent impedance trajectory under current limitation differs significantly from that of SG-based systems due to the limited overcurrent capability of power electronic devices. This difference challenges the power swing detection functions of distance relays designed for SG-based systems. This paper presents a theoretical analysis of the apparent impedance trajectory over a full power swing cycle under two typical current-limiting strategies: variable virtual impedance (VI) and adaptive VI. The analysis reveals that the trajectory under VI current-limiting strategies differs significantly from that of a conventional SG. The results also indicate that the control parameters affect the characteristics of the trajectory. In addition, the new trajectories challenge conventional power swing detection functions, increasing the risk of malfunction. Furthermore, the implementation of VI leads to a deterioration in system stability. The theoretical analysis is further validated through simulations on the MATLAB/Simulink platform.</description></item><item><title>Two-Stage Distributionally Robust Optimization Dispatch for Power Systems With Uncertain Small-Sample Wind and Photovoltaic Data</title><link>http://ieeexplore.ieee.org/document/11203248</link><description>Extreme meteorological phenomena (e.g., cold waves) are low-probability, high-impact events that present significant operational and dispatch challenges for new-energy power systems. 1) Insufficient data on wind and photovoltaic power generation hinder data-driven modelling. 2) The uncertainty of small-sample wind and photovoltaic data is difficult to characterize. Therefore, a two-stage distributionally robust optimization dispatch strategy for a power system based on small-sample wind and solar data with uncertainty is developed. First, a generalized modelling method for a conditional generative adversarial network (CGAN) is proposed, which increases the generation of hourly output data for wind and photovoltaic power. Considering the drawback of large prediction errors for wind power and photovoltaic power in small-sample cases, a two-stage distributionally robust optimization model based on the Wasserstein metric is constructed, which embeds hard constraints (e.g., the capacity constraint of wind and solar transmission lines) and soft constraints (e.g., prediction errors). This model is nonconvex, and exactly solving it incurs a heavy computational burden. Duality theory and relaxation approximation are adopted here; the robust two-stage-distribution model is transformed into a mixed-integer linear programming model, and the iterative Taylor formula algorithm is used to linearize the constraint conditions. A numerical example is provided to demonstrate that the proposed model and solution algorithm can not only address the uncertainty of small-sample wind and photovoltaic data but also reduce the system operating costs and increase the model-solving efficiency.</description></item><item><title>A Two-Stage Optimization Method for Real-Time Parameterization of PV-Farm Digital Twins</title><link>http://ieeexplore.ieee.org/document/11235949</link><description>Digital twins (DTs) are high-fidelity virtual models of physical systems. This paper details a novel two-stage optimization method for real-time parameterization of photovoltaic digital twins (PVDTs) using field measurements. Initially, the method estimates equivalent irradiance from PV power, voltage, and current data, eliminating the need for direct irradiance sensors. This is crucial for tuning the DT&#8217;s parameters to actual environmental conditions, thereby improving power prediction accuracy. The second stage focuses on refining these parameters by minimizing discrepancies between measured and predicted outputs. This optimization utilizes the estimated equivalent irradiance as a model input, maintaining synchronization with real-world conditions. Parameter updates are event-trigger, launched when deviations exceed predefined thresholds. This strategy optimizes prediction accuracy and manages communication loads efficiently. Validated with extensive data from a PV farm, this approach outperforms existing methodologies in predictive accuracy and operational efficiency, significantly improving the performance DTs in real-time grid operations.</description></item><item><title>Optimal Distribution of Grid-Following and Grid-Forming Converters for Charging Control of Electric Vehicles</title><link>http://ieeexplore.ieee.org/document/11181195</link><description>We address the problem of determining the optimal combination of grid-following (GFL) versus grid-forming (GFM) modes of control in electric vehicle charging stations (EVCSs) to maintain an acceptable balance between small-signal stability and voltage stability of electric distribution grids. We recall the state-space dynamic models of EVCSs operating in GFL and GFM modes and demonstrate how high charging rates of electric vehicles (EVs) in the GFL mode can impact small-signal performance. We then optimize the GFL-to-GFM ratio while also determining the optimal EV charging setpoints and a state-feedback controller to minimize the  $\mathcal {H}_{2}$ -norm of the grid transfer function (TF). To make the proposed optimization computationally favorable, we use participation factor analysis to identify the most dominant EVCSs in the GFM mode so that they can be prioritized for optimization. We validate our results using a modified model of the IEEE 33-bus power distribution test system with ten EVCSs.</description></item><item><title>Planning and Integration of a Multi-Robot Adaptive Charging Network for Voltage Regulation via Unscented Kalman Filter-Based Deep Reinforcement Learning</title><link>http://ieeexplore.ieee.org/document/11195829</link><description>High levels of electric vehicle (EV) penetration and load uncertainty pose significant challenges to traditional voltage regulation in distribution systems (DS), particularly concerning voltage drops. This study investigates the potential of a dual-service mode (V2V/V2G) for mobile charging using multiple charging robots, cooperating with conventional DS voltage regulation methods to enhance performance. Specifically, we propose a multi-robot adaptive charging network (MRACN) embedded in a three-level voltage regulation framework to address voltage violations. At the low level, we introduce a voltage security rule-based dispatch strategy for MRACN to mitigate EV-induced voltage drops. At the mid-level, we optimize day-ahead scheduling of on-load tap changers and capacitor banks via optimal power flow for long-term voltage regulation. At the high level, we employ an unscented Kalman filter-based deep reinforcement learning (UKF-DRL) approach to integrate MRACN into DSs for real-time voltage control. Experimental results demonstrate that MRACN effectively reduces voltage violations and enhances the flexibility of conventional voltage control systems. Moreover, the UKF-DRL method accelerates DRL training by nearly an order of magnitude compared to full AC power-flow solutions, with the overwhelming majority of state estimates deviating by no more than 2%.</description></item><item><title>A Resilience-Oriented Incentive Pricing Strategy for Power-Transportation Network Against Flood Hazards</title><link>http://ieeexplore.ieee.org/document/11197582</link><description>Extreme weather events, such as flood hazards, may superimpose damage on coupled power-transportation networks (PTNs). An effective approach is to guide electric vehicle (EV) owners to enhance grid resilience. However, the EV emergency response and incentive prices are not sufficiently quantified for the post-flood recovery of power distribution network (PDN). Thus, this paper develops a fault scenario generation method to capture the capacity attacks on coupled PTNs during flood hazards. Then, a resilience-oriented tri-level incentive pricing strategy of EV emergency response is proposed for PDN post-flood recovery. At the upper level, EV charging station (EVCS) operators decide incentive pricing strategies for EV emergency response services by assessing the coupled relations of EV discharging/path strategies and PDN subsidy. At the middle level, a modified traffic model is proposed to capture the EV owner&#8217;s inconvenience cost associated with emergency response. At the lower level, a resilience metric incorporating EV discharging responses is introduced to mitigate load curtailment of PDN. Furthermore, a decomposition method based on column generation and optimal path set pre-assignment is proposed to address the urgency and destination uncertainty in emergency responses. Numerical results illuminate that the proposed strategy could reduce 41% of the peak load power shedding.</description></item><item><title>Intrusion Detection System for Digital Substations Using Semi-Supervised Learning and Traffic Distance Similarity Clustering</title><link>http://ieeexplore.ieee.org/document/11168910</link><description>Cyber attacks on power grids are imminent and potentially have a severe impact, as evidenced by the cyber attacks in Ukraine in 2015, 2016, and 2022. In response to this challenge, machine learning-based Intrusion Detection Systems (IDS) have become more prevalent as a potential mitigation owing to their alignment with the latest advances in artificial intelligence. However, existing anomaly detection methods for power grid Operational Technology (OT) are often inadequate, as they primarily focus on detecting power grid physical anomalies at the later attack stages and suffer from the scarcity of available data for supervised machine learning. To address these limitations, we propose a novel semi-supervised IDS specifically for digital substations of the power system. The proposed detection method identifies the distinctive distance similarity of digital substation OT communication traffic using a Convolutional Neural Network and Chebyshev distance of packet payloads, and Kolmogorov-Smirnov of packets&#8217; interarrival time using Fast Fourier Transform amplitude. Subsequently, these traffic features are combined into a vector and classified using a novel hybrid semi-supervised Self-Organizing Map (SOM) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN). Results indicate that the proposed method can identify zero-day attacks and achieve accuracy and F1 above 95%.</description></item><item><title>A Dual Power Grid Cascading Failure Model for the Vulnerability Analysis</title><link>http://ieeexplore.ieee.org/document/11175257</link><description>When considering attacks against the power grid, one of the most effective approaches could be the attack to the transmission lines that leads to large cascading failures. Hence, the problem of locating the most critical or vulnerable transmission lines for a Power Grid Cascading Failure (PGCF) has drawn much attention from the research society. There exist many deterministic solutions and stochastic approximation algorithms aiming to analyze the power grid vulnerability. However, it has been challenging to reveal the correlations between the transmission lines for the critical line identification. In this paper, we propose a novel approach that learns such correlations, based on self-supervised learning and the self-attention mechanism, which is inspired by the Transformer model for natural language processing (NLP). Once the correlations are learned, a ranking algorithm is introduced for the critical line identification. With extensive experiments comparing our approach versus 2 other benchmark algorithms, it is proven that the proposed Dual PGCF model provides a novel and effective solution for critical line identification.</description></item><item><title>Scalable Voltage Control for DC Microgrids: Robustness to Network Structural Variations</title><link>http://ieeexplore.ieee.org/document/11180064</link><description>Frequent plug-in/-out operations result in structural variations of DC microgrids (DCmGs), posing challenges to scalable control and often requiring costly redesigns to maintain stability. To address this issue, this paper proposes a scalable voltage control strategy for uncertain DCmGs, enabling plug-and-play functionality without controller redesign or system reconfiguration. A polytopic uncertain DCmG model is first formulated to simultaneously capture parameter uncertainties in distributed generation units (DGUs), power lines, and ZIP (i.e., impedance, current, and power) loads. A structured free-weight matrix technique is then developed to mitigate the adverse effects of line and load uncertainties on DGUs while yielding a more tractable linear matrix inequality formulation. The proposed scalable control method is implemented locally to ensure the dissipative voltage stability of each DGU, thereby preserving the dissipativity of the entire network. Numerical simulations validate the effectiveness of the proposed strategy in achieving faster convergence and reduced overshoot.</description></item><item><title>An SDN-Based Framework for Cyber-Physically Coordinated Voltage Support of Virtual Power Plants Against DoS Attacks</title><link>http://ieeexplore.ieee.org/document/11181222</link><description>The integration of distributed energy resources (DERs) into smart grids is accelerating worldwide. However, the growing reliance on information and communication technologies (ICTs) for real-time monitoring and control in large-scale DER aggregations introduces significant cybersecurity risks. Among these, denial-of-service (DoS) attacks pose a critical threat, with the potential to severely disrupt system operations. To address these challenges, this paper proposes a security-by-design framework for large-scale DER aggregation in the context of virtual power plants (VPPs), with a focus on enhancing the resilience of voltage support services. Central to this framework is a cyber-physical coordinated control architecture that leverages software-defined networking (SDN) to dynamically adapt to variations in both the cyber and physical layers. Specifically, a cyber-aware voltage control algorithm is developed to coordinate DERs based on the real-time status of the communication network, while a physically informed network configuration algorithm adjusts communication paths according to voltage support priorities. The proposed approach is evaluated through cyber&#8211;physical co-simulations on both the IEEE 123-bus test system and the 240-bus test system, based on a real-world distribution system located in the Midwest U.S., under server DoS attack scenarios. Results demonstrate that the SDN-enabled coordination significantly mitigates server DoS attacks, confirming the framework&#8217;s effectiveness and robustness. This work offers a scalable and resilient solution for securing large-scale DER aggregation and integration against evolving cyber threats.</description></item><item><title>Post-Disaster Multi-Timescale Coordinated Restoration of Power and Thermal Cyber-Physical System Considering Hot Standby Resources</title><link>http://ieeexplore.ieee.org/document/11184621</link><description>After extreme natural disasters, the inherent coupling between the cyber and physical components of power and thermal cyber-physical systems (PTCPS) facilitates the coordinated emergency resources from both domains, thereby expediting system restoration. Previous research has overlooked the influences of hot standby emergency resources and actual services in post-disaster restoration. Taking into account thermal inertia (TI) and wireless communication emergency resources, this paper proposes a post-disaster multi-timescale coordinated restoration method for PTCPS, aiming to minimize load loss, reduce emergency costs, decrease communication delays, and maximize distributed generation (DG) absorption. Firstly, models for TI, wireless communication, and repair crew emergency resources are established, and the multi-timescale coordination emergency resources are formed. Secondly, based on the switch control and load control services, a cyber-physical interaction model is constructed, and a dynamic networking model for wireless communication with wired communication node access is established. Then, the communication network, physical system operations, and topology reconfiguration models are constructed. To optimize the numerous unconventional nonlinear constraints in the proposed model, the logical constraint and Big-M methods are introduced in linearization techniques, the multiple linearization methods are derived. Finally, case studies are conducted using an improved RBTS-Bus2 power system/12-node thermal system, demonstrating the effectiveness of the proposed method through comparisons with two benchmarks and highlighting the necessity of multi-timescale emergency resources and cyber-physical interaction.</description></item><item><title>Dynamic PMU Configuration for Stealthy Multi-Snapshot FDIA Mitigation: Enhancing Security in Hybrid-Measurement-Based State Estimation in Power Systems</title><link>http://ieeexplore.ieee.org/document/11184615</link><description>Modern power systems have evolved into cyber-physical power systems (CPPSs) requiring high-resolution spatial-temporal state awareness, driving the adoption of hybrid measurement-based state estimation (SE). However, such advancements introduce heightened cybersecurity requirements that demand systematic investigations from adversarial perspectives. This paper establishes a comprehensive attacker-defender framework with dual contributions. From the attacker&#8217;s perspective, this paper proposes a multi-snapshot coordinated false data injection attack (MS-FDIA) strategy against hybrid measurement-based SE. The proposed attack model can effectively bypass both hybrid measurement synchronization checks and temporal data anomaly detection mechanisms, thereby achieving enhanced stealth and operational impact. From the defender&#8217;s perspective, this paper develops a dynamic trusted phasor measurement unit (PMU) configuration scheme that adaptively reconfigures secure measurement matrix subsets against evolving multistage attacks. The defense mechanism is solved through two complementary approaches: a numerical algorithm based on matrix row transformations and a deep reinforcement learning (DRL)-based optimization method with temporal awareness. Comprehensive case studies on different standard test systems demonstrate the improved MS-FDIA mitigation capabilities and the defense scheme&#8217;s effectiveness, and the test results reveal the matrix transformation algorithm&#8217;s superiority in small-scale systems versus DRL&#8217;s scalability advantages for large networks.</description></item><item><title>Communication-Aware Wide-Area Damping Control Using Risk-Constrained Reinforcement Learning</title><link>http://ieeexplore.ieee.org/document/11222886</link><description>Non-ideal communication links, especially delays, critically affect fast networked controls in power systems, such as the wide-area damping control (WADC). Traditionally, a delay estimation and compensation approach is adopted to address this cyber-physical coupling, but it demands very high accuracy for the fast WADC and cannot handle other cyber concerns like link failures or cyber perturbations. Hence, we propose a new risk-constrained framework that can target the communication delays, yet amenable to general uncertainty under the cyber-physical couplings. Our WADC model includes the synchronous generators (SGs), and also voltage source converters (VSCs) for additional damping capabilities. To mitigate uncertainty, a mean-variance risk constraint is introduced to the classical optimal control cost of the linear quadratic regulator (LQR). Unlike estimating delays, our approach can effectively mitigate large communication delays by improving the worst-case performance. A reinforcement learning (RL)-based algorithm, namely, stochastic gradient-descent with max-oracle (SGDmax), is developed to solve the risk-constrained problem. We further show its guaranteed convergence to stationarity at a high probability, even using the simple zero-order policy gradient (ZOPG). Numerical tests on the IEEE 68-bus system not only verify SGDmax&#8217;s convergence and VSCs&#8217; damping capabilities, but also demonstrate that our approach outperforms conventional delay compensator-based methods under estimation error. While focusing on performance improvement under large delays, our proposed risk-constrained design can effectively mitigate the worst-case oscillations, making it equally effective for addressing other communication issues and cyber perturbations.</description></item><item><title>Load Forecasting Model Trading: A Cost-Oriented and Auction-Based Approach</title><link>http://ieeexplore.ieee.org/document/11181218</link><description>Data sharing is essential for accurate load forecasting and efficient energy management, yet data exchange remains severely constrained by a lack of effective economic incentives. Data markets have emerged as a potential solution by incentivizing the exchange of data and forecasting resources among stakeholders. Existing data market mechanisms, often designed around trading raw data or forecast outputs, face multiple barriers&#8212;such as privacy concerns, valuation misaligned with real operational benefits, unilateral pricing, computationally intensive allocation, and inflexible asset adaptation&#8212;that limit their practicality for real-world energy applications. The aim of this paper is to address these challenges by proposing a novel market framework that treats pre-trained forecasting models as tradable assets, thereby fundamentally redefining the data market paradigm. Specifically, a cost-oriented evaluation approach that links model quality to downstream operational costs is first established as the foundation throughout the entire market process. Subsequently, we propose a bilateral iterative model auction mechanism to enable efficient transactions between the buyer and sellers while maximizing social welfare. Furthermore, we propose a model adaptation strategy, including model fine-tuning and ensembling, for the buyer to enhance the applicability of purchased models to his decision-making problem. Case studies in building energy management based on public datasets demonstrate that our approach converges to the socially optimal solution, allowing all participants to benefit: sellers are appropriately compensated for providing high-quality models, and buyers achieve significant operational cost reductions through the utilization of traded models.</description></item><item><title>Forced Oscillation Recognition With Interpretable Network Framework for Class Imbalance and Limited Real-World Data</title><link>http://ieeexplore.ieee.org/document/11200994</link><description>Deep learning (DL) holds significant potential for distinguishing forced oscillations (FOs) from natural oscillations (NOs) and resonances in power systems. However, most existing studies treat DL models as opaque system classifiers, and these models are often susceptible to challenges such as class imbalance among the three oscillation patterns (i.e., FOs, NOs, and resonances) and the limited size of real-world training datasets. These issues can lead to incorrect diagnoses of oscillation patterns in practical applications. To address these challenges, we propose a FO oscillation recognition framework that integrates balanced data processing, an interpretable recognition network, and a fine-tuning learning strategy. In this framework, DeepSMOTE1D is introduced to address the issue of class imbalance by oversampling features extracted from an encoder-decoder network. The interpretable DWT-CNN-LSTM recognition network incorporates multiple discrete wavelet transforms (DWT) into each convolutional and LSTM layer to enhance both interpretability and performance of the model. Finally, a fine-tuning transfer learning strategy is employed, where the recognition network is first pretrained on simulation data and subsequently retrained on limited real-world data. The effectiveness of DeepSMOTE1D and the fine-tuning strategy in the proposed framework is also evaluated. Experimental results show that the proposed recognition model not only learns effectively from simulated oscillation data but also outperforms existing related networks in real-world scenarios, achieving superior accuracy, precision, recall, and F1-score.</description></item><item><title>OptDisPro: LLM-Based Multi-Agent Framework for Flexibly Adapting Heuristic Optimal DisFlow</title><link>http://ieeexplore.ieee.org/document/11201936</link><description>The existing generative coding of distribution grids modeling and optimization face several issues, like complicated usage or high auto-codes error rates. This paper proposes the OptDisPro, a novel LLM-based multi-agent framework, enabling automatic optimal power flow (OPF) script modeling and solving. Driven by interactive linguistic instruction, it realizes automatic coding for customized requirements and flexibly adaptive heuristic optimization. Specifically, domain expertise and example scripts are encoded into structured prompt sequences to guide OptDisPro and enhance reasoning via Chain-of-Thought (COT). To mitigate LLM hallucinations, a contextual feedback mechanism is introduced, which collects error messages from the run-time environment for self-correction. Furthermore, Adaptive Selection of Multiple Algorithms (ASMA) is applied in the solving process, flexibly selecting heuristic algorithms to decrease the possibility of local optima. According to cases verification in multiple scenarios, the simulation results demonstrate the effectiveness and stability of OptDisPro in OPF problem of distribution network. The results also encourage further exploration of LLM applications in script online self-updating, autonomous OPF problem-solving and intelligent operation within distribution grid.</description></item><item><title>Learning Data-Driven Uncertainty Set Partitions for Robust and Adaptive Energy Forecasting With Missing Data</title><link>http://ieeexplore.ieee.org/document/11202569</link><description>Short-term forecasting models typically assume the availability of input data (features) when they are deployed and in use. However, equipment failures, disruptions, cyberattacks, may lead to missing features when such models are used operationally, which could negatively affect forecast accuracy, and result in suboptimal operational decisions. In this paper, we use adaptive robust optimization and adversarial machine learning to develop forecasting models that seamlessly handle missing data operationally. We propose linear- and neural network-based forecasting models with parameters that adapt to available features, combining linear adaptation with a novel algorithm for learning data-driven uncertainty set partitions. The proposed adaptive models do not rely on identifying historical missing data patterns and are suitable for real-time operations under stringent time constraints. Extensive numerical experiments on short-term wind power forecasting considering horizons from 15 minutes to 4 hours ahead illustrate that our proposed adaptive models are on par with imputation when data are missing for very short periods (e.g., when only the latest measurement is missing) whereas they significantly outperform imputation when data are missing for longer periods. We further provide insights by showcasing how linear adaptation and data-driven partitions (even with a few subsets) approach the performance of the optimal, yet impractical, method of retraining for every possible realization of missing data.</description></item><item><title>Frequency-Aware Multi-Task Forecasting for Integrated Energy Systems via Variational Mode Decomposition and Convolution-Attention Encoding</title><link>http://ieeexplore.ieee.org/document/11205895</link><description>Integrated Energy Systems (IESs) integrate electricity, heating, cooling, and gas through coupled infrastructures, posing forecasting challenges due to heterogeneous temporal patterns and cross-energy interference. These heterogeneous temporal patterns often reflect distinct frequency characteristics, which existing multi-task approaches struggle to disentangle due to the lack of frequency-aware task decoupling. To address this, this paper proposes VATLNet, a unified multi-task forecasting framework that integrates frequency-aware task decoupling with hybrid convolution-attention feature extraction. Specifically, multivariate energy inputs are decomposed via variational mode decomposition, and the resulting components are clustered into frequency-similar groups based on sample entropy. A shared encoder combining temporal convolutional networks and multi-head attention extracts frequency features across all clusters, which are then independently decoded by parallel long short-term memory network branches. Extensive experiments on real-world IES load datasets demonstrate that VATLNet outperforms state-of-the-art baselines, achieving 2.44% and 1.03% MAPE in single- and multi-task forecasting, respectively. The framework improves cross-frequency-aware feature extraction, reduces inter-task interference, and enhances forecasting robustness and interpretability across diverse energy modalities.</description></item><item><title>Smart Meter Scheduling for Data-Driven Granular Customer Voltage Visibility</title><link>http://ieeexplore.ieee.org/document/11215656</link><description>The integration of distributed energy resources (DERs) in power distribution systems introduces greater voltage volatility. Supervisory control and data acquisition (SCADA) measurements at medium-voltage (MV) networks cannot directly monitor customer-end voltages; smart meters provide direct customer-end voltages but have insufficient reporting rates to track short-term voltage fluctuations due to DERs. This paper proposes an approach to high-resolution voltage monitoring at all customer points based on low-resolution smart meter measurements. This is based on staggered smart meter data acquisition: smart meters are grouped into subsets, each of which contains enough information to estimate the voltages of all customers. These subsets of smart meters are scheduled to report their data at different times rather than simultaneously. Then, at each instant when a subset of meters reports their measurements, a data-driven method is used to estimate all the unreported customer voltages by utilizing voltage measurements of the reporting subset. To support multi-customer estimation with minimal computational overhead, an eXtreme Gradient Boosting (XGBoost) model is chosen due to its efficiency and robustness. This approach ensures high-resolution voltage estimation (HiVE) without the need of increasing the reporting rate of smart meters. Extensive simulations on real-world smart meter datasets demonstrate the effectiveness of the proposed method.</description></item><item><title>Aperiodic Sampling Load Frequency Control of Wind Power-Integrated Power Systems With Packet Losses and Delays Under Discrete Time Feedback Interconnection Model</title><link>http://ieeexplore.ieee.org/document/11181202</link><description>This paper explores the stability assessment and the development of controllers for aperiodic sampling load frequency control scheme for wind power-integrated power systems, accounting for communication delays and packet losses. Firstly, transform the multi-area continuous time model into a discrete time load frequency control model. By incorporating linear operators to manage the uncertainties including communication delays, packet losses and sampling interval within the system, the discrete time load frequency control system is converted into a feedback interconnected system that consists of uncertain operators and linear time-invariant systems. Secondly, the exponential stability condition of the system is given by utilizing the integral quadratic constraint theory and linear matrix inequality technique, which can be used to compute the upper bounds for aperiodic sampled-data intervals and delays. Furthermore, based on the proposed stability conditions, a controller iteration optimization algorithm is designed, which effectively addresses issues related to delays and packet losses. Finally, an example study based on one-area, three-area load frequency control system and IEEE 39-bus system show that the method can obtain larger sampling upper bounds and better control performance than previous methods.</description></item><item><title>A Cross-Level Consistency-Aware Diffusion Model of Hierarchical Imputation for Energy Prosumers</title><link>http://ieeexplore.ieee.org/document/11168916</link><description>Motivated by the aggregation structure of prosumers from energy communities within a region, this letter proposes a cross-level consistency-aware diffusion model for solving the hierarchical imputation problem (CDHI), directly processing three-dimensional (3D) hierarchical time series. In CDHI, a 3D attention mechanism of hierarchical, temporal, and feature Transformer layers is developed to capture the aggregated dependency of hierarchical series. Based on mask modeling, we extend imputation target choice strategies of missing patterns, thus training CDHI in a self-supervised manner. For implementation, we formulate the aggregation structure of prosumers as the hierarchical consistency across aggregation levels in the denoising loss function of CDHI.</description></item><item><title>Coupled Task Allocation and Path Planning for Energy-Optimal Multi-AUG Multi-Target Exploration</title><link>http://ieeexplore.ieee.org/document/11113332</link><description>Autonomous underwater gliders (AUGs), as low-energy mobile observation platforms, offer significant potential for multi-target exploration tasks. However, existing studies typically use Euclidean distance to decouple task allocation from path planning, ignoring the effects of ocean currents and seabed topography on task performance. To address this gap, we develop an asymmetric energy consumption matrix that incorporates pitch angle and diving depth as decision variables, enabling energy-optimal path planning between targets. Subsequently, we propose a Discrete Artificial Bee Colony algorithm with Enhanced Search Strategies (DABC-ESS) for optimal task allocation. DABC-ESS integrates a greedy insertion initialization method with three innovative search strategies: enhanced neighborhood search, enhanced insertion, and enhanced destruction-reconstruction. The effectiveness of these strategies is validated through ablation studies, while comparative experiments against five state-of-the-art algorithms demonstrate the superior performance of DABC-ESS. Furthermore, our method achieves greater energy efficiency than the latest multi-AUG task allocation approach, highlighting its potential for complex underwater tasks.</description></item><item><title>SP-CPP: Semi-Physical Coverage Path Planning for Offshore Morphological Survey Aided by Autonomous Surface Vehicles</title><link>http://ieeexplore.ieee.org/document/11120394</link><description>Coverage path planning for autonomous surface vehicles (ASVs) is crucial for underwater morphological surveys. However, current coverage path planning methods for practical surveys are inadequate. The main challenge arises from the fact that typical path-length/turning-number objective of current studies fails to directly minimize the energy consumption as they neglect the nonlinear hydrodynamic characteristics of vessel maneuvering. Furthermore, the intricate coastline features segment the offshore region into various complex areas, posing a significant challenge to CPP. To address these issues, for the first time, this research proposes the idea of establishing the CPP model by solving the nonlinear maneuvering differential equations of ASVs, referred to as Semi-Physical Coverage Path Planning (SP-CPP). SP-CPP can accurately captures the hydrodynamic characteristics of ASVs operating on water and comprehensively address large-scale and complex cases by jointly optimizing factors including survey orders, entry and exit selection, and sweep direction. Simultaneously, we propose a novel hierarchical heuristic approach which is able to quickly find optimal solutions for SP-CPP. Comprehensive simulations have been conducted across both large- and small-scale problem instances. The results indicate that SP-CPP demonstrates superior performance over state-of-the-art models, with its superiority becoming more pronounced as the problem scale increases. Finally, lake trials have been conducted using a real ASV to demonstrate the effectiveness of SP-CPP in practical applications.</description></item><item><title>Efficiency Optimization for Blockchain-Enabled V2V Energy Trading With Dynamic Clustering Based on Deep Reinforcement Learning</title><link>http://ieeexplore.ieee.org/document/11119334</link><description>Vehicle-to-Vehicle (V2V) energy trading is a feasible solution to alleviate charging anxiety and enhance the range of electric vehicles (EVs). Clustering EVs can improve the efficiency of both energy transfer and V2V communication. However, in the complex large-scale Internet of Electric Vehicles (IoEV), the security and reliability of trading and communication, as well as the impact of cluster number and strategy on trading efficiency, require further discussion. This paper proposes a V2V energy trading system that leverages blockchain sharding and dynamic clustering to securely record energy trades as transactions on the blockchain. The system forms clusters using a clustering algorithm based on the mobility information and power levels of EVs, ensuring the reachability of energy trading. These trading clusters correspond to blockchain shards, enhancing transaction throughput through sharding scalability. Deep reinforcement learning (DRL) is employed to optimize the number of clusters, clustering algorithms, and parameters of the sharded blockchain system under security and latency constraints. The results demonstrate that the proposed scheme ensures timely power replenishment for low-power vehicles, improves overall economic utility and throughput for participants, and is effectively applicable to large-scale V2V energy trading scenarios.</description></item><item><title>Physics-Informed Enhanced Fourier Neural Operator for Solving Pantograph-Catenary Interaction in Electric Railway</title><link>http://ieeexplore.ieee.org/document/11125493</link><description>In electric railway systems, the interaction performance of pantograph-catenary systems (PCS) is essential for ensuring a stable electrical supply. Establishing high-fidelity numerical models using the finite element method is generally desirable, yet it involves considerable computational complexity and time demands. In this paper, we propose a novel dynamic modelling method that integrates physical information and data-driven approaches to solve the pantograph-catenary interaction, called Physics-Informed Enhanced Fourier Neural Operator (PI-EFNO). Firstly, the enhanced Fourier Neural Operator (EFNO) based on global perceptron is developed to capture the nonlinear mapping between parameter space and output solution space by approximating solutions to dynamic equations in the frequency domain. Then, we integrate multiple physics-informed loss terms into the EFNO architecture to handle implicit constraints within coupled equations, which leverages physical principles to guide learning while reducing the need for labelled training data. Additionally, a dynamic weighting mechanism adaptively balances the contributions of various terms in the physics-based loss function. Experimental results validate the effectiveness and advantages of PI-EFNO in modelling pantograph-catenary dynamics. It demonstrates exceptional accuracy, computational efficiency, and generalizability across diverse pantograph models and catenary conditions, exhibiting strong capability in learning physically coupled equation systems.</description></item><item><title>Multi-Gate Mixture-of-Experts for Predistortion of Power Amplifiers in Satellite Multi-Antenna System</title><link>http://ieeexplore.ieee.org/document/11114953</link><description>To meet the high data rate and large capacity demands of communications, multi-antenna technology is widely adopted in satellite communication systems, significantly increasing system capacity and spectrum efficiency by transmitting data through several links. However, the increase in the number of transmission paths introduces significant challenges, such as power amplifier (PA) nonlinearity and inter-antenna crosstalk. Traditional digital predistortion (DPD) techniques typically rely on independent compensation for each PA, which leads to high hardware complexity and scalability issues. Moreover, signal crosstalk distorts the feedback signal used for DPD parameter estimation, thereby degrading the accuracy of the nonlinear modeling. To solve the abovemetioned problems, this paper proposes a novel DPD approach that jointly compensates multiple PAs using a single model, thereby ensuring beam linearity while substantially reducing hardware overhead. Specifically, we design a multi-gate mixture-of-experts-based DPD model to mitigate PA nonlinear distortions and multi-antenna crosstalk. The proposed model formulates the inverse modeling of each PA as a multi-task learning problem, in which shared and task-specific representations are jointly leveraged to extract both common and distinctive nonlinear features, thereby enabling efficient and simultaneous compensation across multiple PAs. Experimental evaluations show that the proposed method outperforms conventional polynomial-based and neural network-based approaches in compensating for nonlinear distortions and suppressing inter-antenna crosstalk. Specifically, in a 4-paths antenna array, the proposed model achieves an improvement of 2 dB in adjacent channel power ratio (ACPR) and a 3 dB reduction in normalized mean square error (NMSE).</description></item><item><title>Towards Integrated Sensing in Multi-Tier Multi-User MEC: A DRL-Driven RSMA-Assisted Approach</title><link>http://ieeexplore.ieee.org/document/11120392</link><description>This paper investigates a multi-tier multi-user mobile edge computing (MEC) network with integrated sensing and communication (ISAC), where the base station (BS) first receives computational tasks from $K$ users while simultaneously performing target sensing in an environment with $M$ clutter sources, and then the BS processes both the communication and sensing data, dynamically offloading portions of the computational tasks to the cloud server (CS) while maintaining the sensing performance. Such a system faces significant challenges, particularly in managing interference between sensing and communication processes. The primary goal of this study is to address this interference problem while simultaneously optimizing the performance and resource efficiency of both phases. To tackle these challenges, we employ uplink rate-splitting multiple access (RSMA) to enhance spectral efficiency during the communication phase and indirectly support the sensing phase by mitigating interference, optimizing resource allocation, and preventing resource congestion. Specifically, we formulate an optimization problem that jointly considers computational data rate, beamforming design, and power allocation. This problem is solved using a reinforcement learning-based soft actor-critic (SAC) method. Simulation results demonstrate that the RSMA-assisted system achieves at least 40% higher spectral efficiency than conventional non-orthogonal multiple access (NOMA) while maintaining robust sensing performance, even under the stringent QoS constraints.</description></item><item><title>Resource Optimization for Secure Transmission in Combined Radar and Multicast-Unicast Systems Supported by RIS and NOMA</title><link>http://ieeexplore.ieee.org/document/11119323</link><description>In this research, we explore the secure communication within a system that integrates radar functionality with multicast and unicast communication (Rad-MU-Com), utilizing both reconfigurable intelligent surfaces (RIS) and non-orthogonal multiple access (NOMA). A dual-function base station (BS) sends combined multicast and unicast signals to communication-centric users (C-users) and radar-centric users (R-users) while detecting the R-users. In particular, multicast signals are intended for both C-users and R-users, whereas unicast messages are exclusively directed to C-users. Initially, we investigate an integrated Rad-MU-Com configuration with a single C-user and a single R-user, employing RIS and NOMA technologies to enhance transmission effectiveness. We formulate an optimization challenge aimed at maximizing the secrecy rate of the unicast signal. This is accomplished by concurrently optimizing both the transmit beamforming vectors and the RIS reflection coefficient matrix, with a constraint on maintaining similarity between the transmit beampatterns and the radar's desired beampatterns. To generalize from the single-pair scenario, we further examine a cluster-based Rad-MU-Com scheme that incorporates several pairs of C-users and R-users, with the assistance of RIS and NOMA technologies. The objective of the optimization challenge at hand is to maximize the minimum achievable secrecy rate of the unicast signal. This is accomplished by collaboratively optimizing the RIS's reflection coefficient matrix, the transmission beamforming vectors at the BS, and the power distribution parameters, with respect to the corresponding system constraints. To address the two optimization challenges, we introduce a low-complexity iterative framework that breaks down the original problems into multiple subproblems, each of which can be approximately solved. Simulation findings indicate that the secrecy performance of the proposed system, which incorporates RIS and NOMA, surpasses that of the traditional joint Rad-MU-Com system using RIS and orthogonal multiple access.</description></item><item><title>STAR-RIS-Empowered Monitoring Over Two-Way Suspicious Communications</title><link>http://ieeexplore.ieee.org/document/11125872</link><description>This paper investigates a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) empowered wireless surveillance system, where a pair of suspicious nodes send messages to each other in separate time phases, and the suspicious signal is simultaneously decoded by a monitor through a STAR-RIS-enhanced link for surveillance purposes. During the STAR-RIS-assisted monitoring, cooperative jamming (CJ) can also be leveraged by the monitor to disturb the receiver of the two-way suspicious communications, so as to benefit from the full-space coverage of STAR-RISs. We propose the STAR-RIS and CJ-assisted monitoring (SR-CJM) scheme, the STAR-RIS-assisted passive monitoring (SR-PM) scheme, and derive analytical expressions of their surveillance success probabilities (SSPs) for both infinite and finite phase-shift resolutions at the STAR-RIS, respectively. Since the closed-form and asymptotic analyses facilitate an optimization of the transmission-coefficient amplitudes of the STAR-RIS, we further present the SR-CJM with an optimal transmission coefficient (OTC), denoted by the SR-CJM-OTC scheme. Numerical results not only validate the closed-form SSP analysis and the robustness of proposed schemes for different phase-shift resolutions, but also verify that faced with two-way suspicious communications, the proposed SR-CJM outperforms the conventional pure-transmission/reflection RIS assisted CJ-assisted monitoring (CR-CJM) in terms of the SSPs. Besides, the SR-CJM shows its surveillance performance advantage over the SR-PM, and the performance can be further improved by exploiting more degrees of freedom provided by the transmission-coefficient amplitudes of the STAR-RIS, especially in the high jamming power region.</description></item><item><title>A Novel Spatio-Temporal Rate-Splitting-Based Power Allocation Optimization Strategy for RIS-Assisted 6G MU-MISO Communication Systems</title><link>http://ieeexplore.ieee.org/document/11113353</link><description>Reconfigurable intelligent surfaces (RISs) can dynamically adjust phase shifts to achieve scalability in networks, while rate-splitting multiple access (RSMA) can dynamically allocate spectrum and power resources according to the communication needs of IoT devices and reduce the energy consumption of the system. Therefore, the integration of RIS and RSMA can not only enhance the performance of IoT communication systems, but also reduces wastage of limited resources. This paper proposes a novel spatio-temporal rate-splitting-based power allocation optimization strategy for RIS-assisted multi-user (MU) systems to maximize channel capacity and energy efficiency gains. Leveraging the proposed spatio-temporal minimum mean squared error (STMMSE) principle and the rate splitting-based optimal power consumption (RS-OPC) method, the approach considers the Cram&#233;r-Rao bound for channel errors and derives expressions for maximizing channel capacity and obtaining the optimal solution. The proposed method selectively adjusts power values for different users and transmission types of symbols to achieve optimal power allocation objectives, thereby ensuring communication quality while optimizing channel capacity. This offers communication systems a higher configurability and resource optimization. Extensive simulation results including channel capacity, energy efficiency (EE) and spectral efficiency (SE) validate the effectiveness of the proposed method.</description></item><item><title>A New Achievable Rate for Decode-Forward-Based Gaussian Relay Channel With Hybrid-Duplex</title><link>http://ieeexplore.ieee.org/document/11113337</link><description>Combining half-duplex (HD) and full-duplex (FD) has shown great potential to improve the transmissionrate of relay channels. To approach the channel capacity of Gaussian relay channel, a novel three-phase hybrid-duplex (HyD) scheme was proposed based on decode-forward (DF) relaying. Apart from the pure FD mode, the relay works in receive-only and transmit-only modes for a fraction of time, respectively. The achievable rate of the proposed scheme is characterized. Furthermore, a joint time division and power allocation problem is formulated, aiming at maximizing the achievable rate of the proposed HyD relaying scheme. In particular, a two-step optimization method is raised to solve the formulated problem. Firstly, the local optimal power allocation is obtained for given time division factors. Then, the maximization of the achievable rate is addressed by finding the optimal time division factors, leading to a new achievable rate of the DF-based Gausian relay channel. A degenerated two-phase hybrid-duplex (D-HyD) scheme is also studied to reduce the implementation complexity. Additionally, the maximal achievable rate of the D-HyD scheme is derived in closed-form for specific scenarios. Numerical results demonstrate that, when using optimal parameters, the proposed three-phase HyD scheme and its two-phase variant can significantly enhance the rate performances of Gaussian relay channel, outperforming pure HD, pure FD, and other benchmark DF-based relaying schemes.</description></item><item><title>Enhancing Physical Layer Security of URLLC Using Artificial Noise in Full-Duplex Cooperative NOMA</title><link>http://ieeexplore.ieee.org/document/11115032</link><description>In this paper, we propose enhancing physical layer security (PLS) of ultra-reliable low latency communication (URLLC) in a full-duplex cooperative non-orthogonal multiple access (FD-CNOMA) based Internet of Things (IoT) network. We analyze the PLS performance of a two-user FD-CNOMA system, where a source node transmits the short packet URLLC information to a near user and a far cell-edge user in the presence of an external eavesdropper. To ensure the security and reliability of URLLC signal transmission, the near user is utilized as a cooperative relay for transmitting the information intended for the far user, and also transmits an artificial noise (AN) signal to mitigate the impact of eavesdropping. An approximate closed-form expression of the average secure block error rate (SBLER) and the average secrecy throughput (AST) of the legitimate users under eavesdropping is derived. The analytical framework presented in this work considers the URLLC signal transmission with and without AN signal while evaluating the impact of residual self-interference (RSI) at the relay node on the PLS performance of the FD-CNOMA system. Thus, to improve the PLS performance and maximize the system AST, we optimize the URLLC blocklength and power allocation coefficient (PAC) at the source. The numerical and simulation results validate the proposed analytical framework and demonstrate a significant improvement of average SBLER and overall system AST (SAST) using AN-assisted URLLC signal transmission in the FD-CNOMA system.</description></item><item><title>3D Trajectory Optimization for Energy-Efficient UAV Communication With Obstacle Constraints</title><link>http://ieeexplore.ieee.org/document/11119314</link><description>In this paper, we address the challenges faced by a UAV in multi-obstacle environments, where frequent flight path adjustments increase energy consumption and obstacles impede communication. To tackle these issues, we propose a UAV-assisted ground user communication system, where a fixed-wing UAV navigates a complex multi-obstacle environment. Based on this model, we formulate an optimization problem to maximize the UAV's energy efficiency by optimizing its 3D trajectory. This problem is a mixed-integer non-convex optimization problem, with dual effects of obstacles on the UAV. To tackle this challenge, we introduce an obstacle avoidance factor to optimize the UAV's flight height, thereby avoiding obstacles of specific heights. Additionally, we consider the impact of obstacles on the UAV communication link and derive an equation for determining the blocking region. In response to the influence of obstacles and flight height on UAV energy efficiency, we propose an optimization method based on the DOB-DSCA algorithm. Experimental results show that optimizing flight height can improve energy efficiency by 12.6%, while the presence of obstacles reduces energy efficiency by 17.7%. Furthermore, considering the limited research in the existing literature on factors affecting UAV energy efficiency, we focus on how variations in transmission power, total flight time, and obstacle height can enhance UAV energy efficiency.</description></item><item><title>Joint Transmit and Jamming Power Optimization for Secrecy in Energy Harvesting Networks: A Reinforcement Learning Approach</title><link>http://ieeexplore.ieee.org/document/11120367</link><description>In this paper, we address the problem of joint allocation of transmit and jamming power at the source and destination, respectively, to enhance the long-term cumulative secrecy performance of an energy-harvesting wireless communication system until it stops functioning in the presence of an eavesdropper. The source and destination have energy-harvesting devices with limited battery capacities. The destination also has a full-duplex transceiver to transmit jamming signals for secrecy. We frame the problem as an infinite-horizon Markov decision process (MDP) problem and propose a reinforcement learning (RL)-based optimal joint power allocation (OJPA) algorithm that employs a policy iteration (PI) algorithm. Since the optimal algorithm is computationally expensive, we develop a low-complexity sub-optimal joint power allocation (SJPA) algorithm, namely, reduced state joint power allocation (RSJPA). Two other SJPA algorithms, the greedy algorithm (GA), and the naive algorithm (NA) are implemented as benchmarks. In addition, the OJPA algorithm outperforms the individual power allocation (IPA) algorithms termed individual transmit power allocation (ITPA) and individual jamming power allocation (IJPA), where the transmit and jamming powers, respectively, are optimized individually. The results show that the OJPA algorithm is also more energy efficient. Results also show that the OJPA algorithm significantly improves the secrecy performance compared to all SJPA algorithms. The OJPA algorithm also outperforms the secrecy performance of a genetic algorithm-based RL algorithm and a finite-horizon RL algorithm. The proposed RSJPA algorithm achieves nearly optimal performance with significantly less computational complexity marking it the balanced choice between the complexity and the performance. We find that the computational time for the RSJPA algorithm with considering only 50 percent of the total number of states is around 75 percent less than the OJPA algorithm.</description></item><item><title>Joint Task Allocation and Power Optimization in Multi-UAV Systems: An Overlapping Coalition Formation Game Approach</title><link>http://ieeexplore.ieee.org/document/11120350</link><description>Unmanned Multiple Aerial Vehicle (multi-UAV) systems are capable of executing tasks and transmitting data effectively through cooperation. However, most existing works mainly focus on non-overlapping coalition formation and independent data transmission, which does not fully utilize the capability of UAV. This article investigates the cooperative task allocation of multi-UAV systems with consideration of limited UAV communication energy. In order to improve cooperative task performance, we jointly optimize overlapping coalition formation and UAVs' transmit power within the communication energy budget. Specifically, the problem is formulated as an overlapping coalition formation game (OCFG) in order to model the interactions among UAVs. In addition, a multi-coalition-based altruistic (MCA) order is proposed to support the overlapping of coalition members. The modeled OCFG is strictly proved to be an exact potential game (EPG), and hence the existence of stable coalition sturcture is guaranteed. Furthermore, we derive the conditions for UAV transmit power adjustment and develop a Joint Overlapping Coalition Formation and Transmit Power Optimization (JOCFTPO) algorithm to obtain the stable coalition structure. Finally, simulation results demonstrate that the proposed JOCFTPO algorithm outperforms the benchmark schemes in terms of the network utility.</description></item><item><title>Learning RIS-Assisted Hybrid NOMA Transmissions for Capacity Maximization in Wireless-Powered Networks</title><link>http://ieeexplore.ieee.org/document/11122338</link><description>In this paper, we aim to enhance the throughput of a reconfigurable intelligent surface (RIS)-assisted and wireless-powered network by enabling user devices (UDs) to cooperatively adapt their channel access strategies. The base station (BS) simultaneously receives data and provides radio frequency (RF) energy to the UDs. Each UD equipped with a passive RIS employs non-orthogonal multiple access (NOMA) or backscattering for data transmissions. Moreover, the UD can assist other UDs' data transmissions through RIS's phase reconfiguration. We seek to maximize the overall throughput by optimizing UDs' channel access modes, time allocations, and the beamforming strategies of the RISs and the BS. Throughput maximization is challenging due to uncertain channel information, dynamic traffic demands, and limited energy supply. We propose a hierarchical learning approach to address access mode selection and transmission control in two steps. We first employ a multi-agent attention-enhanced deep reinforcement learning approach to update each UD's channel access strategy by interacting with the dynamic network. Then, we efficiently update the UDs' time allocation and the beamforming strategies of the RISs and the BS to further enhance throughput. Simulation results validate that our proposed scheme achieves improved throughput and learning efficiency, and exhibits superior adaptability against the varying traffic demands, compared to benchmarks.</description></item><item><title>Adaptive Task Offloading and Resource Management for Vehicular Edge Computing</title><link>http://ieeexplore.ieee.org/document/11122339</link><description>Within the field of dynamic vehicular networks, also known as vehicular edge computing (VEC), task offloading and resource allocation face significant challenges due to constantly changing network conditions and limited resources. To address these issues, we propose a novel method for task offloading and resource allocation that considers the unpredictable starting points of vehicle offloading and the immediate impact of vehicle movement on wireless communication links. We utilizes dynamic channel modeling to track the fluctuations in link state, incorporating a task classification and migration strategy. This approach allows us to adaptively modify both single and cross-region offloading. Furthermore, to minimize overall latency and energy consumption, we optimally coordinate communication and computing resources by dynamically assigning vehicle transmission power, local computing resources, and the computing resources of roadside units. Simulation results indicate that the proposed approach effectively minimizes both latency and energy consumption. It notably outperforms benchmark schemes, showing a significant reduction in the Z value, achieving lower task delays and reduced energy consumption compared to existing strategies. These findings highlight the substantial advantages of the proposed approach, particularly in dynamic vehicular environments.</description></item><item><title>On the Convexity Analysis of Message Error Probability in Rateless-Coded Transmission: A Deeper Dive Into Reliability</title><link>http://ieeexplore.ieee.org/document/11358828</link><description>Rateless codes are particularly appealing in dynamic and unpredictable communication environments, making them a natural choice for the communication in high-mobility networks. In this paper, motivated by this, we characterize the message error probability in rateless-coded transmission, defined as the probability that a user fails to decode the original message from the collected encoded packets using a rateless decoder. Building on this characterization, we prove the convexity and concavity of the message error probability with respect to a new variable under distinct sufficient conditions. Specially, under these sufficient conditions, we reveal that the message error probability is convex with respect to a power function of the packet success probability and concave with respect to a power function of the packet error probability, respectively. These properties provide valuable insights into analyzing rateless-coded transmissions across various scenarios. Through a practical multi-stream application example, we demonstrate how the convexity property can be applied to improve the overall reliability in rateless-coded transmissions.</description></item><item><title>A Hybrid Advertising Mode for Neighbor Discovery in Bluetooth Low Energy Networks</title><link>http://ieeexplore.ieee.org/document/11108695</link><description>Neighbor discovery has a great impact on the performance of bluetooth low energy (BLE). BLE neighbor discovery has two advertising modes: pseudo-random delay advertising (RDA) and periodic deterministic advertising (PDA). PDA has low discovery latency but is susceptible to persistent collisions, whereas RDA does not suffer persistent collisions but has much larger discovery latency. In this paper, we propose a novel hybrid advertising mode, called Deterministic and pseudo-Random delay Advertising (DRA), which has the advantages of both PDA and RDA. We develop an analytical model for DRA, and analyze the expected discovery latency of DRA in different cases. Simulations show the accuracy of our analytical model, and verify that DRA can speed up BLE neighbor discovery.</description></item><item><title>Advancements in Self-Assembled Monolayers for Perovskite Solar Cells</title><link>http://ieeexplore.ieee.org/document/11284797</link><description>Self-assembled monolayers (SAMs) are well known as a promising strategy for enhancing the efficiency, stability, and interfacial properties of perovskite solar cells (PSCs). These molecular layers, typically formed through surface binding between electrode surfaces, enable fine-tuning of surface energetics, promote uniform film formation, and suppress interfacial recombination. Lead (Pb)-halide perovskite systems are renowned for their remarkable power conversion efficiencies, with SAMs playing a crucial role in optimizing charge extraction and mitigating degradation pathways. This review explores recent advancements in SAM-functionalized interfaces, particularly focusing on their chemical structure, anchoring groups, electronic alignment, and compatibility with perovskite and charge transport layers. We also highlight the comparative performance of SAM-modified PSCs, discuss current challenges, and suggest future directions for material innovation and device engineering.</description></item><item><title>Analysis of Advanced Nonisolated Topologies for Vehicle-Integrated Photovoltaic (ViPV) Systems in Urban Electric Transport Buses</title><link>http://ieeexplore.ieee.org/document/11141378</link><description>The integration of vehicle-integrated photovoltaic (ViPV) systems enhances the sustainability of urban public transportation and reduces reliance on the electrical grid. However, irradiance variability and partial shading pose significant challenges to system stability and efficiency. This study evaluates three advanced nonisolated dc&#8211;dc converter topologies: interleaved boost, quadratic boost, and multi-input/single-output (MISO) under maximum power point tracking (MPPT) control using the perturb and observe algorithm. Simulations were conducted in Simulink using real irradiance and temperature data collected in a high solar irradiance place, such as Antofagasta, Chile. The system comprises 600 photovoltaic cells ($350\, \mathrm{V}$) connected to a $540\,\mathrm{ V}$ dc-Link bus and a $50\, \text{kWh}$ LiFePO$_{4}$ battery bank. Key performance metrics, such as voltage gain, efficiency, current ripple, and duty cycle behavior, were analyzed under three solar scenarios. Under favorable irradiance, all topologies delivered over $3.2\, \text{kW}$ with ideal efficiencies above 98.4%. The interleaved topology demonstrated strong steady-state performance but limited transient regulation. The quadratic converter operated with a low duty cycle yet showed greater sensitivity to disturbances. In contrast, the MISO converter consistently maintained a stable output, low ripple, and high efficiency even under minimal irradiance conditions (70 W/m$^{2}$). These results position the MISO topology as the most robust solution for variable urban environments, ensuring reliable energy delivery and supporting the efficient deployment of ViPV systems in electric mobility applications.</description></item><item><title>Tracking Concepts for High-Density PV Power Plants</title><link>http://ieeexplore.ieee.org/document/11205357</link><description>In the search for new sites, photovoltaic (PV) system installations spread out into complex places and contexts, such as hilly terrain, floating PV, and agriPV. It is, therefore, plausible to assume that PV power plants will increasingly need to use space and, thus, sunlight more efficiently, e.g., by not wasting solar energy in the space between module rows. This means it may become increasingly important to consider the energy output of PV systems per area of land use, i.e., the &#8220;efficiency of the PV system.&#8221; To increase this efficiency, power plants with high density of PV modules are needed. For tracked systems, this necessitates adapting the tracking strategies to avoid excessive losses from either row-to-row shading or angle-of-incidence losses in backtracking. This article explores different tracking strategies that could contribute to enabling high-density PV power plants with high efficiency. The advantages of these advanced tracking strategies are quantified at two different latitudes as a function of the ground coverage ratio.</description></item><item><title>Floating Offshore Solar Photovoltaics for Land-Constrained and Diverse Renewable Supply Conditions in the United States and Canada</title><link>http://ieeexplore.ieee.org/document/11214224</link><description>Energy transition pathways for large continental areas are largely understood to be achievable using a diverse set of onshore renewable energy technologies. Previous research for the integrated United States and Canada energy&#8211;industry system indicated that solar photovoltaics (PVs) may dominate the primary energy structure, complemented by onshore wind power. However, societal constraints may require increased supply diversity, and onshore renewable energy may not be sufficient for densely populated regions, especially on the east coast of the United States. The LUT Energy System Transition Model was applied to investigate the role of floating offshore solar PV coupled with offshore wind and wave power when onshore solar PV is limited. The results indicate that, when onshore solar PV is limited to 60% of electricity generation, 434 GW of floating offshore solar PV may be installed by 2050 as part of a hybrid power plant sharing the same grid connection as offshore wind power, which reaches 414 GW of installed capacity, contributing 607 and 1576 TWh to the electricity supply, respectively. In total, 7.4 TW of solar PV capacity is installed by 2050, complemented by 1.4 TW of onshore wind power. Increased supply diversity still leads to a 42% reduction in the levelized cost of electricity, reaching 32.7 &#8364;/MWh in 2050. Compared with cost-optimal conditions, the levelized cost of final energy and nonenergy use in 2050 increases by 28% to 52.7 &#8364;/MWh. Nevertheless, such increased costs may be justifiable to meet societal constraints, and a diverse power-to-X economy structure for the United States and Canada may still be technoeconomically viable.</description></item><item><title>Performance Limits in Bifacial Tandem Solar Cell Modules for Multiple Configurations</title><link>http://ieeexplore.ieee.org/document/11224657</link><description>While bifacial tandem photovoltaic technology is promising as it is able to generate higher electrical power output by accessing illumination from both front and rear surfaces, a thorough investigation of the performance limits of bifacial tandems with different architectures/arrangements and under different conditions has not been explored. In this work, we present a comprehensive analytical framework based on the principle of detailed balance to assess the performance limits of bifacial tandems spanning multiple architectures, including unconstrained, current-matched (CM), and voltage-matched (VM) configurations. Our methodology explores the performance benefits of incorporating area-decoupled subcells across layers and examines the impact of different bandgap arrangements (monotonic and non-monotonic) on the performance. We show that having non-monotonic arrangement of bandgaps under optimal albedo conditions can significantly enhance the performance of bifacial tandems. In addition, we analyze the performance resilience of each configuration and bandgap arrangement to spectral variations induced by environmental factors such as shading, fluctuations in temperature, and albedo. This provides crucial design guidelines for the design, fabrication, and estimation of the performance limits of these solar cell architectures in different conditions.</description></item><item><title>Performance Enhancement of Bifacial PV Modules on Horizontal Single-Axis Trackers in Desert Environments</title><link>http://ieeexplore.ieee.org/document/11206410</link><description>The adoption of bifacial photovoltaic (PV) modules has grown significantly due to their potential for higher energy yield. However, their real-world performance under outdoor conditions remains insufficiently explored. This study analyzes the energy gains of bifacial PV modules in a horizontally tracked power plant in the Atacama Desert, Chile, comparing a conventional single-axis tracker with an optimized tracker designed for bifacial performance. Results show that bifacial modules on conventional trackers achieve &#8764;5% higher energy production, while those on optimized trackers reach up to 6.1%, emphasizing the role of tracker design in maximizing bifacial PV efficiency.</description></item><item><title>RR-LTNet: Ramp-Rate-Centric Deep Learning Framework for Short-Horizon Photovoltaic Power Prediction</title><link>http://ieeexplore.ieee.org/document/11237053</link><description>Reliable operation of photovoltaic (PV) fleets with high grid penetration demands prediction tools that translate plant-level irradiance variability into actionable intelligence for PV power management and balance-of-system design. Reliably managing high penetrations of solar PV within modern grids requires predictions that reflect the systemic consequences of fast renewable variability across cyber-physical energy infrastructure. This article proposes RR-LTNet, a ramp-rate (RR)-centric prediction architecture that elevates the RR as the core variability feature linking plant-level intermittency to grid-level operational risk. RR-LTNet first performs dynamic clustering of RR regimes to characterize rapid weather transitions and stability conditions. These regimes taken as feature for hybrid temporal learner that fuses recurrent memory with temporal convolution to capture multiscale dynamics. For predictive assessment, numerical experiments are conducted on one year solar power database of the Yulara Solar Project, Australia. The proposed RR-LTNet consistently outperforms other feature extraction methods by achieving up to 90% reductions in root mean square error (RMSE) for 5-min resolution. The reductions are significantly larger when baseline models are augmented with RR-aware features than when those features are absent. Cross-site validation on two additional PV plants with different capacity and data distribution confirms robustness and consistency required for system engineering deployment across fleets. By surfacing variability intelligence in real time, RR-LTNet supports PV-specific tasks central to reserve scheduling, advanced simulation of PV plant-grid interactions. This framework thus bridges PV monitoring analytics with system level reliability engineering, accelerating the integration of large-scale PV into modern power systems.</description></item><item><title>A 15-bit ROIC With Current-Mode Folding Integration Technique for Microbolometer Thermal Imagers</title><link>http://ieeexplore.ieee.org/document/11223065</link><description>This article presents a 52-mK noise-equivalent temperature difference (NETD) reference-cell-free wide temperature sensing range readout integrated circuit (ROIC) for a microbolometer thermal imager. The proposed ROIC utilizes a 15-bit hybrid analog-to-digital converter (ADC) that employs the current-mode folding integration (CMFI) technique for the coarse conversion and single-slope (SS) operation for the fine conversion. With the proposed coarse CMFI operation, the ROIC achieves a  $300\times $  larger conversion range and  $300\times $  higher conversion gain compared to the conventional nonfolding integration (NFI) technique. Moreover, due to the extended conversion range, the ROIC is able to cover the sensor&#8217;s PVT variations without any signal saturation. With the hybrid operation of CMFI and SS, the ROIC achieves a differential nonlinearity (DNL) and an integral nonlinearity (INL) of  $\pm 0.04~^{\circ }$ C and  $\pm 0.12~^{\circ }$ C, respectively. Furthermore, it achieves a wide temperature sensing range from  $- 20~^{\circ }$ C to  $107~^{\circ }$ C while considering &#177;15% chip-to-chip and &#177;3% cell-to-cell sensor variations.</description></item><item><title>A 40-nm Embedded Flash With Highly Reliable Bitline Transmission and Low-Voltage Current Sense Amplifier</title><link>http://ieeexplore.ieee.org/document/11219246</link><description>A novel read circuit for embedded flash memory operating from a single 1.1-V supply is presented, featuring a negative-voltage dual-MOS transmission structure for bitline (BL) transfer and a low-voltage, high-reliability current&#8211;voltage sense amplifier (SA). This approach effectively addresses the issue of reduced read window size due to decreased BL voltage as supply voltage decreases. The proposed circuit is integrated into a 4.5-Mbit embedded flash memory test chip, fabricated using a 40-nm CMOS process. Experimental results show a read access time of 18.5 ns at a supply voltage of 0.9 V, with a read throughput of 7.78 Gbit/s and a bit density of 3.414 Mbit/mm2.</description></item><item><title>12-bit SAR ADC Employing a 9-bit CDAC in Vanilla CMOS 40-nm Technology</title><link>http://ieeexplore.ieee.org/document/11239468</link><description>This article presents a 130-MS/s successive approximation register (SAR) analog-to-digital converter (ADC) architecture that uses a 9-bit capacitive DAC (CDAC) and innovative techniques that include passive amplification circuitry without engaging active components and the strategic connection of a unity capacitor to multiple reference voltages, to achieve a total of 12 bits. The proposed passive amplification technique saves 27% of the ADC area through reducing the CDAC size by 50% compared to a conventional 10-bit CDAC +2-bit voltage reference design for a 12-bit resolution. Compared with the conventional 12-bit C-DAC SAR, the proposed SAR-ADC saves over 75% of the active area. The measurement results reveal that the core of the proposed ADC architecture dissipates 3 mW. Fabricated in a mainstream 40-nm CMOS technology, the proposed ADC attains SNDR/SFDR ratios as high as 63.5/72.13 dB for a 10-MHz sinusoidal test tone; the SAR active area is about  $0.00966~\text {mm}^{2}$ . Furthermore, this architecture yields favorable results regarding the Walden figure-of-merit of approximately 26.5 fJ/conv-step while maintaining Schreier FOM around 165.37 dB when measured at 10 MHz.</description></item><item><title>60-Gb/s 1:4 Demultiplexer in 22-nm FD-SOI Technology Using TSPC Logic: A Circuit-to-System-Level Analysis and Design</title><link>http://ieeexplore.ieee.org/document/11232454</link><description>This article presents a 1:4 single-ended binary-tree demultiplexer. The entire design, including true single-phase clock (TSPC) flip-flops, latches, and frequency divider, is composed of gated inverter blocks. The causes of voltage dip formation in flip-flops are analyzed and effectively eliminated. The setup time, hold time, and delay criteria of individual components are investigated and optimized over a variety of back-gate bias schemes as well as different supply voltages. Finally, a timing constraint is derived for the top-level demultiplexer architecture. The demultiplexer operates across a wide range of inputs from 1.6 to 60 Gb/s providing a selection of potential supply voltages ranging from 0.6 to 1.2 V. The chip&#8217;s power dissipation is mainly due to the dynamic power of the switching inverters and is self-adjustable on the basis of the input data rate. The circuit is designed and fabricated in 22-nm fully depleted silicon-on-insulator (FD-SOI) CMOS technology with a chip area of 0.033 mm2.</description></item><item><title>A Sampling&#8211;Settling-Merged Technique Enabling an ELDC-Free Continuous-Time Delta&#8211;Sigma Modulator With a Pole-Optimized NS-SAR Quantizer</title><link>http://ieeexplore.ieee.org/document/11244206</link><description>This article presents a hybrid third-order continuous-time delta&#8211;sigma modulator (CT DSM) with a 5-MHz bandwidth, tailored for low-power applications. The design is facilitated by a passive pole-optimized second-order noise-shaping successive-approximation register (NS SAR) quantizer. A sampling&#8211;settling-merged technique is proposed with the assistance of a canceling conductance output stage, leading to significantly suppressed sampling errors and an extension of the available time budget for the NS SAR quantizer. The technique merges the NS SAR quantizer&#8217;s sampling phase with the settling phase of the integration of the continuous-time (CT) feedback digital-to-analog converter (DAC), achieving a power-efficient integration and sampling process. This approach relaxes the operational transconductance amplifier (OTA) requirements in the CT loop and enhances both the resolution and power efficiency of the DSM. The NS SAR quantizer, featuring left-half-circle (LHC) poles, enables complex conjugate poles optimization for the noise transfer function, enabling an excess loop delay compensation (ELDC)-free design. Fabricated in a 65-nm CMOS process, the prototype analog-to-digital converter achieves a 71.6-dB signal-to-noise and distortion ratio within the 5-MHz bandwidth at an oversampling ratio of 20. The design consumes 0.6&#8198;mW of power, achieving a Schreier figure of merit (FoM) of 170.8&#8198;dB and Walden FoM of 19.3&#8198;fJ/conv., demonstrating state-of-the-art energy efficiency.</description></item><item><title>A Fully Integrated Storage-Free Energy Harvesting System With Voltage Self-Regulation and Dual-Channel Power Extraction</title><link>http://ieeexplore.ieee.org/document/11318335</link><description>With the growing demand for self-powered operation in Internet of Things (IoT) nodes and microsensors, photovoltaic energy harvesting (EH) systems have become a key research focus. Although triple-well on-chip solar cells improve photovoltaic conversion efficiency, their multiport output characteristics pose design challenges: conventional parallel output schemes cannot address the mismatch in maximum power point (MPP) voltages among ports, thereby limiting energy extraction efficiency. Moreover, fully integrated EH systems lack external storage, and input&#8211;output coupling renders traditional voltage regulation unsuitable. To address these challenges, this article presents a fully integrated dual-channel EH system that employs a dual-port, independently boosted parallel architecture combined with a frequency-driven lightweight self-regulation mechanism, eliminating the need for conventional regulators. Measurement results show that the system achieves a stable output voltage of approximately 1.22 V, a peak end-to-end efficiency of 63.97%, and a 6.31% improvement in maximum output power, while also exhibiting reliable start-up and ripple suppression, providing valuable guidance for the design of efficient power extraction and self-regulation in on-chip photovoltaic EH systems.</description></item><item><title>AHCO-YOLO: An Algorithm&#8211;Hardware Co-Optimization Framework for Energy-Efficient and Real-Time Object Detection on Edge Devices</title><link>http://ieeexplore.ieee.org/document/11218222</link><description>Real-time object detection on edge devices operates under tight computational, memory, and power budgets. Prior work typically treats model compression and hardware acceleration independently, yielding suboptimal trade-offs among accuracy, latency, and energy. We present AHCO-YOLO, an algorithm&#8211;hardware co-optimization framework (AHCO) that unifies model design, quantization, design space exploration (DSE), and hardware implementation. This approach overcomes the limitations of isolated methods and delivers synergistic gains. We introduce a hardware-friendly, lightweight You Only Look Once (YOLO) model with batch normalization (BN)-preserving quantization method that reduces the model size while maintaining accuracy at low precision. In addition, we propose a layer-specific resource&#8211;latency-aware DSE (LSRLA-DSE) method that selects the optimal dataflow based on layer-wise features and searches hardware design parameters under latency and resource constraints. Furthermore, we propose a FIFO-based streaming architecture with layer-wise dynamic dataflows that maintains high processing element (PE) utilization while minimizing off-chip traffic. Moreover, we introduce a semantic partition and regrouping strategy (SPRG) that improves resource efficiency and throughput. Implemented on a Xilinx ZCU104 FPGA, AHCO-YOLO-T achieves 79.8 FPS at 64.8% mAP, delivering 41.9 FPS/W and 80.5 GOPS/W. Across comparisons with existing YOLO accelerators, AHCO-YOLO achieves state-of-the-art efficiency, demonstrating suitability for real-time, energy-efficient object detection on edge platforms.</description></item><item><title>E2CAP: An Energy-Efficient FPGA Accelerator for Deep Reinforcement Learning With Experience Compression and Configurable PE Array</title><link>http://ieeexplore.ieee.org/document/11227133</link><description>Deep reinforcement learning (DRL) has emerged as a powerful tool for solving complex decision-making tasks in domains such as robotics, autonomous systems, and gaming. However, accelerating DRL on hardware platforms faces three major challenges: 1) large memory footprint of experience replay data; 2) inefficient weight access due to weight transposition; and 3) computational imbalance across processing elements during deep neural network (DNN) inference and training. To address these issues, we propose E2CAP, an energy-efficient field-programmable gate array (FPGA) accelerator tailored for DRL workloads. E2CAP integrates a compression strategy that significantly reduces the data volume of the experience pool in the DRL model, enabling on-chip deployment of the experience pool. In addition, E2CAP features a configurable array processing core (CAP) based on configurable processing elements (CPEs) that support both intra-PE and inter-PE configurability. This design effectively addresses the issues of weight trans position and computational imbalance, improving computational efficiency and hardware resources utilization. We implement full on-chip DRL inference and training using the DQN algorithm on E2CAP. Experimental results demonstrate a 98.19% compression ratio for experience replay data. Compared to the state-of-the-art CPU and GPU, E2CAP achieves  $33.01\times $  and  $17.72\times $  higher energy efficiency, respectively, while outperforming existing FPGA-based DRL accelerators in multidimensional performance.</description></item><item><title>SConvNSys: Accelerating Spiking Convolutional Neural Networks With a Reconfigurable Neuromorphic Architecture for Diverse Applications</title><link>http://ieeexplore.ieee.org/document/11247941</link><description>In recent years, spiking neural networks (SNNs) have progressively closed the performance gap with convolutional neural networks (CNNs), which are renowned for their success in complex artificial intelligence tasks. However, most existing SNN accelerators suffer from limited flexibility, lacking support for diverse convolutional topologies and struggling to deploy complex SNN models. To address these challenges, this article proposes a reconfigurable neuromorphic architecture, SConvNSys, tailored for accelerating spiking CNNs (SCNNs) across a wide range of applications. A fast, sparse detection technique, coupled with a dedicated sparse response unit, is introduced to effectively exploit the spatio-temporal sparsity inherent in spike-based computation. On this basis, a reconfigurable spiking convolution dataflow is designed to optimize computation across various SCNN structures. The proposed architecture supports multiple convolution types, including standard, transposed, dilated, and residual convolutions. Implemented on a field-programmable gate array (FPGA), SConvNSys achieves competitive results: for image classification, it attains recognition accuracies of 91.48% on CIFAR-10 and 68.54% on CIFAR-100, with a power consumption of just 1.8 W and a processing rate of 73 frames/s. In image segmentation tasks, it reaches 99.00% segmentation accuracy at 153 frames/s. For object detection, the proposed detection model achieves a mean intersection over union (MIoU) of 74.20%, with 0.11 giga operations (GOP) of convolutional computation, resulting in a throughput of 27.4 giga operations per second (GOPS) and an energy efficiency of 15.23 GOPS/W.</description></item><item><title>Weightless Neural Networks on Flexible Substrates: A Novel Approach to Wearable Machine Learning</title><link>http://ieeexplore.ieee.org/document/11267783</link><description>In this article, we present a novel approach that seamlessly integrates machine learning (ML) algorithms into wearable technology through the use of weightless neural networks (WNNs) and flexible integrated circuits (FlexICs). Our methodology employs combinational intelligent networks (COIN) for edge inference on resource-constrained devices, highlighting the advantages of WNNs in terms of power efficiency and minimal hardware requirements. We propose an automated design flow for implementing COIN as FlexICs aimed at developing scalable, cost-effective, and environmentally sustainable wearable monitoring solutions. As a proof-of-concept demonstrator, an arrhythmia detection FlexIC was fabricated using COIN to meet the stringent requirements of medium-complexity wearable applications, offering a promising path toward personalized and accessible healthcare solutions.</description></item><item><title>Weighted Coding Scheme for Noise Reduction in Silicon Interposer of HBM</title><link>http://ieeexplore.ieee.org/document/11302879</link><description>High-bandwidth memory (HBM) has enabled substantial advancements in bandwidth-intensive applications, including large-scale artificial intelligence models. HBM is typically integrated with other systems-on-chip (SoCs) through a silicon interposer, and the primary bottleneck in aggressively scaling the bandwidth in next-generation HBM systems stems from significant crosstalk caused by closely spaced, high-density parallel interconnects in the interposer. While crosstalk avoidance code (CAC) has emerged as a promising solution, prior CAC schemes suffer from low bit efficiency and considerable hardware overhead. This article proposes an efficient CAC scheme, WITCH, which employs a novel weighted coding strategy. Unlike prior approaches that consider all channels identically, WITCH assigns different weights to channels based on their relative positions in the array, enabling more bit-efficient crosstalk suppression. We also present WITCH with additional shielding (WITCH-AS), an extension of WITCH that incorporates additional shielding to further reduce crosstalk levels. Our coding schemes achieve high bit efficiency, up to 17.3% higher than state-of-the-art techniques while providing an identical level of crosstalk reduction. Simulation results using an industry-proven channel model demonstrate that WITCH and WITCH-AS improve eye height by 10.1%&#8211;49.4% and 17.1%&#8211;51.1%, respectively. Furthermore, we propose an area- and energy-efficient hardware implementation that can be integrated into real-world HBM systems. The design reduces area and critical path delay by 31.0% and 28.2%, respectively, compared with conventional designs. Finally, we propose a compatible simultaneous switching output (SSO) noise mitigation technique that can be seamlessly integrated into WITCH to further enhance signal integrity under high-speed, high-density operating conditions.</description></item><item><title>A Heterogeneous CIM Architecture With Splittable Nonvolatile Computing-in-SRAM Cell Pairs Enabling Efficient On-Chip Neural Network Inference</title><link>http://ieeexplore.ieee.org/document/11239474</link><description>Heterogeneous computing-in-memory (CIM) offers a promising solution for efficient neural network (NN) accelerations by leveraging the characteristics of different types of memories. However, the previous heterogeneous CIM either requires additional data transfer between different types of isolated memories or solely relies on in situ embedded single-level (SL) or three-level (TL) nonvolatile memories (NVMs), making it difficult to trade off between storage density and robustness benefits. In this article, a new heterogeneous CIM architecture (NVS-SPT) with enhanced storage density and inference robustness is proposed to enable full on-chip acceleration of practical-scale NNs while scalable to larger models. A splittable nonvolatile computing-in-static random access memory (SRAM) cell pairs (nvS2RAM-CIM) is proposed with hybrid in situ embedded SL and TL resistive random access memory (ReRAM) groups, allowing flexible configuration as split or linked state to enhance storage density and restore yield. A layerwise hybrid-coding search (LHCS) algorithm with bitwise and tritwise data-aware mapping (BTM) method is proposed to determine the optimal weight coding patterns with high array utilizations. In addition, a merged hybrid-coding block (MHCB) generation scheme is employed to enable high computing parallelism by merging the dense computing patterns. The proposed NVS-SPT demonstrates up to  $4.2\times $  higher storage density compared with previous heterogeneous CIM with pure SL-ReRAMs and achieves up to 44.7% enhanced NN accuracy, compared with previous unified ternary coding. Furthermore, the proposed NVS-SPT exhibits up to  $1.72\times $  and  $1.44\times $  enhanced energy efficiency with  $3.10\times $  and  $1.42\times $  higher computing density, compared with previous heterogeneous CIM based on pure SL- or TL-ReRAMs, respectively.</description></item><item><title>A Low-Power Speech-Based Depression Recognition Processor With Hierarchical Local&#8211;Global Network</title><link>http://ieeexplore.ieee.org/document/11224022</link><description>Depression is a critical public health concern characterized by underdiagnosis, often due to stigma, lack of awareness, and reluctance to seek help. Cases of delayed intervention could be alleviated by wearable solutions which enable continuous and unobtrusive monitoring of depression indicators. Compared to electroencephalogram (EEG)-based and video-based depression recognition, speech-based approaches can be performed without deliberate user attention. However, due to the limited accuracy of existing algorithms and constrained resources at edge, performing accurate speech-based depression recognition on wearable platforms remains a challenge. Therefore, to achieve unobtrusive, accurate, and efficient depression recognition at edge, this work presents a hierarchical local&#8211;global network (HLG-Net) and optimized processor design for speech-based depression recognition. The proposed HLG-Net integrates convolutional neural networks (CNNs) with multihead attention (MHA) mechanism to simultaneously capture local acoustic features and global utterance-level coherence, enhancing depression stage recognition. For efficient processor design, a cross-layer buffered dataflow is proposed for efficient data handling, reducing data storage by 98.77%. The computing unit (CU) employs layer fusion, operator optimization, and quantization techniques to further improve resource utilization and reduce power consumption while preserving recognition accuracy. System-level low-power techniques such as clock/input gating and near-threshold design for application specific integrated circuit (ASIC) further reduce power consumption. The proposed processor implemented on field-programmable gate array (FPGA) (XC7Z100-2FFG900) achieves the lowest reported mean absolute error (MAE) of 5.13 on AVEC 2014 database. The 180-nm ASIC implementation shows a simulated power consumption of  $17.4~\mu $ W at 0.4 V. The results demonstrate the feasibility of accurate and efficient speech-based depression recognition on wearables.</description></item><item><title>Continuous Matrix Transposition for a Subclass of Matrices Using Minimal Memory</title><link>http://ieeexplore.ieee.org/document/11239467</link><description>Transposing matrices is essential in various fields, including signal processing and machine learning, making efficient hardware implementations for real-time processing highly desirable. The transposition of general matrices in a stream using memory is mathematically formalized. A novel algorithm has been developed to compute the necessary sequence of addresses for the memory whose depth is parametrizable and reducible to its theoretical minimum. For the subclass of matrices, where one dimension is a power of two and the other is two, it has been determined that the recursions in this algorithm exhibit logarithmic time complexity when minimal memory is used. Subsequently, it is shown how efficient transposition circuits can be built for these matrices, achieving minimal latency and full throughput. The proposed solution and recently published designs have been simulated for an ASIC implementation using the 45-nm NanGate Open Cell Library and compared for all suitable matrix dimensions of up to  $2\times 512$ . For the considered configurations, the results indicate for the proposed approach a memory saving of up to 33.3% over the state of the art. Overall area savings of up to 24.9% were achieved, making the new scheme very favorable for deployments with restricted area. Further advantages are seen with an average frequency increase of 13.7% and a lowered power consumption by up to 29.6%.</description></item><item><title>An Energy-Efficient Kalman Filter Coprocessor Design for Multiple-Object Tracking Targeting at Video Understanding</title><link>http://ieeexplore.ieee.org/document/11239472</link><description>Energy-efficient Kalman filter (KF) designs are inevitable in multiple-object tracking (MOT), a challenging computer vision task, for real-time mobile applications such as smart glasses, nanodrones, and mobile robots. VLSI design for KF is a feasible way to implement the required complex matrix operations; however, direct implementations are inefficient due to the data sparsity and redundant calculations existing inside. This article introduces an energy-efficient KF coprocessor, which improves computational efficiency by employing KF formula simplifications, matrix sparsity and symmetric properties, and common coefficient sharing, along with a dedicated but flexible hardware architecture. In contrast to state-of-the-art (SOTA) application-specific integrated circuit (ASIC) designs that rigidly customize several hardware modules for specific formulations in KF, our architecture executes all formulations in one hardware, enabling both flexibility and high efficiency. Implementation results demonstrate up to  $44.8\times $  improvement in energy efficiency over SOTA solutions, achieving 110.2 GOPs/J when executed at 180 MHz, which supports 120-FPS real-time multiobject tracking.</description></item><item><title>EVMx: An FPGA-Based Accelerator for Smart Contract Processing</title><link>http://ieeexplore.ieee.org/document/11230572</link><description>Ethereum leverages smart contracts (SCs) to power decentralized applications (dApps), with execution handled by the Ethereum virtual machine (EVM) within an Ethereum client. Other blockchain platforms, including Avalanche, Polkadot, Aurora, and Cardano, have also adopted the EVM. However, the performance of the EVM is often constrained by the limitations of general-purpose processors, a challenge that has been explored in the literature. This work aims to further address the limitation by proposing EVMx, a dedicated single-core SC execution engine implemented on a field programmable gate array (FPGA). EVMx follows a processor-like architecture inspired by the RISC philosophy. By exploiting the parallelism and high-speed processing capabilities of FPGA hardware, EVMx achieves a 61% to 99% reduction in execution time for commonly used operation codes compared to traditional central processing unit (CPU)-based environments. Furthermore, EVMx executes entire Ethereum blocks with a percentage reduction in execution time between 6% and 56% against comparable FPGA implementations and 98% to 99% compared to CPU-based EVMs in the literature. These results demonstrate the potential of EVMx to significantly accelerate SC execution and enhance the performance of EVM-compatible blockchains.</description></item><item><title>A 95.3% 12-Class, 108-nJ/Inference Keyword Spotting Chip With Hybrid FFT-BFNet Architecture and Exponent-Aware Nonuniform Quantization in 65-nm CMOS</title><link>http://ieeexplore.ieee.org/document/11259055</link><description>This article presents a 65-nm keyword spotting (KWS) chip that achieves 95.3% accuracy on 12-class tasks with 108.04-nJ/inference efficiency through cross-domain hardware-algorithm innovations. The unified fast Fourier transform (FFT)-butterfly-structured neural network (BFNet) accelerator fundamentally rethinks computational reuse: by replacing dense pointwise convolutions with butterfly-based sparse operations mirroring FFT&#8217;s dataflow, it slashes  $6.3\times $  multiply-accumulate (MAC) operations and halves parameter counts while preserving model expressivity. A 6-bit exponent-aware nonuniform quantization (EANUQ) scheme compresses weights, achieving a 25% reduction in storage while maintaining an accuracy loss of less than 0.01% with lightweight on-chip decoders. Hardware resource sharing extends beyond computation: Mel-filter-banks reuse fully-connected (FC) layer multipliers through decomposed 8-bit arithmetic, and FFT output buffers double as convolutional neural network (CNN) feature map memory. Measured at 0.65 V/600 kHz, the 0.58- $\text {mm}^{2}$  core demonstrates  $1.9\times $ &#8211; $15.5\times $  better energy efficiency than prior 65/28-nm implementations, with 14.82-ms end-to-end latency.</description></item><item><title>A RISC-V Accelerator for Sequence Decoding in Mobile DNA Sequencers</title><link>http://ieeexplore.ieee.org/document/11288729</link><description>Modern nanopore sequencers generate raw signal data at high speed, demanding low-latency and energy-efficient basecalling pipelines to enable fully portable genomic analysis. In this work, we present a hardware accelerator for the Viterbi-based connectionist temporal classification (CTC) decoding stage of basecalling&#8212;a key bottleneck in translating neural network outputs into deoxyribonucleic acid (DNA) sequences. Our design is the first pipelined CTC Viterbi decoder architecture tailored for nanopore sequencing and is implemented on a Xilinx Virtex-7 (VC707) FPGA within a Linux-capable reduced instruction set computer-fifth generation (RISC-V) system-on-chip (SoC). The accelerator processes over 23&#8198;000 DNA bases per second at 100 MHz with about  $4.3~\boldsymbol {\mu }$ s per-sample latency and only 0.43-W overhead power. This corresponds to  $\textbf {5.3}\times \mathbf {10^{4}}$  bases/J ( $19~\boldsymbol {\mu }$ J/base) and yields approximately 7x end-to-end speedup over a CPU baseline, while reserving the baseline read-identity accuracy. For the same CTC task, the accelerator delivers 29x higher throughput than a recent FPGA beam-search decoder. These results demonstrate the viability of dedicated decoding accelerators for real time, on-device genomic processing in power-constrained environments.</description></item><item><title>An Energy-Efficient Edge Coprocessor for Neural Rendering With Explicit Data Reuse Strategies</title><link>http://ieeexplore.ieee.org/document/11301889</link><description>Neural radiance fields (NeRFs) have transformed 3-D reconstruction and rendering, facilitating photorealistic image synthesis from sparse viewpoints. This work introduces an explicit data reuse neural rendering (EDR-NR) architecture, which reduces frequent external memory accesses (EMAs) and cache misses by exploiting the spatial locality from three phases, including rays, ray packets (RPs), and samples. The EDR-NR architecture features a four-stage scheduler that clusters rays on the basis of  $Z$ -order, prioritize lagging rays when ray divergence happens, reorders RPs based on spatial proximity, and issues samples out-of-orderly (OoO) according to the availability of on-chip feature data. In addition, a four-tier hierarchical RP marching (HRM) technique is integrated with an axis-aligned bounding box (AABB) to facilitate spatial skipping (SS), reducing redundant computations and improving throughput. Moreover, a balanced allocation strategy for feature storage is proposed to mitigate SRAM bank conflicts. Fabricated using a 40-nm process with a die area of 10.5 mm2, the EDR-NR chip demonstrates a  $2.41\times $  enhancement in normalized energy efficiency, a  $1.21\times $  improvement in normalized area efficiency, a  $1.20\times $  increase in normalized throughput, and a 53.42% reduction in on-chip SRAM consumption compared with state-of-the-art accelerators.</description></item><item><title>ASTRA: Automated Insertion of Distributed Entropy Sources for Robust Authentication</title><link>http://ieeexplore.ieee.org/document/11223067</link><description>The horizontal business model of modern semiconductors&#8212;where design, fabrication, and testing are handled by separate entities across a global supply chain&#8212;exposes integrated circuits (ICs) to various security threats throughout their lifecycle. Physical unclonable functions (PUFs) have emerged as effective hardware security primitives for device identification and attestation. However, integrating PUFs into existing designs is often manual, labor-intensive, and incurs high overhead in area, power, and design time. Moreover, traditional PUFs are typically localized to small regions of a chip, limiting entropy extraction from the full design surface. To address these limitations, we propose ASTRA, an automated framework that integrates PUF-based entropy sources into digital logic circuits in a distributed and timing-aware fashion. ASTRA enhances the conventional logic synthesis flow by inserting memory-in-logic PUFs (MeLPUFs), which are constructed using standard cell elements and offer high entropy. By distributing MeLPUF primitives across the circuit, ASTRA maximizes response randomness while minimizing area and power overhead. It can also reuse existing logic elements and supports multiple MeLPUF templates. ASTRA ensures timing constraints are respected and enables validation of both functional and logic equivalence checking (LEC) between the original and PUF-inserted designs. Experimental results show that ASTRA achieves near-ideal PUF quality metrics, demonstrating its effectiveness and scalability for secure hardware design.</description></item><item><title>An Efficient VLSI Architecture for Hammerstein-Type Spline Adaptive Filters</title><link>http://ieeexplore.ieee.org/document/11218027</link><description>The Hammerstein spline adaptive filter (HSAF) is a class of nonlinear adaptive filters (NAFs), known for its flexible nonlinear modeling and low complexity in applications, such as self-interference cancellation in wireless communications. This brief proposes a delayed dual-weight update reformulation for the HSAF and its efficient high-throughput and low-power architecture. We also propose hardware-efficient techniques for mapping spline interpolation and updating the spline control points in HSAF. The proposed delayed HSAF (DHSAF) architecture is synthesized using Cadence Genus in 45-nm CMOS technology. Synthesis results show that the proposed DHSAF achieves significantly higher throughput compared to the basic HSAF, with only minimal area and power overhead. Furthermore, the proposed DHSAF outperforms the state-of-the-art RFF-KLMS architecture in terms of both area and power efficiency.</description></item><item><title>A 0.31-V 16-Kb 9T SRAM With Enhanced Sensing Margin and Read Performance for Low-Power Applications</title><link>http://ieeexplore.ieee.org/document/11224799</link><description>This brief presents a low-power 9T static random access memory (SRAM) with enhanced read sensing margin and read performance. The read decoupled port of the proposed 9T SRAM cell achieves the enhanced sensing margin by mitigating the read bitline (RBL) leakage and improves the read performance through using one-transistor read path. The multithreshold voltage devices are used in SRAM cell for improving the leakage power and performance of SRAM. Additionally, an interleaved write wordline (WWL) structure is implemented to address the write half-select issue. The measurement results of the test chip fabricated in the 22-nm FDSOI technology demonstrate that the designed 9T SRAM achieves a minimum operation voltage of 0.31 V at 1.05 MHz and can operate at 60.5 MHz when the supply voltage is 0.5 V. The minimum active energy of 18.56 fJ/access-bit is obtained at 0.33 V. Furthermore, the designed SRAM exhibits a minimum leakage power of 0.11 pW/bitcell in the retention mode.</description></item><item><title>An LSGQ-FFS Framework for Adaptive Optimization of Hybrid INT-CIM Architecture</title><link>http://ieeexplore.ieee.org/document/11244865</link><description>Hybrid computing-in-memory (CIM) has recently gained significant attention due to its ability to leverage the strengths of both digital CIM (DCIM) and analog CIM (ACIM). The multibit fusion (MF) scheme enhances energy efficiency by fusing low-bit results, which typically require multiple read-out cycles, into a single-cycle read out. However, the relationship between hybrid INT-CIM circuit design and network performance based on the MF scheme has not yet been systematically explored. In addition, we investigate how different MF configurations affect the performance of various neural networks. To address this gap, we first propose a less-significant group quantization (LSGQ) model, which defines and explores the design space of hybrid INT-CIM. Second, we develop a FastFuse-Search (FFS) algorithm, which optimizes configurations for different networks to strike a better balance between model accuracy and energy efficiency. Based on the experimental results, some key considerations on hybrid CIM design are derived. FFS yields a  $1.72\times $  energy-efficiency boost with negligible accuracy loss. Finally, we fabricate a 28-nm hybrid INT-CIM test chip, achieving 59.74 TOPS/W and 0.96 TOPS/mm2, with performance metrics of 23.21 perplexity for GPT-2, 68.69% accuracy for ResNet18, and 80.53% accuracy for ViT.</description></item><item><title>A Crosstalk Suppressed Reconfigurable Fully Passive Multichannel Noise-Shaping SAR ADC</title><link>http://ieeexplore.ieee.org/document/11239512</link><description>This brief presents a reconfigurable multichannel noise-shaping (NS) SAR analog-to-digital converter (ADC) with crosstalk suppression. All nonmemory blocks are multiplexed among all channels assisted by the proposed timing control scheme, enabling reconfiguration with negligible power and hardware cost. A novel approach to determine the design parameters of nonideal loop filters is proposed, and a crosstalk suppressed multichannel fully passive loop filter is developed based on this method. A memoryless binary dynamic element matching (DEM) is also adopted to suppress the nonlinearity of each channel. The ADC achieves a typical SNDR of 77.49/72.17/66.62 dB with a 20-kHz bandwidth under one-/two-/four-channel modes, respectively, realizing typical Schreier FoMs of 169.54, 167.20, and 164.64 dB. Averaged interchannel crosstalks are &#8722;79.17 and &#8722;77.37 dB with &#8722;2.5-dBFS inputs in all input channels under two- and four-channel modes.</description></item><item><title>A Tri-Band Two-Stage LNA With Simultaneous Linearity and Gain Enhancement for WiFi</title><link>http://ieeexplore.ieee.org/document/11236503</link><description>This brief presents a tri-band, two-stage compact low-noise amplifier (LNA) that simultaneously enhances linearity, gain, and noise performance for WiFi applications. The second stage adopts a dual-path architecture, consisting of a main amplifier and an additional amplifier. The additional amplifier, biased in the subthreshold region, suppresses third-order nonlinearity and enhances gain without increasing power consumption. The first-stage LNA reduces the noise contribution from the second stage, improving overall noise performance. To further minimize power consumption, an inverter-based topology is employed. Fabricated in a 90-nm CMOS process, the proposed LNA achieves an  $S_{11}$  below &#8722;5 dB at 2.4, 5, and 6 GHz, covering key WiFi bands. At 6-GHz band, it delivers 13.5-dB gain, 3.2-dBm third-order input intercept point (IIP3), and 3.1-dB noise figure (NF). At 5-GHz band, it achieves 15-dB gain, 0.7-dBm IIP3, and 2.76-dB NF. At 2.4-GHz band, it provides 20.66-dB gain, &#8722;7-dBm IIP3, and 2.7-dB NF. The circuit consumes only 3 mW of dc power. Measurements at 6 GHz show that the dual-path technique in the second stage improves IIP3 by 8.6 dB, increases gain by 1.5 dB, and reduces NF by 0.6 dB, all without additional power or area overhead.</description></item><item><title>A 0.38-mW, 50-MS/s, 2.3-&#956;App Current-Integration SAR-Based Current-to-Digital Converter for Real-Time OCT Imaging</title><link>http://ieeexplore.ieee.org/document/11271863</link><description>This brief presents an amplifierless current-to-digital converter (CDC) that uniquely integrates an open-loop pseudo-differential current mirror with a current-integration successive-approximation-register analog-to-digital converter (ADC). The proposed architecture enables the CDC to achieve high-speed operation at low power consumption, which is critical for the intended applications in dynamic optical coherence tomography (OCT) systems. Fabricated in 65-nm CMOS, the prototype occupies 0.019 mm2, consumes  $380~\mu $ W from a 1-V supply, and achieves a 47-dB dynamic range (DR) with a 50-MS/s sample rate. It achieves Walden&#8217;s and Schreier&#8217;s figures of merit of 92 fJ/step and 148 dB, respectively, both being the best among reported CDCs.</description></item><item><title>An Analytical Model of Mismatch Dominance Crossover in High-Speed Flash ADC Cores</title><link>http://ieeexplore.ieee.org/document/11288725</link><description>The flash analog-to-digital converters (ADCs), essential for high-speed embedded systems, face inherent linearity constraints due to device mismatch in the resistor ladder and comparator stages. While individual analytical models exist for these mismatch sources, designers rely on Monte Carlo simulations to evaluate the combined errors. This brief introduces a unified analytical framework with closed-form expressions that capture both mismatch sources, enabling efficient estimation of root mean square (rms) integral nonlinearity/differential nonlinearity (INL/DNL). Validated against circuit simulations, the model achieves a mean absolute error (MAE) of 2.71% ( $\boldsymbol {\sigma _{\textbf {DNL}}}$ ) and 2.51% ( $\sigma _{\text {INL}}$ ), and the maximum absolute error (MaxE) remains within 5.44%. This predictive capability guides high-yield, precision, power, and area (PPA)-optimized system-on-chip (SoC) design, enabling over  $3{\times }$  silicon area reduction through application-specific optimization.</description></item><item><title>Modern Wireline Transceivers</title><link>http://ieeexplore.ieee.org/document/11311714</link><description>Over the past two decades, ever-increasing network bandwidth (BW) demands in data centers and high-performance computing systems have fueled exponential growth in per-lane serial link data rates. To keep up with this demand and enable faster communication over BW-limited electrical channels, wireline transceiver architectures and circuit topologies have rapidly evolved over this timeframe to support sophisticated modulation and equalization. This tutorial paper presents an overview of modern serial links. Application background is described, motivating the link energy efficiency and bit error rate (BER) requirements. Transmit and receive circuits and architectures are described for both short-reach and long-reach electrical interconnects. The former tends to rely on power-efficient analog/mixed-signal techniques to equalize relatively low-loss channels with reach up to a few cm, while the latter requires sophisticated digital signal processing (DSP) along with high-speed ADCs and DACs to compensate channels with loss greater than 30 dB at Nyquist. Optical links are reviewed in the context of intra-data center applications where they are increasingly used. Low-jitter, high-phase-accuracy clock generation and distribution techniques are examined. Finally, future directions for modulation, equalization, and error correction to support links exceeding 200 Gb/s are discussed.</description></item><item><title>A 2.16-pJ/b 112-Gb/s PAM-4 Transceiver With Time-Interleaved 2-b/3-b ADCs and Unbalanced Baud-Rate CDR for XSR Applications in 28-nm CMOS</title><link>http://ieeexplore.ieee.org/document/10981549</link><description>This article presents a 112-Gb/s four-level pulse amplitude modulation (PAM-4) transceiver (TRX) for extra-short-reach (XSR) applications in 28-nm CMOS. The receiver (RX) adopts a  $4\times 6$  time-interleaving structure with 2-bit and 3-bit sub-analog-to-digital converters (ADCs) for decoding the PAM-4 signal, eliminating the need for high-speed samplers and saving significant power. The proposed unbalanced baud-rate phase detector (PD) increases the clock and data recovery (CDR) tracking bandwidth without degrading high-frequency (HF) jitter performance. The transmitter (TX) adopts an unsegmented voltage-mode driver with three-tap feed-forward equalizer (FFE). The output impedance control loops maintain the output impedance as different FFE coefficients are applied. This architecture provides high FFE resolution while consuming relatively low power. Designed and fabricated in 28-nm CMOS, the PAM-4 TRX achieves a bit error rate (BER) of &lt;1E&#8722;12 at 112 Gb/s with 2.16-pJ/b energy efficiency over a channel with 8.5-dB Nyquist loss.</description></item><item><title>A 1.19-pJ/b 32-Gb/s Baud-Rate Receiver Employing 2UI Integrated Pattern-Based CDR and DFE Adaptation Without Data-Level Reference</title><link>http://ieeexplore.ieee.org/document/11030828</link><description>This article presents a 32-Gb/s receiver employing a baud-rate clock and data recovery (CDR) and decision feedback equalizer (DFE) adaptation. The proposed receiver utilizes an integrator that integrates analog front-end outputs for two unit intervals (UIs) from the edge of data. The 2UI integration enables the implementation of the pattern-based baud-rate CDR and DFE adaptation algorithm without relying on a data-level reference (dLev). Therefore, the proposed receiver only uses zero-crossing samplers, saving power consumption and chip area. Moreover, the proposed baud-rate CDR is less sensitive to the channel conditions compared to the conventional baud-rate CDR using the Mueller and M&#252;ller phase detector (MMPD). A prototype receiver fabricated in 40-nm CMOS technology is tested with three channels to demonstrate the performance of the CDR and DFE adaptation. As a result, the receiver achieves a bit error rate (BER) less than  $10{^{-12}}$  at 32 Gb/s under 16-dB channel loss. Without the need for the dLev, the proposed receiver occupies an active area of 0.026 mm2 and consumes 38.04 mW, achieving an energy efficiency of 1.19 pJ/b.</description></item><item><title>A 20-Gb/s/Line Single-Ended Transceiver With Coupling-Balanced Crosstalk-Cancellation for Shield-Less 1.5-&#956;m-Pitch Interconnect</title><link>http://ieeexplore.ieee.org/document/11015243</link><description>This article presents a 20-Gb/s/line current-mode (CM) transceiver for dense short-reach on-chip interconnect. The transceiver achieves a systematic crosstalk cancellation (XTC) by balancing the capacitive and inductive coupling. As a receiver frontend, a current-sensing amplifier is designed with an optimum input resistance value for XTC. Without any additional circuits for XTC and equalization, the transceiver implemented in a 40 nm CMOS technology shows a data rate of 20 Gb/s/line and an energy efficiency of 246 fJ/b, even with shield-less dense channels with 1.5- $\mu $ m pitch. In addition, this article analyzes the crosstalk for dense short-reach channels and establishes the theorem of coupling-balanced XTC (CBXTC).</description></item><item><title>A 4-Ch &#215; 64 Gb/s/Ch NRZ VCSEL-Based Co-Packaged Fiber-Terminated Optical TX and 80-Gb/s Optical Driver</title><link>http://ieeexplore.ieee.org/document/10981931</link><description>This article introduces a four-channel (4-Ch) multi-mode (MM) vertical-cavity surface-emitting laser (VCSEL)-based co-packaged optical transmitter (TX), integrating a VCSEL array, a VCSEL driver (VCDRV) IC, an electrical TX IC, and optical fiber termination within a single package. A complex-zero continuous-time linear equalizer (CZ-CTLE) is proposed to effectively equalize the complex-pole response of the VCSEL, improving in-band gain/group delay (GD) flatness and extending bandwidth (BW). To enhance link energy efficiency and jitter margin, resonant clocking techniques are proposed, including a transmission-line-based resonant global clock distribution and a wide-tuning-range coupled-resonator-based quadrature generation. A low-power electrical TX architecture employing an NMOS-over-NMOS (N/N) voltage-mode driver with eye symmetry correction is introduced to further improve the energy efficiency and link margin. The optical TX prototype, implemented in a 22-nm FinFET process, achieves an aggregate non-return-to-zero (NRZ) data rate of 256 Gb/s with an energy efficiency of 1.3 pJ/b. This work outperforms previous optical TXs by  $\gt 2.2\times $  in optical modulation amplitude, achieving  $1.4\times $  ( $7.6\times $ ) greater eye width (EW) [eye height (EH)], with 14% higher per-channel baud rate and 11% better energy efficiency. The direct-drive optical driver achieves 80-Gb/s NRZ operation, demonstrating a 13% higher data rate and  $25\times $  better energy efficiency than prior art. This work also marks the first successful demonstration of more than 50-Gb/s VCSEL-based co-packaged optical TX topology at a  $6.4\times $  higher rate than the previous efforts.</description></item><item><title>A PLL Technique: Charge-Steering Sampling</title><link>http://ieeexplore.ieee.org/document/11017517</link><description>This article introduces a charge-steering sampling (CSS) technique for time-error detection (TD), an equivalent of phase detection (PD), in phase-locked loops (PLLs). The CSS mechanism presets the input capacitors of a successive approximation register (SAR) analog-to-digital converter (ADC) to  $V_{\text {DD}}$  and subsequently discharges them during a reference-triggered pulse through a pseudo-differential MOS pair directly driven by the oscillator. The resulting differential-mode (DM) charge residue, proportional to the time error, is digitized by the ADC to support all-digital PLL (ADPLL) operation. The proposed technique simultaneously achieves high-TD gain for low jitter, the excellent oscillator isolation for reduced reference spur, and multi-bit digital TD output for fast locking, fully leveraging the capabilities of advanced CMOS technology. A digital loop filter (DLF) featuring a dead zone (DZ) in the integral path is introduced to mitigate potential conflicts with the proportional path. To accommodate the short-oscillator period  $T_{\text {osc}}$  at millimeter-wave (mm-wave) frequencies, we propose extending the CSS pulsewidth to  $1.5\,T_{\text {osc}}$ . In addition, a damped-sine waveform model for the CSS current is developed, providing deeper insights into the high-TD gain characteristics. The comprehensive noise analysis of the CSS is conducted using a multirate timestamp model, identifying contributions to the output phase noise (PN). Fabricated in 22-nm CMOS, the 18.8&#8211;23.3-GHz CSS-ADPLL prototype achieves 63-fs rms jitter, &#8722;52.4-dBc reference spur, and a figure of merit (FoM) of &#8722;254 dB, while consuming 9.95-mW total power, with only 1.3 mW allocated to the loop. For an initial frequency error of 200 MHz, the system achieves a locking time of  $0.61~{\mu }$ s, benefiting from the combined effects of a counter-based frequency-locked loop (FLL) ( $0.27~{\mu }$ s) and the multi-bit digital output of the CSS-ADPLL ( $0.34~{\mu }$ s).</description></item><item><title>A D-Band Distributed MIMO FMCW Radar CMOS Transceiver</title><link>http://ieeexplore.ieee.org/document/11049937</link><description>This work introduces a D-band 4TX/4RX distributed multiple-input-multiple-output (MIMO) frequency-modulated continuous-wave (FMCW) radar CMOS transceiver with real-time reference-clock synchronization for multistatic imaging system. The proposed synchronized distributed MIMO radar system eliminates the frequency error, time error, and slope error of local oscillator (LO) signals between radar stations to ensure the correct acquisition and analysis of radar signals, which enables the combination of target data from multitude of transmitting and receiving stations coherently. In addition, several circuit design techniques, including harmonic extraction series power synthesis and harmonic suppression (HS) frequency doubling, are investigated. This work achieves better detection performance than traditional MIMO radar with the same number of channels, demonstrating its advantages in future cooperative coherent multistatic imaging systems.</description></item><item><title>Packaged K-/Ka-Band Down/Up Frequency Converter Chipsets for Phased Array SATCOM Ground Terminals in 65-nm CMOS</title><link>http://ieeexplore.ieee.org/document/10980280</link><description>Large-scale integrated phased arrays are enabling the millimeter-wave (mm-Wave) satellite communications (SATCOMs). Dedicated to the SATCOM planar phased array systems, the design of the K-/Ka-band down/up frequency converter (FC) chipsets is detailed in this article. The quadrature Gilbert FCs benefit from the proposed differentiated IF and LO high-order in-phase and quadrature (IQ) balancing techniques, supporting fully on-chip high-image/sideband rejection ratio (IRR/SRR). The wideband IF signal processing chains, simultaneously enabling gain control, reconfigurable filtering, Hilbert transformation, voltage/power amplifying, as well as single-ended/differential signal conversions, are proposed for the heterodyne up and down FCs, contributing to versatile and ready-to-use IF interfaces for various SATCOM modems in L and S bands. Power amplifying and buffering stages accompanied by gain control blocks are integrated to enhance the driving capability and dynamic range. In addition, the harmonic rejection quadrupler chain is adopted to relieve the high-frequency low-noise requirements on external LO sources and allow low-loss on-board routes. Fabricated in 65-nm CMOS technology and packaged with the wafer-level chip-scale packaging (WLCSP), the FC chipsets fully support the 2-D operation in the RF band of 17.7&#8211;21.2 GHz [downlink receiver (RX)]/27.5&#8211;31.0 GHz [uplink transmitter (TX)] and the wide-IF band of 0.8&#8211;4 GHz, offering the peak conversion gain of 35.7/33 dB for the RX/TX, with over 40-dBc IRR/SRR and 58-dBc calibrated LO suppression.</description></item><item><title>A Millimeter-Wave Power Amplifier With an Integrated CMOS Isolator/Circulator/Receiver</title><link>http://ieeexplore.ieee.org/document/11018353</link><description>This article presents a reconfigurable millimeter-wave (mm-wave) fully integrated transceiver (TRX) front end that comprises a power amplifier (PA) and an integrated nonreciprocal ultra-compact isolator/circulator/receiver (RX). The circulator is based on a ring quarter-wave transmission line (QTL) topology with adjusted characteristic impedances, which improves transmitter (TX)-to-antenna insertion loss and TX-to-RX isolation. The circulator&#8217;s nonreciprocal gyrator features an and-gate switching-based N-path filter while also acting as a mixer-first RX. By activating the embedded cross-coupled negative resistors, the circulator can be reconfigured as an isolator. This compact N-path filter-based circulator/isolator occupies only 0.38 mm2. Over a 27.1&#8211;31.1-GHz band, the realized front end offers &gt;20-dB TX-to-RX isolation, with a measured TX-to-antenna insertion loss of  $1.7{\sim }2.2$  dB. The RX path tolerates the PA&#8217;s blocker signal, achieving 5-dBm in-band and 13-dBm out-of-band (OOB)  $B_{\text {1dB}}$ . The PA delivers 15.15-dBm peak output power with 33% drain efficiency. The functionality of the proposed frequency division duplex (FDD) front end is evaluated by simultaneous TX/RX operation with a 400-MHz TX/RX modulation bandwidth and 400-MHz channel spacing. The measured AM&#8211;PM of the realized PA with the integrated isolator shows relatively high voltage standing wave ratio (VSWR) resilience at the lower power level and less robustness against VSWR around its peak output power. The front-end prototype occupies only 0.7 mm2, including circulator, PA, quadrature hybrid coupler LO generators, and baseband circuits.</description></item><item><title>A Multi-Band 5.3&#8211;18 GHz LNA for FR3 Bands Using Hybrid Switching With Sub-2 dB NF in FDSOI</title><link>http://ieeexplore.ieee.org/document/11008556</link><description>This article presents a multi-band 5.3&#8211;18-GHz low-noise amplifier (LNA) for 6G applications in GlobalFoundries 22FDX technology. The LNA consists of two stages employing tunable LC inter-stage and output matching networks. Using this technique, a sub-2 dB noise figure (NF) across three bands of operation is achieved. The measured results show three different frequency range 3 (FR3) bands with 3 dB bandwidths of 5.3&#8211;9.4 GHz, 8.3&#8211;13 GHz, and 11.5&#8211;18 GHz with a NF of 1.6&#8211;1.8 dB, 1.6&#8211;1.8 dB, and 1.8&#8211;2.2 dB, respectively. The LNA also operates in a wide-band mode with a bandwidth of 6.6&#8211;16.3 GHz and a NF of 2.4&#8211;3.2 dB. The LNA achieves an  $\text {IP}_{\text {1dB}}$  of &#8722;18 to &#8722;22 dBm, and an IIP3 of &#8722;8.7 to &#8722;12.7 dBm for the three bands, and consumes 20 mW from a 1 V supply. The multi-band LNA also shows fourth-order filtering characteristics, which greatly relaxes the requirements of external filters. Results are compared to prior work and show state-of-the-art performance.</description></item><item><title>An 11-GHz Ultra-Fast Wideband FMCW Chirp Generator With 0.051% RMS Frequency Error Under 2.3-GHz Chirp Bandwidth and 2.3-GHz/&#956;s Slope in 65-nm CMOS</title><link>http://ieeexplore.ieee.org/document/11048873</link><description>An 11-GHz ultra-fast wideband frequency-modulated continuous-wave (FMCW) chirp generator with high linearity is presented for rapid walk-through imaging. To facilitate fast frequency modulation while reducing phase noise, a digital-to-time converter (DTC)-based sub-sampling phase-locked loop (SSPLL) with two-point modulation (TPM) technique is leveraged. Integrated with a ramp integrator, the proposed second-order curve-fitting (2nd-CF) digital predistortion (DPD) technique could remarkably mitigate the nonlinearities in the frequency modulation path while significantly reducing the hardware complexity. Meanwhile, a ramp tracker is parallelly utilized to initialize the lookup table (LUT) of DPD for a robust chirp linearity calibration. To reduce the idle time of the ultra-fast chirp without affecting its linearity, a modified DTC modulator is designed to achieve zero phase error at large frequency hopping moments. Furthermore, to achieve robust background calibrations in SSPLL, a voltage tracking loop (VTL) with a hold function is proposed to extract the phase-error sign and cooperate with the LUT to ensure an orderly convergence of the DPD. Fabricated in a 65-nm CMOS process, the FMCW chirp generator occupies a core area of 1.2 mm2 and consumes 50.8 mW. The measured maximum chirp bandwidth is 2.4 GHz, corresponding to 21.4% of the center frequency. A maximum chirp slope of 2.3 GHz/ $\mu $ s is achieved with 2.3-GHz chirp bandwidth, 1- $\mu $ s chirp duration, and 50-ns idle time, and the largest measured rms frequency error is 1198 kHz for sawtooth and triangular chirps, corresponding to 0.052% of the chirp bandwidth.</description></item><item><title>A Hybrid Voltage-Time Domain Pipelined ADC With Reference-Embedded Time-Domain Residues</title><link>http://ieeexplore.ieee.org/document/11048902</link><description>This article presents a hybrid voltage-time domain pipelined analog-to-digital converter (ADC). The proposed ADC employs a voltage-domain SAR quantizer for the coarse stage, while a time-domain quantizer is used for the fine stage. A hybrid-domain dual-residue method is proposed to generate reference-embedded time-domain residues. It ensures full-scale matching between the converted time-domain residue and the time-domain reference of the fine stage. For the fine stage sub-quantizer, an interpolating time-to-digital converter (TDC) suited for dual-residue quantization is employed without using an external time-domain reference. A prototype ADC, implemented in a 40-nm CMOS process, occupies 0.034 mm2. Operating at a sampling rate of 150 MS/s, the ADC achieves an SNDR of 61.1 dB and an SFDR of 75.5 dB at a Nyquist input, while consuming 2.54 mW, resulting in a Walden figure-of-merit (FoMW) of 18.3 fJ/conv.-step.</description></item><item><title>An Easy-Driving Incremental Zoom ADC With Skipped Sampling Scheme and NS-SAR Quantizer</title><link>http://ieeexplore.ieee.org/document/11039217</link><description>This article presents an incremental zoom analog-to-digital converter (ADC) for Internet-of-Things (IoT) applications. Unlike prior zoom ADC designs, a floating inverter amplifier (FIA)-assisted residue extraction scheme is proposed to maintain the residue voltage during loop filtering. It allows the ADC to skip repeated sampling operations between consecutive fine conversions, thus largely reducing the sampling time and driving cost. To speed up the conversion, a high-efficiency second-order single buffer embedded noise-shaping (NS) successive approximation register (SAR) is proposed as the fine quantizer, allowing a low conversion cycle of 32. Together with the amplifier-reused kT/C noise cancellation technique, the prototype ADC fabricated in a 28-nm CMOS realizes a 92.5-dB SNDR at 300 kS/s with a small input capacitor of 0.8 pF. With fully dynamic operation, the power consumption is only  $160~{\mu}$ W, leading to a superior Schreier figure of merit (FoM) of 182.2 dB.</description></item><item><title>A Bi-Directional Neural Interface Chip With 32-Channel 83-dB DR CTDSM-Based Recording Using FIRDAC With Pre-Emptive ELD Compensation</title><link>http://ieeexplore.ieee.org/document/11023219</link><description>Clinical-ready neuromodulation devices for real-time monitoring and treatment of neurological disorders require a neural interface integrated circuit (IC) that supports therapeutic neurostimulation together with concurrent recording of neural activities from large brain regions. To address this need, this article presents an IC with 32 high dynamic range (HDR) electrocorticography (ECoG) recording channels and two programmable neurostimulators allowing bi-directional neural interfacing. The recording channel uses a 2nd-order continuous-time  $\Delta \Sigma $  modulator (CTDSM) architecture with 12-tap finite impulse response digital-to-analog converter (FIRDAC) feedback facilitated by a pre-emptive current-steering excess loop delay (ELD) compensation scheme. By employing a high-performance linearized low-noise/low-power transconductance amplifier (L3TA) in the input integration stage, the recording channel achieves 83-dB dynamic range (DR) with up to 222-mVpp linear input range, and thus can accommodate large electrode dc offsets (EDOs) and stimulation artifacts. Thanks to the FIRDAC that relaxes component matching requirements, each recording channel occupies only 0.028 mm2 and consumes  $5.39~{\mu }$ W while being manufactured in standard 180-nm CMOS technology. The concurrent neural recording and stimulation capabilities of the chip have been validated in a mouse experiment in vivo, which shows that the recording channel can tolerate real stimulation artifacts and the recorded ECoG signals can be separated from the artifacts with high fidelity.</description></item><item><title>A Highly Power-Efficient Input-Boosted First Stage for Capacitively Coupled Chopper Instrumentation Amplifiers</title><link>http://ieeexplore.ieee.org/document/10988836</link><description>This article presents a highly power-efficient capacitively coupled chopper instrumentation amplifier (CCIA) featuring an input-boosted first stage and leakage compensation circuits. To address the limitations of low-noise front-end amplifier design imposed by the physical constraints of  $g_{\mathrm {m}}/I_{\mathrm {d}}$ , we proposed an input-boosted, inverter-based operational transconductance amplifier (OTA) scheme. This approach introduces a new perspective by doubling the signal-dependent voltage, effectively halving the input-referred noise (IRN) with the same supply current and voltage. Two prototypes were implemented in 180 and 22 nm CMOS processes, consuming 24 and 1.6 nW, respectively. To mitigate leakage current issues in the ultralow-power 22 nm prototype, compensation circuits are incorporated to address reverse-biased diode leakage and bulk leakage current. The 180 nm prototype achieves an IRN of  $5.09~{\mathrm {\mu V_{\rm rms}}}$  within a 1.6 kHz bandwidth (BW), yielding a power efficiency factor (PEF) of 0.58. The 22 nm prototype achieves an IRN of  $8.05~{\mathrm {\mu V_{\rm rms}}}$  within a 230 Hz BW, resulting in a PEF of 0.69. Measurements under varying temperatures validate the effectiveness of the leakage compensation circuits. The proposed input-boosted CCIA achieves the highest PEF among continuous-time amplifiers (CTAs), offering a general solution for power-efficient amplifier design.</description></item><item><title>A Capacitive Touch-Sensing Chip With NTF-Alignment Excitation Source and Direct Lock-In ADC</title><link>http://ieeexplore.ieee.org/document/11029238</link><description>Capacitive touch-screen systems have been widely used in tablets, smartphones, smartwatches, etc. Various sources of noise, such as display and charger noise, limit the energy efficiency of capacitive touch sensors. Traditional noise-reduction methods such as lock-in sensing architecture lead to significant power consumption that shortens the lifetime of battery-powered devices. To address the issue, we propose a noise transfer function (NTF)-alignment technique, in which the excitation signals are precisely placed at the zeros of NTF and the touch-screen system noise lies between them. In addition, a subsequent direct lock-in analog-to-digital converter (ADC) with bandpass noise shaping utilizes the same NTF zeros as the excitation source, resulting in a high signal-to-noise ratio (SNR) throughout the entire signal chain. This simple structure also eliminates bandpass filters, mixers, and low-pass filters in conventional lock-in sensing chains. The proposed techniques are implemented in a 65-nm CMOS process, demonstrating a touch-screen prototype embedded with a 28-channel chip occupying an area of 1.31 mm2. The measured results show that the chip achieves an SNR of 58.9 (for 10-mm  $\Phi $ ) and 41.3 dB (for 1-mm  $\Phi $  stylus), with only 1.054-mW power dissipated at 120 frames/s. Compared to state-of-the-art designs, the proposed chip achieves the best energy efficiency (27.2 pJ/step).</description></item><item><title>A 96.5% Efficiency Hybrid Step-Up Converter With Low Input-Level Voltage Stress and Duty-Independent Constant Inductor Current</title><link>http://ieeexplore.ieee.org/document/11017521</link><description>This article presents a duty-independent step-up converter (DIUC) for battery-powered or USB-powered devices. The DIUC limits the voltage stress on all switches to an input voltage (VIN) level, eliminating the need for high-voltage (HV) transistors like LDMOS. Unlike previous step-up converters where the inductor current (IL) rapidly increases as a duty (D) rises, the DIUC maintains IL equal to the load current regardless of D. This feature mitigates the conduction loss due to the inductor parasitic dc resistance (DCR) and right-half-plane (RHP) zero effect, improving both power efficiency and frequency response. When changing the operation mode according to the conversion ratio (CR), the DIUC achieves a small overshoot of 158 mV and undershoot of 107 mV in the output voltage (VOUT) with the proposed smooth mode transition (SMT) technique. Additionally, a multi-step gate driving method with two precharging techniques reduces the required bootstrap capacitance by 46.3% to save the silicon area. The 0.18- $\mu $ m prototype chip uses only 5-V CMOS transistors, while all bootstrap capacitors are integrated on the chip. With a 4.7- $\mu $ H inductor (DCR of 98 m $\Omega $ ) and two 10-  $\mu $ F flying capacitors, the DIUC achieves high  ${V} {_{\text {OUT}}}$  up to 13 V, a maximum load current of 1.2 A, and a peak efficiency of 96.5%.</description></item><item><title>A 3&#8211;5 V to Sub-1 V DLDO-SC-Sigma Converter With Auxiliary Loop for Efficiency Improvement in High-Density Power Delivery</title><link>http://ieeexplore.ieee.org/document/11002627</link><description>This article presents a switched-capacitor (SC) sigma converter with a digital low dropout (DLDO) regulator and an auxiliary loop for efficiency improvement for high-density power delivery applications. The proposed converter has the input-series and output-parallel feature, and it consists of a hybrid SC converter on the high side for high density and high efficiency, and a DLDO on the low side for fast voltage regulation. By combining two sides of converters, this work takes advantage of both high power density and fast response under 5 V to sub-1 V step-down conversion. To further improve overall efficiency, an auxiliary control loop is proposed to guarantee a minimized dropout voltage for the DLDO across a wide range of input and output voltages. The DLDO-SC-Sigma converter was fabricated in a 40 nm CMOS process. It can deliver 5 A maximum current from 3 to 5 V input to sub-1 V output and achieves a peak efficiency of 92%. A  $1.6~{\mu }$ s response time and 36 mV voltage droop are achieved with a 2 A load transient. The converter achieves a system power density of 101.3 W/cm3.</description></item><item><title>A 24&#8211;20-V Isolated DC-DC Converter Using a Transformer-Based Supply-Generating Technique</title><link>http://ieeexplore.ieee.org/document/11007660</link><description>This article introduces a 24&#8211;20-V isolated dc-dc converter that utilizes a transformer-based supply-generating technique to efficiently drive power transistors. Traditional high-voltage inverters with output voltages above 5 V typically require dedicated power converters, such as LDOs or buck converters, to supply power to gate drivers and control circuits, often leading to reduced efficiency and increased system costs. In this work, an efficient supply-generating technique that directly produces a 5-V power supply from an auxiliary coil&#8212;strategically positioned to harness energy from the primary coil&#8212;simplifies the power supply design and eliminates the need for external components. The transmitter (TX) and receiver (RX) were fabricated using a 0.18- $\mu $ m BCD process and packaged in a land grid array (LGA) package. Experimental results confirm that the converter achieves a peak efficiency of 73.2% and a power density of 36.5 mW/mm3. Compared to other integrated solutions, the proposed converter realizes a 13.2% efficiency improvement, and its electromagnetic interference (EMI) performance satisfies the CISPR-32 Class B standard on a two-layer PCB without any stitching capacitors.</description></item><item><title>A 48&#8211;5-V Buck Converter With Triple EMI Suppression Circuit for Achieving 41-dB Peak EMI Reduction and Meeting CISPR 25 Automotive Standards</title><link>http://ieeexplore.ieee.org/document/11036262</link><description>This article presents a triple electromagnetic interference suppression circuit (TESC) designed to reduce electromagnetic interference (EMI) value to meet CISPR 25 standards. The energy resonant recycling (ERR) technique is employed to control dv/dt of  $V_{\text {SW}}$  using additional  $L_{\text {r}}$  and capacitors ( ${C} {_{1}}$  and  ${C} {_{2}}$ ) to achieve zero-voltage switching (ZVS) and zero-current switching (ZCS). Simultaneously, the dv/dt of  $V_{\text {SW}}$  is adjusted by the limiting pre-charge current  $I_{L\text {r}}$  to lessen  $V_{\text {SW}}$  ringing, thereby contributing to EMI suppression. Moreover, ERR recycles the ringing energy at  $V_{\text {SW}}$  back to the input switched-capacitor (SC) network during light-load condition. The line impedance stabilization network-based front-end cancellation (LFC) generates a current  $I_{\text {INJ}}$  through sense  $V_{\text {IN}}$  information to eliminate the current ripple of  ${I} {_{\text {Battery}}}$  from 4.5 to 0.8 mA, thereby preventing interference with other circuits and reducing EMI. The true-random spread-spectrum modulation (TR-SSM) utilizes dual TR-SSM to effectively mitigate harmonic tone. After applying TR-SSM, the EMI amplitude of  $V_{\text {Battery}}$  and  $V_{\text {SW}}$  can be significantly reduced by 20 and 16 dB at  $f_{\text {SW}}$ , respectively. By combining these three techniques, TESC reduces EMI by 33 dB at 2 MHz and 41 dB at 73 MHz.</description></item><item><title>A Cryo-BiCMOS Controller for Quantum Computers based on Trapped Beryllium Ions</title><link>http://ieeexplore.ieee.org/document/11272083</link><description>This article presents a cryo-BiCMOS system on chip (SoC) designed for single and two-qubit gate operations for quantum computers (QCs) based on beryllium trapped-ions (TIs). Signal generation from 0.7 to 1.6 GHz is supported, covering all microwave transitions in a  ${}^{9}\text {Be}^{+}$  QC realization. An integrated 48-kbit waveform memory is implemented for improved two-qubit gate fidelity. The fabricated IC is verified in a 4 K environment with up to 4 qubits, thus enabling quantum processor unit (QPU) cointegration. IC operation up to RT ensures compatibility with future system realizations. Measurements demonstrate qubit state control with an oscillation amplitude of 94% before SPAM correction and Rabi oscillation rate of 172 kHz. Evaluations of long sequences of  $\sigma _{x}$  gates indicate control of the quantum state with high quality. Interaction with one computational zone is possible at a total power consumption of 86 mW translating to 21.5 mW/qubit in the presented measurements. Comparison with the state-of-the-art controller reveals drastic power and form-factor reduction at comparable performance, thus paving the way for a scalable TI platform. The chip is fabricated in a 0.13- $\mathrm {\mu }\mathrm {m}$  SiGe BiCMOS technology. To the best of our knowledge, this is the first reported from-scratch system design for TI-based QC concluding with a qubit state manipulation demonstration.</description></item><item><title>SRAM Static Entropy Extraction From Every Single Transistor in Unmodified Bitcell and Data Fingerprinting for Provenance Assurance</title><link>http://ieeexplore.ieee.org/document/11168123</link><description>In this work, an SRAM macro uniquely extracting static entropy from every transistor in unmodified 6T bitcells is presented, achieving for the first time 6-bit/bitcell entropy. When operating as a conventional physically unclonable function (PUF), it achieves a state-of-the-art 296% PUF-to-SRAM capacity ratio without any error correcting code (ECC), retaining its energy and area efficiency at the system level. In addition, the PUF output has native cryptographic-grade quality after one-time self-calibration, uniquely suppressing any entropy post-processing circuitry. As further operating mode, the proposed SRAM macro performs data fingerprinting by exploiting its unique data-dependent response. Data fingerprinting represents an additional layer of security supporting provenance assurance of data and user authentication in real time or in retrospect. Competitive 134-F2/bit area efficiency is demonstrated in 28 nm with minor modification of conventional SRAM periphery.</description></item><item><title>EMEP: Early-Monitoring Error Prediction for Activity and Variability Resilience in a 28-nm RISC-V Controller</title><link>http://ieeexplore.ieee.org/document/11015592</link><description>In situ timing monitoring significantly improves the energy efficiency of low-voltage digital ICs by eliminating the excessive timing margins inserted to address high PVT variations in conventional digital flows. However, such techniques face challenges related to design overhead and robustness. This article presents the early-monitoring error prediction (EMEP) technique to address these issues effectively. With minimal clock tree (CT) impact and low area (1.6%) and power overhead (2%), EMEP achieves 60% endpoint coverage. This wide coverage, combined with increased resilience against critical activity masking and variability, enhances system robustness. In addition,  $4\sigma $  yield is ensured through statistical critical path identification. Automatically integrated into a 28-nm CMOS RISC-V microcontroller, EMEP recovers 86% of conventional energy margins and reduces energy consumption by 2.9 pJ/cycle (41%), outperforming traditional replicas by 61% and endpoint monitoring (EPM) techniques by 31%. EMEP operates the microcontroller with only 14.5% energy overhead compared with margin-free operation, which is essential to address activity uncertainty, becoming minimal when the slowest critical paths are active.</description></item><item><title>An Adaptive Clock Duty-Cycle Controller to Mitigate Aging-Induced Clock Duty-Cycle Distortion in Automotive and IoT Processors</title><link>http://ieeexplore.ieee.org/document/11089959</link><description>An adaptive clock duty-cycle controller (DCC) mitigates the adverse effect of aging-induced clock duty-cycle distortion (DCD) on the minimum supply voltage ( $V_{\text {MIN}}$ ) of high-performance automotive and Internet of Things (IoT) processors. The all-digital DCC measures the DCD from a clock-leaf node with a duty-cycle monitor (DCM). The DCM interfaces with an adaptive control to configure a duty-cycle adjuster (DCA). The DCA adapts the duty cycle at the clock-root node to compensate for the DCD at the clock-leaf nodes. A 3-nm test chip integrates the DCC into the clock path of a high-performance, industry-level neural processing unit (NPU) matrix-multiplication unit (MXU). Silicon measurements validate the DCC system with a self-checking test, as required for automotive processor safety compliance. Silicon accelerated-stress test-chip measurements demonstrate the DCC restoring the clock duty cycle from aging-induced clock DCD and the corresponding MXU  $V_{\text {MIN}}$  degradation, up to 10% at 1.2 GHz and 9% at 0.6 GHz.</description></item><item><title>A 14 nm SRAM Using NMOS Header Assist Cell for Improved Write Ability and Reduced Cell Retention Leakage With Minimal Power Overhead</title><link>http://ieeexplore.ieee.org/document/10976723</link><description>This article presents an NMOS header assist cell (NHAC) that lowers static random access memory (SRAM) minimum operating voltage ( $V_{\text {MIN}}$ ) with minimal power overhead for low-power applications, even in the case of increased interconnect resistance ( $R_{\text {INT}}$ ) with technology scaling. The proposed NHAC, featuring a Bitcell-compatible layout, is inserted between cell arrays to supply power by dividing cell-power (CVDD) into sub-arrays without additional dummy cells or white space. NHAC improves write ability even in high  $R_{\text {INT}}$  cases, thanks to the continuous self-collapse of the CVDD voltage by supplying cell power through NMOS during write operations. The NMOS header in NHAC prevents excessive CVDD voltage collapse, thus ensuring the dynamic data retention stability of column half-selected cells (CHSCs). Additionally, by enabling all NHACs in sleep mode, the CVDD voltage can be clamped below the supply voltage, thereby reducing bitcell retention leakage without additional area costs. SRAM macros with additional resistors were fabricated using a 14 nm FinFET process to measure the impact of  $R_{\text {INT}}$  on the write assist circuits. NHAC achieves a  $V_{\text {MIN}}$  improvement of 210 mV with 4% power overhead, even in the high  $R_{\text {INT}}$  case. In sleep mode, NHAC reduces bitcell retention leakage by 25% at 0.65 V and up to 61% at 1 V. NHAC demonstrates improved write  $V_{\text {MIN}}$  similar to transient voltage collapse (TVC) write assist. Additionally, it achieves low-power overhead similar to self-induced voltage collapse (SIC) write assist.</description></item><item><title>A 22-nm 109.3-to-249.5-TFLOPS/W Outlier-Aware Floating-Point SRAM Compute-in-Memory Macro for Large Language Models</title><link>http://ieeexplore.ieee.org/document/11016687</link><description>Large language models (LLMs) have demonstrated exceptional performance in complex artificial intelligence (AI) tasks. However, their rapidly increasing parameter sizes lead to significant communication and computational overhead, posing challenges to the energy efficiency (EEF) and memory footprint of AI processors. Compute-in-memory (CIM) architecture has emerged as a promising solution to alleviate bandwidth constraints and improve EEF. Nonetheless, both integer (INT) and floating-point (FP) CIM implementations struggle with the trade-off between accuracy and memory requirement when applied to LLMs. Outlier-aware quantization (OAQ), which employs low-precision formats for normal values and retains FP formats for high-magnitude outliers, has proven effective in matching the accuracy of full-FP baselines and has become a mainstream approach for efficient LLM deployment. Therefore, this work presents OA-CIM, an SRAM-based digital CIM macro that facilitates element-wise hybrid processing of BF16 outliers and INT4 normal values. The major contributions are: 1) an LUT-based multiply-and-accumulate (MAC) circuit design, which supports efficient FP/INT-compatible (FIC) MAC operations; 2) an xor-sharing non-maximum exponent gating scheme that reduces latency and area by bypassing unnecessary exponent comparisons in FP dataflow; and 3) a sparsity-aware readout circuit with distribution-offset weight encoding (DOWE) to mitigate the power-intensive charging/discharging process on the bitline. A 22-nm 512-kB 8T SRAM OA-CIM prototype is fabricated, which achieves an EEF of 346.6 TOPS/W in INT4 mode and 249.5 TFLOPS/W in outlier mode, representing a  $2.7{\times }$  to  $3.1{\times }$  improvement over state-of-the-art mixed-precision CIMs.</description></item><item><title>Cache-PIM: An ECC-Compatible eDRAM Processing-in-Memory for Last-Level Cache With Triple-Level Error Correction</title><link>http://ieeexplore.ieee.org/document/11007279</link><description>This article presents cache-processing-in-memory (PIM), an error correction code (ECC)-compatible embedded dynamic random access memory (eDRAM) PIM-based last-level cache (LLC) with a novel triple-level error correction. Integrating PIM into the cache system causes the existing ECC to become a performance bottleneck, leading to higher latency and decreased computational accuracy. An ECC-compatible eDRAM-PIM enables reliable in-memory computing (IMC) even in less stable DRAM environments while reducing ECC latency for PIM tasks. Cache-PIM proposes three key features: 1) triggered error correction with concurrent error detection (TECCED) reduces cell error correction latency for PIM tasks; 2) adaptive error canceling (AEC) corrects computation errors; and 3) resolution-aware single-cycle voting (RSV) reduces analog-to-digital converter (ADC) readout error. Cache-PIM is fabricated in 28-nm CMOS technology and occupies 0.66-mm2 die area. A demonstration of ViT-Base on the ImageNet dataset achieves 61% latency reduction compared to the conventional ECC and 77.1% accuracy.</description></item><item><title>ETCIM: Error-Tolerant Digital CIM Processor With Redundancy-Free Hard Error Repair and Run-Time Soft Error Correction</title><link>http://ieeexplore.ieee.org/document/11007640</link><description>Digital computing-in-memory (CIM) has demonstrated outstanding energy and area efficiency. Although digital CIM avoids errors along the in-memory computing path, it is indispensable to correct hard and soft errors in digital CIM&#8217;s SRAM cells like conventional SRAM for commercial products. Hard errors come from defects in chip fabrication. Soft errors result from bit flips in an SRAM cell during CIM computation, and cause multiply-accumulation (MAC) errors. However, traditional SRAM&#8217;s error correction scheme cannot be directly applied to digital CIM, which causes hardware overhead in hard error repair, and incompatibility and latency problems in soft error correction. To tackle the above challenges, we propose an error-tolerant digital CIM processor ETCIM with three corresponding features: 1) a fault-adaptive CIM initializer (FACI) and input feeder reduce the hard error repair overhead by up to  $8.47{\times }$  power and  $18.16{\times }$  area savings; 2) a blockwise error correction code (BW-ECC) CIM macro suits the digital CIM structure that integrates multiple weight blocks, and corrects soft MAC errors; and 3) a progressive cell error corrector (PCEC) hides soft cell error correction latency during computation, reducing the total latency by up to 96.8%. The fabricated ETCIM achieves a state-of-the-art energy efficiency with an error correction of 19.5 tera operations per second (TOPS)/W at INT8.</description></item><item><title>FSNAP: An Ultra-Energy-Efficient Reconfigurable Few-Spikes-Neuron-Based SNN Processor Supporting Unified On-Chip Learning and Adaptive Time-Window Tuning</title><link>http://ieeexplore.ieee.org/document/11031188</link><description>Spiking neural network (SNN) processors have attracted significant attention as energy-efficient alternatives to artificial neural network (ANN) processors due to their event-driven and sparse computing properties. However, existing SNN processors primarily rely on leaky-integrate-and-fire (LIF) neurons, which require large time-windows (TWs) and a substantial number of spikes to achieve high accuracy. This results in excessive energy consumption and high latency. Furthermore, most SNN processors either support spike-based backpropagation (BP) learning or ANN-to-SNN conversion-based learning, limiting their adaptability across diverse applications. Additionally, the use of fixed-size TWs leads to inefficient resource utilization and poor adaptability to dynamic input characteristics. To address these challenges, this work proposes FSNAP, an energy-efficient SNN processor that leverages the recently introduced few-spikes-neuron (FSN) model. Unlike conventional LIF neurons, FSNs utilize an optimized spike encoding and decoding scheme that enables high computational efficiency with significantly fewer spikes and a shorter time window. The proposed processor has the following contributions: 1) a reconfigurable FSN-based SNN inference and learning architecture with time-skipped spike accumulation and parallel spike generation, which achieves low-latency, high-efficiency computation; 2) a unified on-chip learning architecture supporting the proposed low-complexity FSN-hybrid learning, FSN-BP learning, and ANN-to-FSN-SNN conversion based (FSN-conversion) learning, which enhances accuracy and flexibility across various applications; and 3) an accuracy-driven adaptive TW tuning technique that dynamically adjusts TW sizes to optimize energy consumption and latency while maintaining high accuracy. Fabricated in a 55-nm CMOS process, FSNAP achieves substantial improvements over state-of-the-art SNN designs on six different tasks. On the IMAGE task, it demonstrates  $2.24{\times }$  to  $172.8{\times }$  higher energy efficiency when scaled to the same process node and operating voltage, and  $3.40{\times }$  to  $1616.4{\times }$  speedup when scaled to the same operating frequency, all while maintaining high accuracy.</description></item><item><title>Ferroelectric Digital In-Memory Computing for Scalable, Reliable, and Efficient Similarity Computation</title><link>http://ieeexplore.ieee.org/document/11178075</link><description>Classification-based learning in deep neural networks, particularly few-shot learning, demands efficient similarity metrics such as Hamming distance. Conventional architectures suffer from high energy overheads due to frequent data movement between memory and processing units, hindering scalability. In-memory computing addresses this by integrating computation within memory, yet analog-based systems rely on power-hungry analog-to-digital converters (ADCs) and face scalability challenges due to device variability, especially in emerging memories. This work presents a fully digital Ferroelectric FET (FeFET)-based Logic-in-Memory (LiM) XOR cell, designed using GlobalFoundries&#8217; 28 nm technology, eliminating ADCs and ensuring robust, energy-efficient, and scalable operation. Our 2T FeFET XOR cell, applied to 4096-bit Hamming distance calculations, achieves  $23\times $  lower energy,  $3\times $  faster latency, and  $14\times $  area reduction over state-of-the-art designs. Delivering 2337 Gsamples/(s $\cdot $ W $\cdot $ mm2) &#8212; a  $300\times $  improvement &#8212; this architecture offers a compelling solution for energy-efficient, reliable, and scalable AI hardware, driving sustainable computing.</description></item><item><title>A Class-F VCO With Ultra-Low-Power and Low-Phase-Noise by Reactivating the Common-Mode Coupling Factor in a 1:2 Transformer</title><link>http://ieeexplore.ieee.org/document/11259086</link><description>In this paper, a Class-F voltage-controlled oscillator (VCO) with low-phase-noise (PN) and ultra-low-power consumption is proposed by reactivating the common-mode (CM) coupling factor in a 1:2 transformer. Unlike conventional designs that exclusively consider the differential-mode (DM) coupling factor in 1:2 transformers, our proposed architecture effectively leverages the combined potential of DM and CM coupling factors in a single transformer. For DM operation, a novel design method is presented to efficiently guide the design of ultra-low-power VCOs. This method provides clear insights into how Class-F3 resonator parameters influence the loop gain characteristics, establishing a quantitative framework for performance optimization. Regarding CM operation, the 1:2 transformer&#8217;s coupling mechanism is analyzed in detail for the first time. The analysis reveals that strategic layout optimization of the center tap can reactivate the CM coupling factor, effectively expanding the CM resonance to reduce PN. Furthermore, by incorporating a tightly coupled tertiary coil, a local oscillator signal with high spectral purity is realized. Fabricated in a 110-nm CMOS process, the proposed VCO achieves a 20.2% frequency tuning range (FTR) from 10.45 to 12.80 GHz, consuming 0.38-0.50 mW with 0.2-V power supply. The measured PN exhibits &#8722;107 and &#8722;130 dBc/Hz at 1 MHz and 10 MHz offset from a 12.80-GHz carrier, respectively, with corresponding excellent figures-of-merit (FoM) of 192 and 195 dBc/Hz, respectively.</description></item><item><title>A 32.5&#956;g/&#8730;Hz, 0.64mm2/Axis MEMS Accelerometer Using High-Voltage Pulse Excitation and Active Noise Cancelation Readout Technique</title><link>http://ieeexplore.ieee.org/document/11269916</link><description>For wearable applications, the small size low noise MEMS accelerometer with high efficiency is required. However, the sensitivity of the MEMS sensor reduces with the sensor size scaling down, leading to deterioration of the circuit noise. To meet this challenge, the interface circuit with high-voltage pulse excitation (HVPE) and active noise cancelation readout technique is proposed. The HVPE reduces the circuit noise and the wire resistance noise significantly without introducing additional electrostatic force to the sensor. The drift and mismatch problems of the HVPE are addressed by three specific correction circuits. The power efficiency of the system is optimized by the capacitance-to-voltage converter with active noise cancellation and pulse current supply. The propose HVPE technique is demonstrated in an interface IC fabricated by  $0.18\mu $  m BCD process and tested with a small size MEMS accelerometer (0.64mm2/axis). The measurement result shows that this IC has achieved a noise floor of  $32.5\mu $ g/ $\surd $  Hz with 2kHz bandwidth and  $80\mu $  W power consumption.</description></item><item><title>A Multibit ReRAM Computing-in-Memory Processor With Adaptive Decision Level Nonlinear ADC for Ultra-Low-Energy Keyword Spotting in Mobile Devices</title><link>http://ieeexplore.ieee.org/document/11149659</link><description>This paper presents an ultra-low-energy keyword spotting (KWS) processor based on the charge-mode multi-level resistive random-access memory (ReRAM) bitcell and adaptive analog-to-digital converter (ADC) quantization. Previous ReRAM computing-in-memory (CIM) architectures have suffered several challenges, including excessive computing energy due to direct current branches, computation non-linearity, and throughput degradation resulting from analog-to-digital conversion. The proposed processor addresses these challenges by introducing a charge-mode multi-bit ReRAM bitcell (CRB), which achieves a 61.39% reduction in multiply-and-accumulate (MAC) energy. The CRB also enhances MAC linearity by  $1.65\times $ . Additionally, the 5-bit additive powers-of-two ADC achieves a 65.42% reduction in analog-to-digital conversion energy, an 11.70 percentage points decrease in ADC accuracy loss, and a  $1.33\times $  increase in conversion throughput. Furthermore, the pipelined layer fusion clusters reduce intermediate data movement energy to 97.2 nJ and enhance KWS system throughput by  $1.35\times $ . The proposed processor is designed utilizing 45 nm CMOS technology and compatible ReRAM devices. The processor occupies an area of 0.94 mm2 with a 68.5 KB ReRAM cell. The processor also achieves  $0.74~\mu $ J/decision energy consumption, 22.59 TOPS/W energy efficiency, and 92.7% accuracy on the Google Speech Commands Dataset.</description></item><item><title>An FD-SOI-Based Compact In-Pixel Computing Architecture Enabling Real-Time Feature Extraction</title><link>http://ieeexplore.ieee.org/document/11159278</link><description>To empower resource-limited edge devices in artificial intelligence (AI) and Internet of Things (IoT) applications, it is essential to overcome challenges posed by restricted area resources and the high latency demands of transmitting and processing substantial sensory data. In-pixel computing addresses these challenges effectively, and the Fully Depleted Silicon-On-Insulator (FD-SOI)-based pixel, which relies on an FD-SOI transistor whose current is made photosensitive to light by applying a negative back-gate voltage, shows significant potential with its compact structure and in-situ computation capability. In this paper, for the first time, we present an FD-SOI-based chip-level architecture for in-pixel computing. Our design implements programmable, massively parallel convolution with low latency using a pulse-width modulation (PWM) input encoding scheme. Furthermore, the proposed compact 1P1T (1 Phototransistor 1 Transistor) pixel design, integrated with an improved single-slope analog-to-digital converter (SS ADC), greatly enhances area efficiency. Validated through simulation in a 22nm FD-SOI process, the design achieves 990 frames/s under typical outdoor illumination conditions, with the figure of merit (FoM) of 16.86 pJ/pixel/frame. In addition, the proposed architecture has been evaluated on hand gesture recognition (5697 training and 633 validation images across six categories), achieving an accuracy of 97.48%. The results demonstrate that, compared to state-of-the-art designs, our approach achieves a  $6\times $  improvement in in-pixel convolution speed and a  $7.3\times $  reduction in area overhead.</description></item><item><title>A 4.36 &#956;g/&#8730;Hz 197 pJ High Linearity and Low Power Consumption Interface ASIC for MEMS Accelerometer With Physical-Stimulus-Free Built-in Self-Test (BIST)</title><link>http://ieeexplore.ieee.org/document/11126429</link><description>A charge-balanced fully differential capacitive micro-electromechanical system (MEMS) accelerometer with low noise level, high energy efficiency and built-in self-test (BIST) function was developed. By applying charge-balanced architecture, the accelerometer achieves high linearity at comparatively low power. The novel C-V converter (CVC) and programmable gain amplifier (PGA) with time-multiplexed fully differential structure greatly inhibit the influence of the common-mode voltage and noise interference, enhancing the linearity and noise floor of the accelerometer. By employing time-division multiplexing, the interface application-specific integrated circuit (ASIC) proposed in this work is capable of detecting defects in both the sensing element and the interface ASIC while maintaining high precision and low noise characteristics, realizing physical-stimulus-free BIST for capacitive accelerometers. The proposed readout ASIC is fabricated in a commercial  $0.18\mu $ m CMOS process. The measurement result shows that the circuit has achieved a noise floor of  $4.36\mu $ g/  $\surd $ H z, an FoM of 197pJ, and a DC non-linearity of 0.06% within &#177;1g.</description></item><item><title>A 99.9% Efficient, Ultra-Low Power Automated On/Off Adaptive MPPT Circuit for RF, PV, and TEG Sources From 1 &#956;W to 4 mW</title><link>http://ieeexplore.ieee.org/document/11152395</link><description>This paper presents a high-efficiency, ultra-low-power automated on/off adaptive MPPT (AOA-MPPT) system for microscale energy harvesters. It is designed to extract the maximum available power from photovoltaic (PV), radio frequency (RF), and thermoelectric generator (TEG) energy sources. AOA-MPPT combines a power-change detector (PCD) that activates tracking only when input power changes (auto-on) with an auto-off convergence detector that halts perturbation at lock and powers down MPPT circuitry, eliminating steady-state dither and lowering controller power. Input power is estimated from a single sample of the inductor peak current, enabling duty-cycled sensing with low sensitivity to converter gain. A low-power, wide-range PWM control (LS-PWM) provides broad duty-cycle adjustment of the inductor charge time, enabling input impedance matching for maximum power transfer. The AOA-MPPT circuit is designed along with a boost converter and fabricated in 65nm CMOS technology. It achieves a peak tracking efficiency of 99.9%, a peak converter efficiency of 87%, and a power consumption of only 112nW.</description></item><item><title>High-Speed Optical Binary Neural Network Accelerator Enabled by Nonvolatile MEMS Phase Shifters for Edge AI Applications</title><link>http://ieeexplore.ieee.org/document/11130384</link><description>This paper presents a novel approach for implementing Binary Neural Networks (BNNs) utilizing nonvolatile optical phase shifters. These phase shifters employ a micro-electromechanical system (MEMS) tuning mechanism, which enables the adjustment of the refractive index and phase of the propagating mode. In this approach, the weights of the BNN can be controlled by applying electrical signals to the phase shifters. Moreover, due to the nonvolatile operation of these devices, the network&#8217;s weights remain stable even when the electrical power source is cut off. The phases of the propagating modes, manipulated by the proposed phase shifters, determine the logic of the photonic circuit. The in-memory design of this device eliminates the need for network register banks, thereby significantly reducing resource usage, footprint, and power consumption. This approach offers much faster operation than other technologies, such as CMOS or spintronics, making it particularly appealing for edge artificial intelligence applications.</description></item><item><title>An Interference-Resilient 120&#176;-Apart Pseudo-I/Q BLE-Compatible Wake-Up Receiver Achieving &#8722;21 dB SIR, &#8722;94 dBm Sensitivity, and 4-D Wake-Up Signature</title><link>http://ieeexplore.ieee.org/document/11165427</link><description>Wake-up receivers (WuRXs) help to cut down the average power consumed by the wireless devices in the Internet of things (IoT). Compared to the non-standard designs, the standard (e.g. BLE-compliant) WuRX chips can be integrated seamlessly into the widely-deployed infrastructures, while there are more design challenges since the BLE-compliant WuRX should be resilient to adjacent-channel interferes as well as realize a high sensitivity. In traditional BLE-compliant WuRXs, the interferes were suppressed by an FBAR filter or a low-noise local oscillator (LO) generator, with the penalty of sensitivity degradation or additional power consumption. The existing edge-combine LO generating method can cut down the power consumption, while the increased LO noise significantly degraded the signal-to-interference ratio (SIR) performance. In this work, we have demonstrated a BLE-compliant WuRX chip that improves both the SIR and sensitivity with low power dissipation. Instead of the conventional I/Q path with 90 degrees out of the phase, a pseudo-I/Q dual-downconversion structure is proposed to offer a WuRX driven by 120-degree-apart ultra-low-power LOs signals, which helps to improve the SIR performance due to the lower LO noise than the conventional edge-combine methods. In addition, a dummy down-converter based mismatch-cancellation technique is proposed to improve the image rejection ratio (IRR) and sensitivity. Fabricated by a 65nm CMOS process, the proposed BLE-compliant WuRX chip achieves -21dB SIR in the adjacent channel as well as -94dBm sensitivity at the cost of only  $306\mu $ W power.</description></item><item><title>Analysis and Design of an 884-MHz Duty-Cycled Ambient RF Energy Harvester IC Capturing 8.7 &#956;J From &#8211;35.2 dBm per 1.6 Hours</title><link>http://ieeexplore.ieee.org/document/11151652</link><description>This paper presents an analysis and design of a duty-cycled ambient RF energy harvester (RFEH) IC effectively harvesting a relatively large amount of energy from a small input RF power. We have newly developed the system model of the duty-cycled ambient RFEH by considering the rectifier current, the power management unit (PMU) current, the capacitor current and the load current. Based on this system model, we have defined the capacitor charging power and analyzed the power conversion efficiency (PCE). From the analysis results, we could find the optimum input RF power maximizing the PCE at a given output DC voltage. By considering this optimum input RF power as well as the PCE, the passive amplification gain and the charging time simultaneously, we have optimized the design parameters of the RF-DC rectifier. For circuit implementation, we have placed the input coupling metal-oxide-metal (MOM) capacitors of the RF-DC rectifier above the P-diffusion area with relatively low parasitic resistance, minimized the power consumption of the PMU and considered the capacitor leakage current to enhance the PCE. The duty-cycled ambient RFEH IC has been implemented in a 28nm 1P11M CMOS process and the active die area is 0.047mm2. It has demonstrated the ability to harvest  $8.7{\mu }$ J at  $100{\mu }$ F per 1.6 hours from &#8211;35.2dBm input RF power at 884MHz. The measured input power sensitivity is &#8211;40.8dBm for the output DC voltage of 0.87V when the storage capacitance is  $0.47{\mu }$ F and the PMU is operating.</description></item><item><title>A Low-Power 8&#215;8 SiPM Readout ASIC With Row-Column Summing Structure for Compact TOF-PET Detectors</title><link>http://ieeexplore.ieee.org/document/11197601</link><description>A new low-power 64-channel Front-End application-specific integrated circuit (ASIC) for the readout of  $8\times 8$  Silicon photomultiplier (SiPM) Arrays (FESA) with a row-column summing structure is proposed for flexibly building a compact and cost-effective time-of-flight (TOF) positron emission tomography (PET) system. The inputs from the SiPM array are picked up individually and row-column summed to reduce the number of measurement circuits and overall power consumption. An energy-to-time conversion circuit based on the delayed linear discharge method is proposed with high linearity and enhanced small-signal measurement ability, which allows FESA to use a fully time-based readout strategy so that a simple and robust interface for system-level integration is provided. Fabricated in 180 nm CMOS technology, FESA has been evaluated with an intrinsic timing jitter of 11.8 ps, a dynamic energy measurement range of 44 dB, a power consumption of 2.39 mW per channel, and an event rate of 4 MS/s. With an  $8\times 8$  Hamamatsu S13361-3050 SiPM array 1:1 coupled to an  $8\times 8$  lutetium yttrium oxyorthosilicate (LYSO) crystal array, the FESA-based detector exhibits a coincidence time resolution (CTR) of 237 ps FWHM and an energy resolution of 12.6%. The measured flood image with an  $8\times 8$  SiPM array 1:9 coupled to a  $24\times 24$  LYSO crystal array demonstrates the ability of FESA to decode a crystal size of 1 mm. The test results show that FESA is a promising candidate for the future construction of high-performance and high-integration TOF-PET systems.</description></item><item><title>A Class-C CMOS Rectifier With Active Modulation Achieving &gt;76% Peak Efficiency and Extended Input Power Range Over 8.8 dB Across Multiple Frequency Bands</title><link>http://ieeexplore.ieee.org/document/11133675</link><description>This paper presents a class-C cross-coupled differential CMOS rectifier with an active modulation technique enabled by dual-path feedback loops. The proposed design effectively mitigates reverse leakage current losses at high input power levels, thereby enhancing power conversion efficiency (PCE) and extending the input power range (IPR). Unlike conventional designs that employ resistive or diode-based feedback control circuits in the DC path, leading to degraded PCE at high RF power levels and additional power consumption in the feedback loop, the proposed scheme incorporates a fully active modulation mechanism that improves PCE across a wide frequency range. Fabricated in a standard 180 nm CMOS process, the rectifier occupies a compact active area of 0.009 mm $\mathbf {^{2}}$ . Measured at a 100 k $\boldsymbol {\Omega }$  load, the design achieves a peak PCE greater than 76%, an IPR (PCE &gt;60%) spanning over 8.8 dB, and a sensitivity better than -18 dBm for generating a 1 V output consistently at 433 MHz, 920 MHz, and 2.4 GHz operating frequencies.</description></item><item><title>Characterizing the Intrinsic Bank-Level Accuracy Versus Energy Trade-Off of SRAM-Based Analog In-Memory Computing Architectures in 28 nm CMOS</title><link>http://ieeexplore.ieee.org/document/11219413</link><description>In-memory computing (IMC) architectures are emerging as the next-generation computing platforms for deep learning applications, surpassing traditional von Neumann architectures due to their superior energy efficiency and computational density. However, there is a lack of comprehensive understanding of the trade-off between accuracy at the bank level and energy consumption of SRAM-based IMCs, which execute computations in the analog domain. To gain a complete understanding of IMC&#8217;s fundamental limits and design space, we first adopt the signal-to-noise-and-distortion ratio (SNDR) as a metric, inspired by ADC design, to quantify the accuracy at the bank level. Second, we propose a methodology for accurately measuring SNDR. Finally, we propose a chip architecture for to directly measure pre-ADC SNDR. This characterization chip, incorporating mainstream IMC architectures, is fabricated in 28 nm CMOS technology. Measurement results indicate that SNDR and energy consumption are trade-offs that can be adjusted through the dot-product dimension and wordline voltage for charge/current summing models, and through input-driver voltage for a charge-redistribution model. To the best of our knowledge, this is the first experimental quantification of the trade-off between bank-level accuracy and energy consumption for SRAM-based IMC architectures through silicon measurements. These results underscore the importance of characterizing IMC SNDR to properly benchmark and compare future IMC designs.</description></item><item><title>A Complementary 3T-Based eDRAM Macro for High-Density Dual-Direction CAM and Logic-in-Memory</title><link>http://ieeexplore.ieee.org/document/11165429</link><description>Content-addressable memory (CAM) is regarded as an attractive solution for data-intensive applications with high-density search demands. To further improve functional flexibility yet at a low cost, several CAM macros have been developed to support multiple bit-wise logic operations. However, conventional SRAM-based CAM designs are constrained by the large bitcell area, posing significant challenges to achieve higher density. To address this issue, we propose a complementary 3T (C3T) based embedded dynamic random access memory (eDRAM) macro for high-density dual-direction CAM searching and logic-in-memory operations. First, we propose a compact C3T bitcell featuring a pair of complementary decoupled read ports, enabling dual-port read and efficient CAM operations. Second, we present a compact dynamic-circuit-based sense amplifier (DSA) to optimize the area of readout peripheral circuitry while mitigating the read bit line saturation issue. Additionally, we implement dual-direction CAM searching and logic-in-memory operations exploiting the C3T-based eDRAM macro. A 4 Kb C3T-based eDRAM macro has been validated in a commercial 40-nm CMOS process. Post-layout results demonstrate a 53% reduction in the bitcell area and a 58.1% reduction in the macro area compared to the state-of-the-art 6T compute SRAM. Moreover, the proposed design achieves a maximum frequency of 578 MHz for binary CAM (BCAM) searching operations and 694 MHz for logic operations, with energy consumption of 1.12 fJ/bit and 26.8 fJ/bit, respectively.</description></item><item><title>A High-Energy-Efficiency Lightweight BNN Accelerator for Arrhythmia Detection</title><link>http://ieeexplore.ieee.org/document/11224382</link><description>Arrhythmia poses a significant threat to human health. Accurate and real-time arrhythmia detection using electrocardiogram (ECG) signals is critical for medical diagnosis. With the rapid development of deep learning technologies, Deep Neural Networks (DNNs) have considerably improved the accuracy of arrhythmia monitoring. However, deploying these techniques on power-constrained wearable devices for real-time monitoring remains challenging. Lightweight designs have thus become essential for achieving low-power and high-throughput real-time detection with limited hardware resources. Binary Neural Networks (BNNs), as a promising lightweight method, exhibit significant potential in reducing hardware resource usage and enhancing inference speed. Nevertheless, existing binarized ECG detection accelerator designs have not yet conducted architectural Design Space Exploration (DSE), and therefore do not sufficiently balance the trade-off between throughput and power consumption. To address this, we propose a highly energy-efficient one-dimensional BNN accelerator for ECG detection. First, we develop a hardware-friendly BNN algorithm by eliminating fully connected layers and nonlinear computations. Subsequently, for the first time, this work utilizes Timeloop to analyze the optimal mapping of the BNN algorithm onto hardware, identifies the optimal accelerator dataflow, and conducts in-depth optimization of both the dataflow and the accelerator hardware circuits based on the Field-Programmable Gate Array (FPGA) architecture. Finally, we introduce a prediction mechanism for fine-grained power control by dynamically disabling redundant computational logic. Experimental results demonstrate that the proposed accelerator achieves a latency of 105.79&#8198; $\mu $ s, power consumption of 160 mW, throughput of 112.2 GOPS, and energy efficiency of 701.51 GOPS/W at 100 MHz. Compared with state-of-the-art Xilinx FPGA-based ECG detection accelerators, our design improves energy efficiency by  $15.56\sim 3220.89$  times.</description></item><item><title>LSTM Hardware Inference Accelerator for LiteRT</title><link>http://ieeexplore.ieee.org/document/11172322</link><description>The efficient deployment of Recurrent Neural Networks (RNNs), particularly long short-term memory (LSTM) architectures, on edge devices has become increasingly important due to their ability to model nonlinear time-variant dynamics. However, the computational demands of LSTM inference often exceed the capabilities of resource-constrained microcontroller-based IoT devices. Efficient mapping of computational load onto hardware and software resources is a key challenge for improving performance while maintaining low power and a small area footprint. This paper presents a hardware-software framework that accelerates LSTM inference on edge devices by combining a modified LiteRT (formerly TensorFlow Lite) model running on a microcontroller (MCU) with a dedicated LSTM engine in a Neural Processing Unit (NPU) accelerator. To evaluate trade-offs between accuracy, latency, and energy efficiency, we introduce an LSTM benchmark suite for ultra-low-power tiny ML systems. Using this framework, experiments on various LiteRT-based LSTM architectures demonstrate up to 300x speedup compared to software-only implementations. For instance, the runtime for the HAR classification task is reduced from 1.8 seconds to just 6 milliseconds.</description></item><item><title>U-Sparta: A Unified Speech Processing Accelerator for Real-Time Applications</title><link>http://ieeexplore.ieee.org/document/11230607</link><description>With the advancements in deep learning for speech processing and the rising popularity of smart devices, the demand for edge devices to support multiple speech processing applications is steadily increasing. However, existing unified AI platforms are unsuitable for such edge scenarios, while dedicated accelerators lack flexibility for diverse speech tasks, and current multi-task solutions remain limited in operator support and task coverage. In this work, we propose U-Sparta, a Unified Speech Processing Accelerator for Real-Time Applications. First, a decomposition scheme, comprising three dedicated strategies, is proposed to efficiently support various neural network operators for speech processing. Additionally, an efficient hardware-implemented approach for precise layer-wise fixed-point quantization is introduced, and a range of compression techniques are employed; then we propose hardware-aware expansion to effectively compensate for performance degradation caused by compression. These approaches collectively reduce the model size by an average of 93.1% and computational complexity by 89.9%. The design has been implemented on a Pango PGL50H FPGA, achieving worst case 1.65W and 1.39W on average low power consumption at 50MHz, lower resource utilization compared to single-task related works. It has been further implemented in 55-nm CMOS technology, with a core area of 3.61 mm2, achieving an average power consumption of 22.6 mW and high accuracy across multiple speech processing applications, including voice activity detection (VAD), keyword spotting (KWS), speaker verification (SV), environmental sound classification (ESC), speech enhancement (SE), speech separation (SS), and speech recognition (SR).</description></item><item><title>TRIM: Acceleration of Multiplication-Less Neural Networks via Versatile Sparsities</title><link>http://ieeexplore.ieee.org/document/11153541</link><description>Recently, multiplication-less neural networks (L1NNs), replacing multiplication-intensive dot products with addition-only  $\ell _{1}$ -distance kernels have emerged to enhance energy efficiency and speed with negligible degradation of accuracy. Despite these gains, such models suffer from pruning challenges that can negate their benefits. In this work, we identify the root cause of these challenges and introduce a novel method called synapse pruning, which is explicitly designed for L1NNs to overcome them for the first time. Building upon this algorithmic innovation, we present TRIM, an algorithm-hardware co-design framework that sparsifies and accelerates L1NNs to achieve ultra-high energy efficiency and speed. On the algorithmic side, we propose structured synapse pruning tailored for hardware-friendly  $\mathbb {N:M}$  sparsity patterns for L1NNs. On the hardware side, we introduce a sparse processor architecture that efficiently exploits both the proposed  $\mathbb {N:M}$  structured synapse sparsity and the intrinsic unstructured weight and activation sparsities in L1NNs by skipping redundant operations. Additionally, an  $\mathbb {N:M}$  sparsity-aware elastic mapping technique is introduced to maximize hardware utilization and data reuse. Evaluations on seven benchmarks demonstrate that TRIM achieves up to 87.5% unstructured sparsity and up to 81.3% structured sparsity with less than 1% accuracy loss. Implemented in a 65 nm technology, our processor achieves 5.22 TOPS/W and 1.17 TOPS/mm2, surpassing the existing SOTA L1NN accelerator by  $1.7\times $  in energy efficiency and  $14.9\times $  in area efficiency. The source code is available at: https://github.com/XZH28/TRIM-Sparse-L1-Distance-Net.git</description></item><item><title>A 1.1 &#956;J/Inference Binary Spiking Neural Network Accelerator for DVS Gesture Recognition</title><link>http://ieeexplore.ieee.org/document/11128877</link><description>Dynamic vision sensors (DVS) are bioinspired sensors that can generate sparse data streams with low latency, low power consumption and high dynamic range. Spiking neural networks (SNNs), which are inspired by biological brains, are event-based models, and therefore they can be used to process the binary data streams produced by such sensors naturally. However, SNN accelerators usually require more memory and longer time for inference, due to the extra time dimension in SNNs. In this paper, an energy efficient binary spiking neural network (BSNN) accelerator for DVS gesture recognition is proposed with algorithm and hardware codesign. We integrate the binary neural network (BNN) training method into SNN to directly train a BSNN model, which significantly reduces memory consumption. A temporal pooling (TP) layer is further proposed to reduce the time steps in SNNs while maintaining competitive accuracy. The proposed BSNN accelerator can achieve high parallelism with high resource utilization, and the sparsity of input spikes is utilized to further reduce power consumption. The proposed BSNN model achieves an accuracy of 95.49% on IBM DVS Gesture dataset. The implementation results show that the BSNN accelerator can achieve 38.2k inference per second with  $1.1~\mu $ J/inference energy consumption and 216.9 TOPS/W energy efficiency.</description></item><item><title>Efficient and Flexible Deep Learning Processor for Embedded Devices With 99.8% PE Utilization Under Low Silicon Cost</title><link>http://ieeexplore.ieee.org/document/11143600</link><description>The flexibility and efficiency of accelerator hinder the realization of DNN (Deep Neural Network) on embedded devices. How to design efficient and flexible deep learning processors to meet low-power requirements while supporting various iteratively updated deep neural networks, which is a major challenge in the current field. Moreover, the significant power consumption and latency generated by data access between on-chip and off-chip memory have been the bottleneck of DNN accelerator development. We hence design the flexible and efficient deep learning processor (DLP) based on our designed specific neural network instruction set for DNN inference, which can be used to flexibly accelerate the inference of iteratively updated neural networks. Our design includes the design of hardware architecture, neural network acceleration instruction set, efficient SIMD control path and data path, which can be used to accelerate the execution of the DNN programs, and support hiding the data transfer time between on-chip and off-chip memory. In addition, we propose a parallel and conflict-free data access scheme to reduce data access overhead in memory system. Moreover, we also propose a scheduling framework to improve performance and minimize power consumption under the hardware resource constraints. The experimental results indicate that our design&#8217;s power consumption efficiency is 75.3 TOPS/W at TSMC 65 nm process. Our power efficiency is 7.6, 5.5 and 4 times higher than the state-of-art DNN accelerators respectively.</description></item><item><title>WireLightning: Harnessing Capacitances for In-Transit Massively Parallel Matrix Multiplication</title><link>http://ieeexplore.ieee.org/document/11150498</link><description>Analog computing-in-memory accelerators promise ultra-low-power, on-device AI by reducing data transfer and energy usage. Yet inherent device variations and high energy consumption for analog-digital conversion continue to hinder their wide-scale adoption in mainstream systems. To address these issues, this paper introduces WireLightning, a novel capacitive-computing accelerator featuring a mixed-signal architecture that rethinks analog AI acceleration. Unlike conventional analog crossbars that encode weights in programmable devices, WireLightning exploits intrinsic charge dynamics in passive capacitors, encoding matrix multiplication through spike amplitude and timing. This design addresses critical limitations such as weight drift, stochasticity, and power-intensive ADC bottlenecks. Key innovations include: amplitude-temporal dual encoding that enables constant-time analog dot-products; time-based decoding scheme that significantly reduces reliance on power-intensive ADCs; row-wise parallel architecture for concurrent dot-product calculations across multiple rows to enhance throughput; and value repetition exploitation in low-bit quantized vectors to reduce multiplications to constant time complexity. A PCB pro totype achieved a range-normalized RMSE of 1.80%&#8212;69.2% of the error in RRAM crossbar implementations&#8212;and a normalized error of 9.18%, corresponding to 77.1% of that in leading PCM crossbars. Implemented in a 40-nm CMOS technology, WireLightning macro delivers 465.47 TOPS/W at 4-bit precision, outperforming state-of-the-art analog accelerators while maintaining 0.23% range-normalized RMSE. By integrating algorithm-circuit co-design with physical computing, this work establishes capacitive computing as a promising path toward combining digital precision and analog efficiency in next-generation edge AI.</description></item><item><title>iFCN: An Automated RTL-to-Device Framework for Molecular Field-Coupled Nanocomputing Circuits</title><link>http://ieeexplore.ieee.org/document/11130445</link><description>Molecular Field-Coupled Nanocomputing (MolFCN) offers a promising post-CMOS alternative, characterized by ultra-low power consumption and high integration density. However, existing MolFCN design flows face critical challenges, including rigid clock-phase constraints, inefficient placement and routing, and the absence of accurate gate-to-device mapping. This paper introduces iFCN, an automated RTL-to-device-level design framework specifically optimized for MolFCN circuits. Building upon prior heuristic methods, iFCN incorporates inverter pruning at the RTL level to simplify circuit structure, utilizes Morton-coded linear quadtrees for efficient spatial indexing, and enhances A* routing to maximize path reuse for multi-fanout nets. To address limitations of fixed-phase clocking, we propose a hierarchical placement approach guided by Graph Convolutional Networks (GCN). The GCN learns connectivity-aware node embeddings that guide recursive partitioning and intra-layer ordering, significantly reducing wire crossings and improving placement quality. Subsequently, a lightweight adaptive method heuristically assigns clock phases to each layout layer, with careful consideration of timing and topological constraints. Additionally, we present an accurate gate-to-cell mapping algorithm to facilitate direct physical simulation and energy analyses. Benchmark results show a 30% reduction in runtime and a 10% improvement in layout area compared to our heuristic algorithm. Furthermore, the proposed method achieves comparable runtime performance to the state-of-the-art fiction tool, completing the layout of circuits with over 150 nodes in under one second. In addition, Comparative analyses against 12nm CMOS designs confirm that MolFCN circuits generated by iFCN exhibit superior area utilization and reduced power consumption, highlighting the practical potential of MolFCN for future ultra-low-power computing. All source code and data are available at https://github.com/li-yangshuai/iFCN</description></item><item><title>HA-BFNN-ICP a Streaming FPGA Architecture for Energy Efficient Real-Time 3D LiDAR Mapping</title><link>http://ieeexplore.ieee.org/document/11165417</link><description>Three-dimensional Light Detection and Ranging (3D LiDAR) sensors are widely used in autonomous vehicles including localization, sensing, and mapping. However, their significant computational requirements remains a major limitation. Although high-end Graphics Processing Units (GPUs) and Central Processing Units (CPUs) can solve the aforementioned problem, the cost and power consumption hinder the widespread adoption of 3-D LiDAR in commercial vehicles. To overcome these limitations, this paper presents a novel high-efficiency 3D mapping method that aims to achieve faster computation speeds than CPUs while providing better energy efficiency compared to GPUs. First, an optimized real-time LiDAR data preprocessing procedure is proposed, which is based on a fixed-point computation framework. Second, to accelerate the LiDAR point cloud matching process, we introduce a new processing architecture called Hardware Accelerated Brute Force Nearest Neighbor (HA-BFNN). Third, we further enhance real-time performance and energy efficiency by proposing a streaming FPGA accelerator architecture for both HA-BFNN and the Iterative Closest Point (ICP) algorithm. Experimental results show that our custom test board, based on the AMD Kintex-7 chip, accelerates point cloud matching, completing single-frame calculations in 5.76 ms, significantly outperforming other 3D mapping implementations on both CPUs and GPUs. Moreover, our FPGA implementation achieves up to  $17.36\times $  speedup in execution time compared to CPU implementations. Finally, the proposed system enables real-time performance while consuming only 3.4W of power, maintaining accuracy comparable to software counterparts and even state-of-the-art 3D mapping methods.</description></item><item><title>TEA-SPS: A Tiny and Efficient Architecture for Softmax With Parallelism and Sparsity Adaptability</title><link>http://ieeexplore.ieee.org/document/11184336</link><description>With the remarkable performance of Transformer-based networks in multiple fields and increasing demand for computational resources by softmax within them, it is inevitable for hardware accelerators to support softmax in Transformer. However, due to the lack of co-design of algorithm and hardware, there still remains space for optimizing the hardware architecture for softmax. Therefore, TEA-SPS is proposed as an algorithm and hardware co-designed architecture to improve softmax with two methods: Configurable Parallelism softmax with Sparse mask Strategy (CPSS) and Specific Piecewise Information Extractor (SPIE). CPSS has the advantage of supporting different throughput requirements through configurable data-level parallelism and performing sparse masking on the outputs to reduce the computational load and memory access of subsequent operations. To further explore the optimal solution set among the design space of parameters in CPSS, SPIE is proposed to achieve co-optimization of accuracy and hardware overhead. Based on them, the efficient hardware architecture of TEA-SPS is proposed. The implementation results show that at the frequency of 0.5 GHz under TSMC 90-nm technology, the peak efficiency of TEA-SPS processing 8-bit quantized data can reach up to 216.97 Gps/(mm $\boldsymbol {^{2}\cdot }$  mW), with the area of  $3290.21~\boldsymbol {\mu }$  m $\boldsymbol {^{2}}$  and the power consumption of 0.7004 mW. In addition, TEA-SPS provides support for input sequences of arbitrary length with negligible accuracy loss compared to the quantized baseline, while achieving an average sparse rate of 68.6% on the GLUE tasks.</description></item><item><title>A 5.3-W 83.7% Peak Efficiency Simultaneous Wireless Power and Data Transfer IC Enabling 10&#8211;9 BER 540-kb/s Data Rate or Output Voltage Regulation</title><link>http://ieeexplore.ieee.org/document/11121158</link><description>This paper proposes the first simultaneous wireless power and data transfer (SWPDT) integrated circuit (IC) which exploits a Capacitive-Inductive Channel (CI-Channel), enabling concurrent power and data transmission. The communication across the CI-Channel can support data-only transmission or can be incorporated into the system control loop, allowing output voltage regulation through phase-shift control applied at the primary side. The proposed IC can be configured as primary side (power transmitter, P-TX, and data receiver, RX) or secondary side (power receiver, P-RX, and data transmitter, TX). In order to ensure communication robustness, unwanted disturbances are removed through specifically designed Power Blanking and Ringing Blanking circuits. The proposed SWPDT IC test-chip prototype was fabricated using a 130-nm BCD process and experimentally verified considering the complete wireless power transfer (WPT) system, including primary side, CI-Channel and secondary side. The overall system, targeting medium-power industrial applications, achieves a maximum 5.3-W output power, a peak efficiency of 83.7% and a load regulation of 0.09 mV/mA. Moreover, a 540 kb/s data rate with no transmission errors across  $10^{9}$  bit acquisitions, corresponding to a bit-error-rate (BER)  $\lt 10^{-9}$ , was achieved.</description></item><item><title>Characteristic Exploiting-Based Delay-Dependent Stability Analysis of Grid Systems With Wind Power and Electric Vehicles</title><link>http://ieeexplore.ieee.org/document/11159117</link><description>Integrating wind power and electric vehicles into the load frequency control of grid systems is promising for modern power grid operations. For such energy systems, it is crucial to establish stability criteria with less conservatism, and equally important is to ensure computational tractability. This paper attempts to achieve this purpose from the perspective of characteristic exploiting in an exploratory manner. First, we exploit the sparse characteristic of the system matrices by separating state variables into delay-dependent and delay-independent categories, thus the reconstructed model is obtained. While maintaining equivalence to the original system, it improves the computational efficiency through reducing the dimension by more than 30%. Then, to address challenging higher-order time-varying delay terms and system matrix-Lyapunov matrix products, the variable-augmented free-weighting matrix method is applied. By exploiting such matrix characteristics, we justify the introduction of these matrices and derive the less conservative stability criteria. Finally, case studies show that, compared with existing results, the proposed method has increased the calculation accuracy measured by the average improvement rate of allowable maximum delay upper bound by at least 16.02%, and the calculation efficiency measured by the average calculation time has increased by more than 71.1%.</description></item><item><title>Data-Driven Fault-Tolerant Control Framework for EV Dynamic Wireless Power Transfer System Based on Self-Learning Predictor</title><link>http://ieeexplore.ieee.org/document/11128874</link><description>This paper aims to develop a constant output voltage controller for dynamic wireless power transfer systems(DWPTSs) incorporating sensor noise filtering and fault tolerance. DWPTSs are designed to alleviate range anxiety in electric vehicles(EVs); however, the output voltage fluctuations are their significant drawback compared to static charging mode. Additionally, DWPTSs also face sensor measurement noise and potential faults that exacerbate system instability. To mitigate above challenges, a data-driven fault-tolerant control framework is designed for DWPTS based on a self-learning predictor, which implements constant voltage regulation with enhanced noise and fault immunity. Specifically, a self-learning predictor is integrated into the feedforward loop of a high-gain extended state observer (ESO) to filter sensor noise. Then, a data memory stack is constructed to store predicted states and estimated disturbances, and a concurrent learning algorithm is introduced to recover control gains online. Finally, a composite anti-disturbance control law is implemented to generate the required control signals for the charging circuit. A notable advantage of this scheme is its ability to simultaneously address both sensor noise and faults, ensuring a constant output voltage during EV driving. Experimental results validate that the designed control framework effectively eliminates output voltage fluctuations and measurement noise, even in the presence of sensor faults.</description></item><item><title>A Markov Tree Model for Cascading Failure Risk Assessment in Power Grid With Uncertain Renewable Energy Generation</title><link>http://ieeexplore.ieee.org/document/11150496</link><description>The increasing penetration of renewable energy generation (REG) introduces significant uncertainty into power grids, posing heightened risks for cascading failures. In this paper, a Markov tree model is proposed to assess the risk of cascading failure in power grid with uncertain REG. The model captures the diverse failure paths caused by REG uncertainty, representing the cascading failure process as a sequence of state transitions with probabilities reflecting the likelihood of state transitions. To identify critical tripping branches during cascading failure propagation, a hybrid probability-interval method is introduced. Probabilistic power flow analysis identifies branches with overload risk, while interval positional relationships rank their severity. To improve the efficiency of risk assessment, a risk-based depth-first search (R-DFS) method is proposed. This method uses estimated risk indices to prioritize high-risk failure paths while pruning low-risk paths, significantly reducing simulation time while maintaining assessment accuracy. Compared with existing models, the proposed model balances simulation efficiency and accuracy, effectively identifying high-risk failure paths under REG uncertainty. Simulation results demonstrate the impact of threshold selection on the retention of high-risk paths and simulation performance, providing insights into managing cascading failure risks in power grid with high REG penetration.</description></item><item><title>Steady-State and Small-Signal Analysis of High-Ratio Hybrid Buck Converters With Enhancement to State-Space-Averaging Methodology</title><link>http://ieeexplore.ieee.org/document/11136126</link><description>This paper proposes convergence enhancement to state-space averaging (SSA) methodology for steady-state and small-signal analysis of high-ratio hybrid DC-DC converters, first using analysis of Double-Step-Down (DSD) topology, including parasitics, as an example, then extending to other hybrid topologies with different numbers of capacitors and inductors. The enhanced SSA method can be used to: 1) derive small-signal control-to-output transfer functions, which is essential to optimize the compensator for fast and stable closed-loop operation; 2) calculate steady-state inductor currents, output voltage, input current and the voltage(s) across the flying capacitor(s),  $V_{CFs}$ , which is important to determine steady-state characteristics and performance; 3) include circuit non-idealities such as parasitics and timing mismatches; and 4) evaluate  $V_{CF}$  balancing property by the proposed matrix invertibility principle and added constants, and determine whether dedicated  $V_{CF}$  balancing circuits can be eliminated, which is considered an important benefit with reduced complexity and improved reliability. The theoretical results of DSD are then plotted in MATLAB and verified in simulations using PSIM and Cadence periodic transfer function (PXF) analysis, and measurement results using GaN devices. The simulation and measurement results match well with theoretical analysis. The enhancement is then extended beyond the DSD topology to analyze emerging hybrid topologies with more switched inductors and capacitors, future-proofing its capability to be applicable to new hybrid topologies.</description></item><item><title>Impact of Bifurcations on the Performance of Power Electronic Circuits</title><link>http://ieeexplore.ieee.org/document/11125513</link><description>This paper investigates the impact of bifurcations on the performance of power electronic circuits. We focus on circuits that include energy-harvesting devices, which exhibit a maximum power point (MPP). In particular, a DC&#8211;DC converter with a photovoltaic (PV) module is considered a representative example of such systems to evaluate the relationship between the circuit performance indices (such as power conversion and maximum power point tracking (MPPT) efficiency) and the bifurcation phenomena observed in the system. First, experimental results are reported that evaluate circuit characteristics and performance under MPPT control. Then, a novel mathematical PV model is presented and fully defined using experimentally measured parameters; this model does not necessitate the use of root-finding algorithms. Next, this model is integrated with the switched nonlinear model of a DC&#8211;DC converter subject to peak current mode control (PCMC), and a stability analysis of the periodic orbits is performed. Finally, the relationship between circuit performance and observed bifurcation phenomena is investigated and discussed. This research demonstrates the occurrence of both period-doubling and Neimark&#8211;Sacker bifurcations in the system considered here, and these features are shown in a two-parameter bifurcation diagram.</description></item><item><title>A 1.5-GS/s 7-bit Charge-Injection SAR ADC Using a PVT-Tracking 1-bit Metastability Detector</title><link>http://ieeexplore.ieee.org/document/11269846</link><description>This brief presents a 7-bit 1.5GS/s area-efficient asynchronous Charge Injection Successive Approximation Register (CI-SAR) analog-to-digital converter (ADC). The proposed ADC architecture consists of a 6-bit CI-SAR and a 1-bit Metastability Detector (MD), forming a 7-bit ADC. Superior area efficiency is achieved by architecting the CI-DAC in a segmented structure. The Charge Injection Cell (CIC) is biased by a temperature-aware bias generator that maintains the ADC full-scale over a wide temperature range. The gm-boosted strongARM comparator helps achieve high sampling speed up to 1.5GS/s. A background-calibrated metastability-detector extracts an additional bit under different process, voltage, and temperature (PVT) conditions. The proposed ADC is fabricated in 28nm CMOS process in an area of  $202\mu $ m2. The peak SNDR is 39.04dB with FoM ${}_{\mathrm {w}} =17.4$ fJ/conv.-step. The measured SNDR drops by less than 2.7dB across the &#8722;40&#176;C to 80&#176;C temperature variation and 0.9V to 1.1V supply voltage variation.</description></item><item><title>An 8-bit Precision 10T SRAM Compute-in-Memory Macro Using ADC With Small Area</title><link>http://ieeexplore.ieee.org/document/11275808</link><description>This brief proposes a charge-domain analog Compute-In-Memory (CIM) architecture based on multi-bit SRAM. The proposed structure consists of a  $64\times 64~10$ T1C SRAM array, which can perform 1024 MAC operations between 4-bit signed input and weight within a single clock cycle. An 8-bit Analog-to-Digital Converter (ADC) is employed for quantization, converting the analog Multiply-Accumulate (MAC) results into 8-bit digital signals for output. The ADC module adopts capacitor array multiplexing, pseudo-differential sampling with double-terminal flipping method and matching layout designing to save area. The proposed circuit is implemented in 28nm process which operates at a supply voltage of 0.8V. It achieves an energy efficiency of 184 TOPS/W and an area efficiency of 7.3 TOPS/mm2, and reaches an accuracy of 86.9% in the training on CIFAR-10 dataset. When compared with other works, the highlight of this work is the highest energy efficiency and the highest area efficiency on 4-bit input and weight precision normalized to 28nm.</description></item><item><title>Efficient Time-Skew Calibration for Time-Interleaved ADC via Matrix Binary Decomposition and Increment-Based Adaption</title><link>http://ieeexplore.ieee.org/document/11284889</link><description>A fully digital background time-skew calibration technique for time-interleaved analog-to-digital converters (TI-ADCs) is presented in this brief. Interleaving errors due to time-skew are modeled as additive error terms through first-order Taylor expansion and are corrected by finite impulse response (FIR) differentiators. Computational complexity is substantially reduced by leveraging matrix binary decomposition technique. Furthermore, the increment-based adaption technique is employed to accelerate the convergence of coefficients estimation while maintaining low steady-state error. Both theoretical analysis and experimental results demonstrate that the proposed approach offers lower computational complexity and faster convergence compared to conventional methods. The proposed method is applied to an 11-bit, 3.5 GS/s, 8-channel time-interleaved SAR ADC fabricated in 28-nm CMOS. Measurement results show that the proposed calibration method improves the SFDR by 16.66 dB and the SNDR by 10.45 dB at low frequency, and by 20.6 dB and 17.4 dB at the Nyquist frequency, respectively.</description></item><item><title>A Reconfigurable Voltage&#8211;Time Hybrid ADC With Quantization Threshold Shifting and Common-Mode Tracking</title><link>http://ieeexplore.ieee.org/document/11300288</link><description>This brief presents a reconfigurable 4-channel voltage-time-domain hybrid analog-to-digital converter (ADC) supporting reconfigurability in resolution and sampling speed. The ADC can be configured as 8-, 9-, or 10-bit based on time-domain quantization threshold (QT) shifting. Each sub-channel adopts a two-stage voltage-time architecture to enable fast and accurate QT injection. To maintain stable performance of the voltage-to-time converter (VTC), a constant-voltage-difference tracking circuit is proposed. The ADC prototype achieves 45.6-, 50.2-, and 53.7-dB SNDR with Nyquist inputs at 4-, 2-, and 1-GS/s sampling rates, respectively. Under 1.2-V supply, the power consumption is 23.92 mW, corresponding to the Walden FoM of 38.4, 45.2, and 60.4 fJ/conversion-step, respectively.</description></item><item><title>An IR-UWB Transmitter Using Two-Dimensional Differential Pulse Position Modulation</title><link>http://ieeexplore.ieee.org/document/11301785</link><description>This presents a low-power, high-data-rate impulse-radio ultra-wideband (IR-UWB) transmitter that integrates a two-dimensional differential pulse position modulation (2D-DPPM) with time-division multiplexing (TDM) and power-gating (PG) schemes. The proposed 2D-DPPM achieves a modulation order of 9-bit while eliminating the sync pulse required in conventional multipulse pulse position modulation (MPPM). By employing the TDM scheme, all data pulses are generated from a single delay-line-based digital-to-time converter (DTC), reducing power consumption and eliminating mismatch between two delay lines. The PG scheme further enhances power efficiency by dynamically deactivating unused delay cells according to real-time input data. Fabricated in 40 nm CMOS process, the transmitter delivers a data rate of 1.8 Gbps with an energy efficiency of 2.2 pJ/bit. A transcutaneous transmission distance of 11 cm is measured under the condition of applying 15-mm-thick pork tissue and a BER of less than  $10^{\mathbf {-3}}$ .</description></item><item><title>An 11.5-GHz 203.7-dBc/Hz FoMA Multi-Tap Inductor-Based Single-Core Fixed-Supply Reconfigurable VCO Achieving 8.2-dB PN Scaling</title><link>http://ieeexplore.ieee.org/document/11303291</link><description>Reconfigurable VCOs with scalable phase-noise (PN) and power consumption are critical for multi-protocol communication systems. This work presents a multi-tap inductor based PN-scaling (MIPS) technique that achieves PN and power-consumption scalability at a fixed supply voltage within a single-core area. By switching the drain connection to different taps of the tank inductor, the drain tank impedance is reconfigured, achieving scalable ISFeff, PN and power consumption. Fabricated in a 28-nm CMOS process with a core area of 0.053 mm2, the 11.5 GHz prototype MIPS VCO demonstrates an 8.2 dB PN and 3.4x power-consumption scalability across three operation modes. To the best of the authors&#8217; knowledge, the measured FoMA of 203.7 dBc/Hz is one of the highest reported among the recently published PN-scaling oscillators in CMOS, FDSOI, and BiCMOS technologies.</description></item><item><title>Efficient Asynchronous Sampling of Ripple Counter in VCO-ADC Using Ripple Register and Event Arbitration</title><link>http://ieeexplore.ieee.org/document/11339947</link><description>We present a power and area-efficient solution for robust asynchronous sampling of a ripple counter for coarse-fine VCO-ADCs. We show that by replacing the parallel register with a delay-matched sequential register and utilizing asynchronous arbitration, sampling errors are avoided. Post-layout simulation of a 7-bit system shows that our proposed solution tolerates VCO frequencies  $197\times $  higher than the baseline design, while requiring a 42&#8198;% increase in power and a 26&#8198;% area overhead, thereby improving upon a state-of-the-art double-counter solution.</description></item><item><title>A Seamless Mode Transition Scheme With DCM Compensation for AOT Buck Converter</title><link>http://ieeexplore.ieee.org/document/11343864</link><description>Power-saving sleep mode (SM) is commonly employed to extend devices runtime in battery-powered buck converters. However, conventional mode transitions from active mode (AM) to SM rely on hard-switching actions for power-state conversion, which inject loop noise and may cause output glitches. This brief proposes a seamless power and gain transition (SPGT) scheme to achieve smooth transition from AM to SM and competitive conversion efficiency. Besides, the introduced DCM compensation effectively suppresses subharmonic oscillation to address the instability issue during SM operation. The proposed scheme is implemented in a 180 nm BCD process with a core scheme area of  $0.07~\mu $ m2. Test results show seamless transitions both AM-SM and PWM-PFM without any glitches. No subharmonic oscillation is observed during either steady-state or transient operation. The prototype achieves a peak efficiency of 96% and a 30 mV undershoot voltage and a  $7\mu $ s settling time under a 0.1-3A load step.</description></item><item><title>A 24&#8211;30-GHz Small-Size High Isolation CMOS Common-Leg T/R Front-End IC With Variable-Gain Phase Shifter and Path Control Network</title><link>http://ieeexplore.ieee.org/document/11272908</link><description>This brief presents a 24&#8211;30GHz common-leg T/R front-end IC using a 65-nm CMOS process. The proposed IC comprises a path control network (PCN), a variable-gain phase shifter (VGPS), and two gain amplifiers. The VGPS and 3-piece transformers provide a significant reduction in chip size and insertion loss compared to conventional common-leg T/R front-end ICs. In addition, the proposed architecture facilitates integration with RF front-end modules and beamforming ICs. The PCN provides high isolation between the TX and RX paths, which is important for common-leg operation. The developed T/R IC exhibits a gain control dynamic range of 12 dB and a phase resolution of 5.625&#176;. The T/R IC has a compact chip size of 0.46 mm2 excluding pads. The measured rms phase and gain errors were less than 1.1&#176;/0.9&#176; and 0.3/0.3 dB in the TX and RX modes, respectively, across the entire operating frequency range, while the power consumption was measured as 37.9/43.3 mW.</description></item><item><title>LW-ResGRU DPD: Layer-Wise Residual GRU for Low-Latency DPD in Nonlinear RF Systems</title><link>http://ieeexplore.ieee.org/document/11278888</link><description>This brief presents LW-ResGRU, a layer-wise residual GRU architecture for low-latency digital predistortion (DPD) of power amplifiers (PAs) under hardware constraints. Conventional RNN-based DPD suffers from three hardware bottlenecks: high-sampling-rate demands, sequential hidden-state dependencies that limit pipelining, and the latency&#8211;accuracy trade-off from large hidden sizes. LW-ResGRU addresses these issues by injecting residual connections at every recurrent layer, enabling stable depth scaling even with reduced hidden sizes. All models were evaluated on the OpenDPD DPA 200 MHz dataset (13.4 dBm output, PAPR = 9.6&#8211;11 dB) under an equal parameter budget (&lt;600). With  $H=5$ , LW-ResGRU achieved Normalized Mean Square Error (NMSE)  $= -43.5$  dB, Error Vector Magnitude (EVM)  $= -46.7$  dB, and Adjacent Channel Power Ratio (ACPR) (Left/Right)  $= -50.4$ /&#8722;47.8 dBc, outperforming baseline RNN-based DPD models. Hardware feasibility was further confirmed by FPGA HLS synthesis, demonstrating the potential for real-time deployment.</description></item><item><title>Canonical Variate Autoencoder-Based Interpretable Fault Detection for Lithium-Ion Battery Packs</title><link>http://ieeexplore.ieee.org/document/11278887</link><description>With the large-scale application of electric vehicle and grid-scale energy storage systems, accurate and reliable fault detection (FD) of lithium-ion (Li-ion) battery packs is critical to the safe operation of such devices. As the key feature of battery faults, voltage correlation reflects the abnormal state of the battery by measuring the correlation change between data. Inspired by this, this brief proposes a canonical variate autoencoder for online FD in battery packs. First, the original voltages are reconstructed to obey the Gaussian distribution. Then, the canonical variable model is constructed to assess the synchronization between past and future voltages. Finally, a voltage correlation-based robust optimization objective is formulated to improve FD performance. Studies on a real lithium-ion battery experimental rig verify that the proposed method has reliable detection performance and clear physical interpretability.</description></item><item><title>Finite-Time Data-Driven Load Frequency Control for Multi-Area Power Systems</title><link>http://ieeexplore.ieee.org/document/11299053</link><description>In this brief, a novel finite-time data-driven control algorithm to address the load frequency control (LFC) problem in multi-area power systems (MAPSs) with unknown system parameters. To enhance the system&#8217;s response speed in solving the LFC problem, a new finite-time performance cost function is introduced within the model-free adaptive control (MFAC) framework. This cost function ensures that the LFC problem is resolved within a finite time step. Furthermore, the proposed algorithm relies solely on real-time input and output data, without the need for an accurate system model or prior knowledge. The stability of the algorithm is rigorously validated through comprehensive theoretical analysis, and its effectiveness is confirmed through simulations of a three-area power system.</description></item><item><title>A 21-Transistor Single-Phase-Clocked Flip-Flop With Low Leakage Current for Near-Threshold Voltage Operation</title><link>http://ieeexplore.ieee.org/document/11260504</link><description>A 21-transistor single-phase-clocked flip-flop with low leakage power is presented in this brief. The architecture of the proposed flip-flop is based on topological modification and device merging within a conventional 24-transistor transmission-gate flip-flop (TGFF). It achieves an asymmetric leader&#8211;follower design that can operate under a single-phase clock, eliminating the requirement for complementary clock signals and enhancing area efficiency. Post-layout evaluation on a 28nm CMOS technology confirms a 6% area reduction compared with the TGFF. With reduced transistor count, the proposed flip-flop lowers leakage power across a wide supply range: 17% at 0.4 V and 7% at 0.9 V. Without any device sizing optimization, it still reduces the total power consumption by more than 10% at both 0.4V 20MHz and 0.9V 1GHz. Across 5K Monte Carlo simulations covering process and temperature corners, the proposed flip-flop supports robust operation at the near-threshold voltage (NTV) region as other static contention-free flip-flops.</description></item><item><title>A Power-Efficient Hardware Accelerator for Real-Time Hashmap Construction in VVC Intra Block Copy</title><link>http://ieeexplore.ieee.org/document/11271677</link><description>Intra Block Copy (IBC) is a key coding tool in the Versatile Video Coding (VVC) standard for exploiting redundancy in screen content video. However, its hardware implementation suffers from high computational complexity, incomplete pipelining, and significant power consumption. To address these challenges, we propose a power-efficient hardware accelerator for real-time hashmap construction. First, a sliding window reuse mechanism and parallel CRC32 computation are proposed, organized in a six-lane processing manner. Next, a pre-segmentation method is proposed to enable processing of different bit depths. Finally, a low-power single-bit content-addressable memory (CAM) is designed to support fast and efficient storage and matching. Experimental results show that the proposed architecture achieves a  $32\times $  improvement in hash construction speed and approximately 42.02% reduction in power consumption during hash retrieval, enabling 4K@50fps real-time processing at 415MHz. To the best of our knowledge, this is the first dedicated hardware design for hashmap construction in VVC IBC.</description></item><item><title>A Counter-Based Addition Circuit Design for Stochastic Computing</title><link>http://ieeexplore.ieee.org/document/11298180</link><description>Stochastic computing (SC) encodes real values via probabilistic bitstreams, enabling complex arithmetic operations to be realized by simple logic gates. However, the requirement of longer bitstreams to ensure computing accuracy leads to higher latency, partially offsetting the low-complexity advantage of SC. To address this, this work utilizes a dynamic truncation method for stochastic bitstreams, and designs an energy-efficient counter-based addition circuit (CBAC) through effective bit recognition and correlation. Further, a tree-structured cascading architecture is then used to perform multi-input addition computing. Experimental results demonstrate that the proposed CBAC outperforms the state-of-the-art designs. For instance, a 16-input configuration achieves at least 75.9% reduction in mean square error (MSE) and a more than 43.1% reduction in area. When applied to polynomial computation and Gaussian filtering, the proposed architecture exhibits superior accuracy and efficiency, delivering MSE reductions of at least 10.7% and area reductions exceeding 6.8%.</description></item><item><title>Continual Learning-Guided Adaptive Approximate Computing for Real-Time MEA Spike Detection</title><link>http://ieeexplore.ieee.org/document/11298200</link><description>We propose a novel Continual Learning (CL)-based adaptive Approximate Computing (AxC) framework for Microelectrode array (MEA) spike detection on Field Programmable Gate Array (FPGA), enabling adaptive precision control under key constraints in real-time. Our approach aims to continuously learn from incoming MEA data and configure computational precision in response to dynamic input characteristics and design constraints, i.e., latency and accuracy, which are more critical than power consumption in this case. Towards this, we investigate the accuracy-efficiency trade-offs of MEA spike detection, through precision scaling. Our evaluations at the algorithmic-level reveal that 32-bit floating-point (FP32) single-precision filtering operation performs  $1.8\times $  faster than 64-bit floating point (FP64) double-precision baseline, with minimal detection accuracy loss. Moreover, the hardware-synthesized fixed-point implementations demonstrated substantial resource savings and an 86.6% reduction in dynamic power when using 16-bit fixed-point (Fix16) compared to the 32-bit fixed-point (Fix32).</description></item><item><title>An Area-Efficient Normal Input/Output Ordered Memory-Based FFT Using an SC Kernel</title><link>http://ieeexplore.ieee.org/document/11303851</link><description>This brief presents a 1024-point radix-2 memory-based fast Fourier transform (FFT) architecture. This work aims to achieve a normal order at both the input and the output without requiring an additional circuit or memory. The proposed architecture is the first memory-based FFT to utilize a serial commutator (SC) kernel as a processing element (PE). This halves the number of adders and multipliers. Likewise, a novel address generation circuit is presented. It produces the same memory read and write addresses for both memories, as well as conflict-free access. The proposed architecture has been implemented on a Virtex 7 field-programmable gate array (FPGA). The experimental results indicate that it achieves low area, efficient resource utilization, and low power consumption.</description></item><item><title>Physics-Informed Surrogate Neural Network for Optimizing Diode-Based Interfaces in Leadless Pacemaker Energy Harvesting</title><link>http://ieeexplore.ieee.org/document/11293066</link><description>Efficient AC&#8211;DC interfaces are essential for low-power energy harvesters to power intracardiac leadless pacemakers (ICLPs) reliably. For the front-end circuitry, selecting a diode that minimizes both conduction and leakage losses under specified operating conditions is challenging, as the forward voltage drop and reverse leakage current cannot be simultaneously reduced due to the device&#8217;s inherent physics. This brief presents a machine learning framework that predicts the DC output of diode-based AC-DC interfaces directly from specific voltage-current (V-I) characteristic points of the diodes and descriptive features of the excitation waveform. A physics-informed surrogate model is trained on SPICE-simulated data of rectifiers driven by experimentally captured cardiac harvester waveforms. Hardware validation with printed-circuit rectifiers powered by the same harvester source exhibits an average error of 0.03 V between prediction and measurement, matching the performance observed on the synthetic set and demonstrating robust generalization to real-world applications. This data-driven approach offers an instant, datasheet-only diode screening without circuit-level evaluation and can be integrated into automated multi-objective optimization flows for the design of low-power energy harvester AC&#8211;DC interfaces.</description></item><item><title>A 24-W 91.5% Peak Efficiency All-in-One Dual-Loop Controlled Quasi-Resonant Isolated DC&#8211;DC Converter With Adaptive Peak Current and Valley-Hysteresis-Locking Techniques</title><link>http://ieeexplore.ieee.org/document/11310826</link><description>This brief presents an all-in-one isolated DC-DC converter combines a primary flyback controller, secondary synchronous rectifier and digital isolator on a single chip. The converter adopts quasi-resonant (QR) peak current mode control with valley-hysteresis-locking (VHL) method. The adaptive peak current and VHL techniques could prevent sudden frequency hopping at some load point. Additionally, a down-hill detection method in the valley detector ensures accurate valley switching operation. With these proposed techniques, the converter could realize quasi-resonant under different load conditions. The chip has been fabricated with a  $0.18~\mu $ m BCD process, and the primary and secondary control chips occupy the area of 1.04 mm2 and 0.62 mm2, respectively. The converter delivers 12 V output with a maximum current of 2 A, achieving a peak efficiency of 91.5%.</description></item><item><title>Flexible Automatic Design of GaN PA Based on Gaussian Process-Assisted Nondominated Sorting Genetic Algorithm</title><link>http://ieeexplore.ieee.org/document/11062675</link><description>This article introduces a new method for designing power amplifiers (PAs) using a flexible, automatic approach. It employs a Gaussian process (GP)-assisted fast nondominated sorting genetic algorithm (GP-NSGA-II) for both circuit synthesis and layout optimization. Traditional genetic algorithms are computationally intensive and have poor convergence, making them difficult to use with 3-D full-wave simulators. To address these issues, the authors incorporate GP regression from Bayesian optimization into NSGA-II, improving convergence and computational efficiency. The method integrates layout simulation and optimization, enabling automatic PA design with direct layout optimization. To demonstrate the method&#8217;s effectiveness, the authors design a wide-band PA and a tri-band PA using a 10-W gallium-nitride (GaN) high electron mobility transistor (HEMT). The tests show that the prototypes perform well: the wide-band PA has a power-added efficiency (PAE) of over 61% and an output power greater than 41.5 dBm in the 2-3 GHz band, while the tri-band PA achieves PAE values of over 59%, 55%, and 57% in the 0.7-1.1 GHz, 2.3-2.5 GHz, and 3.4-3.5 GHz bands, respectively, with output powers exceeding 41.2 dBm, 40.6 dBm, and 40.6 dBm.</description></item><item><title>Chiplever: A Hardware&#8211;Software Co-Design Framework Toward Extension of Chiplet System for Fully Homomorphic Encryption</title><link>http://ieeexplore.ieee.org/document/11060913</link><description>fully homomorphic encryption (FHE) is a promising privacy-preserving technique that has drawn increasing attention from academia and industry. It allows computation directly on encrypted data without decryption. However, FHE incurs intensive computations. Chiplet-based designs integrate multiple processors, delivering high performance and thereby are embraced by computation-intensive FHE tasks. Despite the chiplet-based system with various processors, it is designed for unencrypted applications, falling short in handling FHE with unique ciphertext manipulations. One common approach to make it capable of FHE is developing a new FHE accelerator. However, this approach overlooks existing abundant resources already in the system and introduces a large area overhead. In this article, we propose Chiplever, a framework that empowers a non-FHE-tailored system to efficiently support FHE tasks via a hardware extension. Chiplever aims to leverage the existing resources already in the room for FHE tasks. To achieve this, 1) Chiplever introduces a hardware extension with an FHE unit providing efficient function support for FHE operators. 2) Chiplever proposes an FHE coordinator in the extension, which enables direct ciphertext transfer between the newly introduced extension and existing chiplets, achieving efficient integration of the extension. 3) Chiplever lowers the high-level homomorphic operations to primitive operators that can be matched by existing chiplets and constructs a fine-grained computation graph (CG). Based on this, Chiplever employs a task scheduling algorithm, which partitions the FHE task across the extension and existing chiplets to exploit the parallelism between them and reduce the ciphertext communication overheads. With these hardware and software optimizations, Chiplever achieves efficient FHE acceleration. Compared with prior FHE ASICs, Chiplever achieves  $9.6{\times }$ &#8211; $15.9{\times }$  speedup and  $6.2{\times }$ &#8211; $67.4{\times }$  throughput improvement on TFHE, while consuming only 18.8%&#8211;35.6% of the area overhead of dedicated FHE ASICs.</description></item><item><title>eBrainISA: Edge-Oriented Instruction Set Architecture for Hybrid Brain-Inspired Computing</title><link>http://ieeexplore.ieee.org/document/11084892</link><description>Hybrid brain-inspired computing (BIC), which integrates computer science-oriented artificial neural networks (ANNs) with neuroscience-oriented spiking neural networks (SNNs), represents a significant trend in the field of BIC. This approach demonstrates considerable advantages in domains, such as perception, cognition, and learning. Nevertheless, several challenges persist in deploying hybrid BIC on resource-constrained edge devices, particularly in enabling these devices to effectively manage complex tasks. To tackle these challenges, we present eBrainISA, an edge-oriented hybrid BIC instruction set architecture (ISA). eBrainISA is designed to support sophisticated ANNs, SNNs, and hybrid neural networks (HNNs), which integrates an extensive suite of neural operators that are tailored to accommodate the hardware limitations on edge devices. To validate the proposed architecture, we develop a unified low-precision quantization approach alongside a hardware simulator. Prior ISAs offer limited support for hybrid BIC, while ours can support all major networks, including ANNs such as ResNet and Yolo, SNNs such as Spike_ResNet and Spike_Transformer, and HNNs such as DetectHNN and ReSpike with &lt;1% accuracy degradation. Moreover, our architecture achieves about  $5\times $  memory saving compared to full-precision versions and  $3.87\times $ &#8211; $53.61\times $  higher energy efficiency compared to edge GPU when executing different neural networks with diverse behaviors. This work demonstrates a promising balance between intelligent demands for general models and resource constraints on edge devices.</description></item><item><title>SCISSORS: System Level Error Detection for Enabling Near-Threshold Operating Systolic Arrays</title><link>http://ieeexplore.ieee.org/document/11062572</link><description>Since dynamic power has a quadratic relationship with voltage, reducing voltage is an effective way to lower power consumption in digital circuits. However, maintaining stable operation at lower voltages is challenging due to increased sensitivity to process, voltage, and temperature (PVT) variations, making it difficult to determine optimal operating points using static timing analysis (STA). While circuit- and device-level solutions like timing error detection (TED) systems can enable lower voltage operation, they introduce significant overhead and design complexity. In this article, we integrate an algorithm-based fault tolerance (ABFT) method into the structure of systolic arrays (SAs) to capture timing errors when voltage is scaled down, ensuring safe and optimized low-voltage operation. Our proposed approach, SCISSORS, demonstrates how extra voltage margins in SAs used for matrix arithmetic can be trimmed by integrating a simple algorithmic technique into the structure of the array. This solution not only detects errors in the accelerator but also those caused by voltage reduction in on-chip memory and auxiliary circuits. It is fully implementable through hardware description languages (HDL) without requiring transistor- or circuit-level modifications to the netlist. Implementation on a Zynq system-on-chip (SoC) shows that SCISSORS introduces only a tolerable overhead of 11% and 8% for  $32{\times }32$  and  $64{\times }64$  SAs, respectively, while achieving nearly a  $2{\times }$  improvement in energy efficiency. Experimental results further demonstrate that SCISSORS adaptively adjusts voltage in response to the voltage-temperature coupling behavior of digital circuits at runtime, specifically addressing inverse temperature dependence (ITD).</description></item><item><title>Scalable Sequential Logic Synthesis Using Observability Don&#8217;t Care Conditions</title><link>http://ieeexplore.ieee.org/document/11078761</link><description>Sequential logic synthesis expands the solution space compared to combinational logic synthesis by reasoning about the reachable states of memory elements, leading to better power-performance-area (PPA) outcomes. As gate costs continue to rise in advanced technologies, sequential logic synthesis is gaining significant traction within the electronic design automation (EDA) community as a powerful alternative. This article introduces a scalable algorithm for don&#8217;t care (DC)-based sequential logic synthesis, leveraging sequential k-step induction to perform redundancy removal and resubstitution under sequential observability don&#8217;t care (SODCs). sequential observability don&#8217;t cares (SODCs) generalize observability don&#8217;t care (ODCs) by explicitly considering reachable states, making SODC-based optimization a challenging problem due to dependencies and alignment issues between the base case and inductive case in k-step induction. Our approach overcomes these challenges, fully utilizing the potential of SODCs without limiting the solution space. We rigorously prove the correctness of our approach, discuss some limitations arising from bounded-step induction, and analyze how our approach can effectively be used in practice to exploit obscure optimization opportunities. Implemented as part of an industrial tool, our algorithm achieves an average &#8722;6.9% area improvement after technology mapping compared to state-of-the-art sequential synthesis methods, and further provides 3.16% and 1.06% reductions in combinational and sequential areas, respectively, in post place-and-route results. Furthermore, all optimizations are efficiently verified using industrial sequential verification tools.</description></item><item><title>Identifying Design Challenges in Analog Circuits Due to Device Nonidealities at Cryogenic Temperatures</title><link>http://ieeexplore.ieee.org/document/11068185</link><description>This work presents a detailed analysis of the impact of MOS device performance on circuit metrics at cryogenic temperatures. An experimentally proven, industry standard compact model is calibrated to match the performance of the corresponding devices from ST Microelectronics 28nm (STM28) PDK. The temperature related parameters of this model are then calibrated with experimental data at cryogenic temperatures, available in the literature. This model is then used to explore a Strong-Arm latched comparator, a 4-bit Flash analog-to-digital converter (ADC) and a ring oscillator to study temperature-dependent performance trends. We point out certain key concerns which necessitate additional design effort and area/hardware overhead required to achieve the desired specifications at cryogenic temperatures.</description></item><item><title>veriSiM: Formal Verification of SPICE Netlists for MAGIC-Based Logic-in-Memory</title><link>http://ieeexplore.ieee.org/document/11050967</link><description>Advancements in emerging technologies have recently increased the traction of non-von Neumann design styles. One of the most popular design styles in this domain involves using memristors to perform logic operations in memory, known as logic-in-memory (LiM). memristor aided logic (MAGIC) is one of such LiM based design style that is widely used given its benefits in latency and energy. Several prior works have focused on the generation of logic operations, also called micro-operations, for LiM based on the MAGIC design style. Recently, the generation of SPICE netlists for MAGIC design style has been achieved by the MemSPICE tool. While this represents a significant step forward, verifying the correctness of the generated netlists still depends on SPICE-level simulations. These simulations become particularly impractical for medium-to-large designs presenting a bottleneck in the validation process. To address this limitation, in this article, we introduce veriSiM, an automated formal verification methodology for MAGIC-based LiM. More concretely, it ensures the correctness of the generated LiM SPICE netlists against the golden reference Verilog design. Our methodology involves generating clauses from the SPICE netlists and verifying them against clauses generated from the golden reference Verilog design, using the high-performance Z3 solver to perform the equivalence checking. The clause generation process from the SPICE netlists needs to be based on several conditions, which have been identified and discussed in detail. We have used several benchmarks from ISCAS&#8217;85, ISCAS&#8217;89, and ITC&#8217;99 to demonstrate the efficacy of the veriSiM methodology in formally verifying the LiM SPICE netlists.</description></item><item><title>QNU-CPN: A Low-Power Single-Event Quadruple-Node-Upset Recovery Latch</title><link>http://ieeexplore.ieee.org/document/11084868</link><description>Integrated circuit are increasingly sensitive to radiation-induced multinode upset in advanced cMOS technology. This article proposes a novel low-power quadruple-node-upset (QNU) recovery latch (QNU-CPN), which is based on the feedback interconnection of twenty-two input-split C-element with P-input and N-input (CPNs) to achieve high reliability. Post-layout simulation results for 45-nm cMOS by HSPICE technology show that the proposed QNU-CPN latch exhibits a reduction in power consumption by an average of 56.45%, a reduction in power-delay product (PDP) by an average of 56.92%, a reduction in area-PDP (APDP) by an average of 58.59%, and a reduction in setup time by an average of 11.11%, in comparison to four other existing QNU recovery latch (LDAVPM, QRHIL, QRHIL-LC, MURLAV). Furthermore, this article proposes the recovery rate calculation algorithm method that can calculate the recovery rate based on the configuration of multiple fault-tolerant components.</description></item><item><title>AnaCraft: Duel-Play Probabilistic-Model-Based Reinforcement Learning for Sample-Efficient PVT-Robust Analog Circuit Sizing Optimization</title><link>http://ieeexplore.ieee.org/document/11063353</link><description>Recent advancements in machine learning offer the potential for finding faster and robust optimization approaches for analog circuit design automation. However, fully automated yet fast and process, voltage, and temperature (PVT)-robust sizing algorithms are still lacking as even the most recent methods continue to require extensive simulations or domain-specific circuit expertise. In this article, we present a PVT-robust analog circuit sizing method, called AnaCraft, that is the first to introduce an adversarial training scheme of multiagent reinforcement learning (RL) for robust circuit design automation. We adopt the soft actor&#8211;critic (SAC) agent for circuit sizing, which outperforms other actor&#8211;critic agents in stability and robustness. Then, we introduce a duel-play scheme to address PVT-robustness, where sizing agents cooperate to find optimal circuit parameters while competing with an adversarial PVT agent. We combine this approach with the model-based policy optimization method: an ensemble of probabilistic models is trained and used to extract many short rollouts of generated data for updating the sizing agents. We test our algorithm on the sizing of operational amplifiers in a 45-nm CMOS technology, as well as on a complex data receiver circuit in a predictive 7-nm FinFET technology. This demonstrates our approach&#8217;s ability to find PVT-robust power-area-optimal sizes for advanced technologies and circuits. Our proposed method achieves a higher figure of merit with up to  $\sim 3\times $  fewer circuit simulations and  $\sim 2\times $  less runtime compared to existing state-of-the-art methods.</description></item><item><title>Oiso: Outlier-Isolated Data Format for Low-Bit Large Language Model Quantization</title><link>http://ieeexplore.ieee.org/document/11062568</link><description>The scale of large language models (LLMs) has steadily increased over time, leading to enhanced performance in multimodal understanding and complex reasoning, but with significant execution overhead on hardware. Quantization is a promising approach to reduce computation and memory overhead for LLM deployment. However, maintaining accuracy and efficiency simultaneously is challenging due to the presence of outliers. Moreover, low-bit quantization tends to deteriorate accuracy due to its limited precision. Existing outlier-aware quantization/hardware co-design methods split the sparse outliers from the normal values with dedicated encoding schemes. However, such separation produces a nonuniform data format for normal values and outliers, leading to additional hardware design and inefficient memory access. This article presents an outlier-isolated data format (Oiso) for low-bit LLM quantization called Oiso. Oiso is a unified representation for both outliers and normal values. It isolates the normal values from the outliers, which can reduce the impact of outliers on the normal values during the quantization process. Taking advantage of the uniform format, Oiso arithmetic can be performed using a homogeneous computational unit, and Oiso values can be stored in a standardized format. Hierarchical block encoding with a subblock alignment scheme is introduced to reduce the encoding cost and the hardware overhead. We introduce the Oiso architecture, equipped with Oiso processing elements and encoders tailored for Oiso arithmetic, realizing efficient low-bit LLM inference. Oiso quantization can push the limits of low-bit LLM quantization, and the Oiso accelerator outperforms the state-of-the-art outlieraware accelerator design with  $1.26\times $  performance improvement and 25% energy reduction.</description></item><item><title>TRIM: Thermal Auto-Compensation for Resistive In-Memory Computing</title><link>http://ieeexplore.ieee.org/document/11073135</link><description>in-memory computing (IMC) has emerged as one of the most promising architectures to efficiently compute artificial intelligence tasks on hardware, particularly deep neural networks (DNNs). IMC can make use of analog computation principles alongside emerging nonvolatile memories (eNVM) technologies, potentially offering several orders of magnitude increased energy efficiency compared to generic processing units. Yet, the use of analog circuitry, potentially integrated with emerging technologies post-processed on top of silicon wafers, increases the susceptibility of hardware to a large spectrum of variations, for instance manufacturing, noise or temperature sensitivity. Hence, this susceptibility can hamper the large-scale deployment of IMC circuits into the market. To tackle the reliability of analog resistive-based IMC circuits regarding temperature variations, this article presents TRIM, a thermal on-chip auto-compensation method aimed at fully calibrating first-order temperature effects. TRIM is designed to maintain the computational accuracy of IMC cores in DNN applications over a wide temperature range, while being highly scalable and adaptable. In essence, the temperature compensation is realized through a complementary-to-absolute-temperature (CTAT) voltage reference integrated inside a voltage regulator and applied at the zero reference node of a multiplying digital-to-analog converter (MDAC), eliminating the need for external circuits or look-up table. The proposed methodology is demonstrated on a proof-of-concept 65 nm CMOS resistive IMC column. Measurement results showcase that the proof-of-concept auto-compensation system significantly enhances inference and multiply-and-accumulate (MAC) operation accuracy of any first-order resistive crossbar column, achieving inference accuracy recovery of 100% over a temperature range of &#8211;20 &#176;C to 60 &#176;C and a 91.3% improvement in MAC operation accuracy, with an area overhead of 2% and power overhead of &#161; 0.02%.</description></item><item><title>Memristive Neural Network Circuit Implementation of Model Predictive Control for Trajectory Tracking</title><link>http://ieeexplore.ieee.org/document/11096083</link><description>model predictive control (MPC), a receding-horizon optimal control strategy, predicts system dynamics and optimizes control actions to satisfy performance and constraint requirements, making it widely adopted in control engineering. However, contemporary computing platforms struggle to meet the real-time and energy-efficient demands of MPC&#8217;s computationally intensive matrix operations, stemming from high data movement overhead, extensive circuit resource utilization, and frequent data conversions inherent in physical system interfaces. These challenges collectively impose significant latency and power penalties, particularly critical as systems grow in complexity and scale within the big-data era. This article introduces a zeroing neural network (ZNN)-based memristive neural network circuit that directly converges the MPC error function to zero in one step. Theoretical analysis and simulations validate the closed-loop circuit&#8217;s stability. For a 32-step prediction horizon, evaluations show that the control output from the proposed circuit matches the ideal digital MPC solution with 96.0% accuracy. The circuit also executes at least an order of magnitude faster and consumes less energy than traditional MPC solvers. Additionally, the circuit successfully accelerates the proposed trajectory tracking algorithm, achieving 98.0% accuracy compared with the theoretical result and  $318.2\times $  improvement in computation time compared to CPU.</description></item><item><title>NeFT: Negative Feedback Training to Improve Robustness of Compute-in-Memory DNN Accelerators</title><link>http://ieeexplore.ieee.org/document/11087589</link><description>Compute-in-memory accelerators built upon nonvolatile memory devices excel in energy efficiency and latency when performing deep neural network (DNN) inference, thanks to their in-situ data processing capability. However, the stochastic nature and intrinsic variations of nonvolatile memory devices often result in performance degradation during DNN inference. Introducing these nonideal device behaviors in DNN training enhances robustness, but drawbacks include limited accuracy improvement, reduced prediction confidence, and convergence issues. This arises from a mismatch between the deterministic training and nondeterministic device variations, as such training, though considering variations, relies solely on the model&#8217;s final output. In this work, inspired by control theory, we propose negative feedback training (NeFT)&#8212;a novel concept supported by theoretical analysis&#8212;to more effectively capture the multiscale noisy information throughout the network. We instantiate this concept with two specific instances, oriented variational forward (OVF) and intermediate representation snapshot (IRS). Based on device variation models extracted from measured data, extensive experiments show that our NeFT outperforms existing state-of-the-art methods with up to a 45.08% improvement in inference accuracy while reducing epistemic uncertainty, boosting output confidence, and improving convergence probability. These results underline the generality and practicality of our NeFT framework for increasing the robustness of DNNs against device variations. The source code for these two instances is available at https://github.com/YifanQin-ND/NeFT_CIM.</description></item><item><title>Gas Leakage Detection Using YOLO Accelerator Based on ZYNQ</title><link>http://ieeexplore.ieee.org/document/11096717</link><description>Infrared imaging is a valuable technology for gas leakage detection due to its high sensitivity, long detection range, and high efficiency. Conventional target detection methods depend on manually extracting image features, which often leads to limited accuracy, low adaptability, and slow detection speeds. Deep learning technology offers a potential solution to these challenges; however, the increasing depth of neural networks imposes significant computational demands, posing challenges to real-time detection. This article presents a compact and energy-efficient gas detection system, implemented with a ZYNQ platform and an infrared camera. We propose a ZYNQ-based convolution accelerator to enhance gas plume detection from images captured by the infrared camera. Operating at a clock frequency of 130 MHz, the accelerator is capable of reaching a peak performance of 37.44 Gop/s, with power consumption of only 4.12 W. The system achieves a processing speed of 0.235 s per image, enabling real-time gas leakage detection.</description></item><item><title>Systematic Methodology of Modeling and Design Space Exploration for CMOS Image Sensors</title><link>http://ieeexplore.ieee.org/document/11068172</link><description>CMOS image sensors (CIS) are integral to both human and computer vision tasks, necessitating continuous improvements in key performance metrics, such as latency, power, and noise. Despite experienced designers being able to make informed design decisions, novice designers and system architects face challenges due to the complex and expansive design space of CIS. This article introduces a systematic methodology that elucidates the tradeoffs among CIS performance metrics and enables efficient design space exploration (DSE). Specifically, we propose a first-principle-based CIS modeling method. By exposing low-level circuit parameters, our modeling method explicitly reveals the impacts of design changes on high-level metrics. Based on the modeling method, we propose a DSE process that swiftly evaluates and identifies the optimal CIS design, capable of exploring over  $10^{9}$  designs in under a minute without the need for time-consuming SPICE simulations. Our approach is validated through a case study and comparisons with real-world designs, demonstrating its practical utility in guiding early-stage CIS design.</description></item><item><title>A ReRAM-Based Processing-in-Memory Framework for LSM-Based Key-Value Store</title><link>http://ieeexplore.ieee.org/document/11087580</link><description>log-structured merge (LSM) tree-based key-value (KV) stores organize writes into hierarchical batches to optimize write performance. However, the notorious compaction process and multilevel query mechanism of LSM-tree severely hurt system performance. Our preliminary experiments show that 1) When compaction occurs in the  $L_{0}$  and  $L_{1}$  of the LSM-tree, it may saturate system computation and memory resources, ultimately causing the entire system to stall and 2) large number of iterative retrievals across multiple levels is usually required to locate the queried data, while redundant key range overlap in  $L_{0}$  further increases the overhead. Based on these observations, we introduce Re-LSM+, a resistive random-access memory (ReRAM)-based Processing-in-Memory framework for LSM-based KV Stores. In Re-LSM+, we offload compaction tasks from the higher levels of the LSM-tree to the PIM processing part. A highly parallel ReRAM compaction accelerator is designed by breaking down the three-phase compaction process into basic logic operations. Additionally, we design an index table and a multilayer Bloom filter for different levels to improve the query efficiency of the LSM-tree. Evaluation results from db_bench show that Re-LSM+ achieves a  $2.37\times $  improvement in random write throughput compared to RocksDB. Furthermore, the ReRAM-based compaction accelerator achieves a  $68.16\times $  speedup over the CPU-based implementation and reduces energy consumption to  $25.5\times $ .</description></item></channel></rss>